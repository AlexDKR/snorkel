{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28087\n",
      "27896\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "print len(train)\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()\n",
    "print len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1)\n",
      "(27896, 1)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "\n",
    "L_gold_train = label_manager.load(session, train, \"CDR Training Label Set\")\n",
    "print L_gold_train.shape\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")\n",
    "print L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `L_train` and `L_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1645)\n",
      "(27896, 1557)\n",
      "CPU times: user 20.3 s, sys: 680 ms, total: 21 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from snorkel.annotations import merge_annotations\n",
    "from utils import binarize_LF_matrix, get_binarized_score\n",
    "\n",
    "L_TRAIN_BLOCKS = ['1', '2', '3', '4.1', '4 T2', '4 N', '5', '6']\n",
    "L_DEV_BLOCKS   = ['1', '2', '3.1', '4', '4 T2', '4 N', '5', '6']\n",
    "\n",
    "L_train_blocks = [label_manager.load(session, train, 'LF Training Labels %s' % lfn) for lfn in L_TRAIN_BLOCKS]\n",
    "L_dev_blocks   = [label_manager.load(session, dev, 'LF Development Labels %s' % lfn) for lfn in L_DEV_BLOCKS]\n",
    "\n",
    "L_train   = merge_annotations(L_train_blocks)\n",
    "L_train_b = binarize_LF_matrix(L_train)\n",
    "L_dev     = merge_annotations(L_dev_blocks)\n",
    "L_dev_b   = binarize_LF_matrix(L_dev)\n",
    "print L_train.shape\n",
    "print L_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `F_train` and `F_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 69885)\n",
      "(27896, 69885)\n",
      "CPU times: user 32.5 s, sys: 1.32 s, total: 33.8 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "\n",
    "F_train = feature_manager.load(session, train, 'Train Features')\n",
    "F_dev   = feature_manager.load(session, dev, 'Train Features')\n",
    "print F_train.shape\n",
    "print F_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load canonical & secondary dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cPickle import load\n",
    "cd = load(open('cd.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 1: Direct EN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 1.i: Exact Match\n",
    "\n",
    "In this first setup, we simply try to do exact matching on noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.825947334618\n",
      "R:\t0.323440643863\n",
      "F1:\t0.464847279957\n"
     ]
    }
   ],
   "source": [
    "correct   = 0\n",
    "predicted = 0\n",
    "total_pos = 0\n",
    "for i,c in enumerate(dev):\n",
    "    if L_gold_dev[i,0] > 0:\n",
    "        total_pos += 1\n",
    "    \n",
    "    # Check for exact *positive* matches to the canonical dictionary\n",
    "    p    = c.disease.get_span().lower()\n",
    "    sids = cd.term_to_sids[p]\n",
    "    cids = set([cd.sid_to_cid[sid] for sid in sids if sid in cd.sid_to_cid])\n",
    "    if len(cids) > 0:\n",
    "        predicted += 1\n",
    "        cid = list(cids)[0]\n",
    "        if cid == L_gold_dev[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total_pos)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 1.ii: TF-IDF\n",
    "\n",
    "We tune the accept threshold on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 272295\n",
      "CPU times: user 39.8 s, sys: 1.01 s, total: 40.8 s\n",
      "Wall time: 39.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from entity_norm import CanonDictVectorizer \n",
    "\n",
    "# Create a vectorizer based around this \n",
    "cd_vectorizer = CanonDictVectorizer(cd.term_to_sids, other_phrases=[])\n",
    "\n",
    "# Vectorize the dictionary\n",
    "D_pos   = cd_vectorizer.vectorize_phrases(cd.pos_terms)\n",
    "D_pos_t = D_pos.T\n",
    "D_pos_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_pos_vector_matches(candidates):\n",
    "    best_match = defaultdict(lambda : (0.0, -1))\n",
    "    for c in candidates:\n",
    "        p  = c.disease.get_span().lower()\n",
    "        cx = cd_vectorizer.vectorize_phrases([p])\n",
    "        m  = cx * D_pos_t\n",
    "        m  = m.tocoo()\n",
    "        for i, s in enumerate(m.data):\n",
    "            j    = m.col[i]\n",
    "            t    = cd.pos_terms[j]\n",
    "            sids = cd.term_to_sids[t]\n",
    "            cid  = list(set([cd.sid_to_cid[sid] for sid in sids if sid in cd.sid_to_cid]))[0]\n",
    "            if s > best_match[c.id][0]:\n",
    "                best_match[c.id] = (s, cid)\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 2.25 s, total: 3min 7s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%time best_match = get_pos_vector_matches(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3870"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_pos_train = sum([1 for i in range(L_gold_train.shape[0]) if L_gold_train[i,0] > 0])\n",
    "N_pos_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GRID = xrange(0, 20)\n",
    "f1s  = []\n",
    "\n",
    "# Grid search over threshold using training set labels\n",
    "for t in GRID:\n",
    "    thresh = 0.05 * t\n",
    "    \n",
    "    correct   = 0\n",
    "    predicted = 0\n",
    "    for i,c in enumerate(train):\n",
    "        s, cid = best_match[c.id]\n",
    "        if s > thresh:\n",
    "            predicted += 1\n",
    "            if cid == L_gold_train[i,0]:\n",
    "                correct += 1\n",
    "    \n",
    "    prec   = correct / float(predicted)\n",
    "    recall = correct / float(N_pos_train)\n",
    "    f1     = (2*prec*recall) / (prec+recall)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESH = GRID[np.argmax(f1s)]*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 1.91 s, total: 3min 5s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%time best_match = get_pos_vector_matches(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.482858803021\n",
      "R:\t0.41800804829\n",
      "F1:\t0.448099218118\n"
     ]
    }
   ],
   "source": [
    "N_pos_dev = sum([1 for i in range(L_gold_dev.shape[0]) if L_gold_dev[i,0] > 0])\n",
    "correct   = 0\n",
    "predicted = 0\n",
    "for i,c in enumerate(dev):\n",
    "    s, cid = best_match[c.id]\n",
    "    if s > THRESH:\n",
    "        predicted += 1\n",
    "        if cid == L_gold_dev[i,0]:\n",
    "            correct += 1\n",
    "    \n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(N_pos_dev)\n",
    "f1     = (2*prec*recall) / (prec+recall)\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 1.iii: Using the Gen. Model directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the multinomial version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "N, M        = L_dev.shape\n",
    "mn_maps     = []\n",
    "mn_inv_maps = []\n",
    "nz_idxs     = []\n",
    "Xs          = []\n",
    "for i in range(N):\n",
    "    nz = L_dev.getrow(i).nonzero()[1]\n",
    "    if len(nz) > 0:\n",
    "        nz_idxs.append(i)\n",
    "    \n",
    "        # Construct the map from CID -> column index, and reverse\n",
    "        mn_map     = {}\n",
    "        mn_inv_map = []\n",
    "        for j in nz:\n",
    "            label = L_dev[i,j]\n",
    "            if label not in mn_map:\n",
    "                mn_map[label] = len(mn_map)\n",
    "                mn_inv_map.append(label)\n",
    "        mn_maps.append(mn_map)\n",
    "        mn_inv_maps.append(mn_inv_map)\n",
    "    \n",
    "        # Construct the candidate label matrix\n",
    "        X = np.zeros((M, len(mn_map)))\n",
    "        for j in nz:\n",
    "            k = mn_map[L_dev[i,j]]\n",
    "            X[j, k] = 1\n",
    "        Xs.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training for rate=0.01, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.430527\n",
      "Final gradient magnitude for rate=0.01, mu=1e-06: 0.455\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.learning_mn import LogReg\n",
    "\n",
    "gen_model = LogReg()\n",
    "gen_model.train(Xs, n_iter=100, rate=1e-2, w0=np.ones(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marginals = gen_model.marginals(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.68532759151\n",
      "R:\t0.560362173038\n",
      "F1:\t0.616576726166\n"
     ]
    }
   ],
   "source": [
    "predicted = 0\n",
    "correct   = 0\n",
    "for i,m in enumerate(marginals):\n",
    "    cid = mn_inv_maps[i][np.argmax(m)]\n",
    "    if cid > 0:\n",
    "        predicted += 1\n",
    "        if cid == L_gold_dev[nz_idxs][i,0]:\n",
    "            correct += 1\n",
    "            \n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(N_pos_dev)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 1.iv: DP -> SSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 3.47 s, total: 2min 31s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorize the train & dev sets\n",
    "X_train = cd_vectorizer.vectorize_phrases([c.disease.get_span().lower() for c in train])\n",
    "X_dev   = cd_vectorizer.vectorize_phrases([c.disease.get_span().lower() for c in dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from entity_norm import SSIModel\n",
    "\n",
    "model = SSIModel(D, cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27439422734594754"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
