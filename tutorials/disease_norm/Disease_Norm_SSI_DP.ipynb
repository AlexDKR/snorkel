{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the full EN pipeline\n",
    "\n",
    "1. Use the LFs to train a binary classification LR model: DISEASE vs. OTHER\n",
    "2. Filter by the predictions of this model\n",
    "3. Train an SSI model using DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28087\n",
      "27896\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "print len(train)\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()\n",
    "print len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1)\n",
      "(27896, 1)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "\n",
    "L_gold_train = label_manager.load(session, train, \"CDR Training Label Set\")\n",
    "print L_gold_train.shape\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")\n",
    "print L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load canonical & secondary dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cPickle import load\n",
    "cd = load(open('cd.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 271512\n",
      "CPU times: user 42.9 s, sys: 1.74 s, total: 44.6 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from entity_norm import CanonDictVectorizer \n",
    "\n",
    "# Create a vectorizer based around this \n",
    "cd_vectorizer = CanonDictVectorizer(cd.term_to_sids, other_phrases=[])\n",
    "\n",
    "# Vectorize the dictionary\n",
    "D_pos = cd_vectorizer.vectorize_phrases(cd.pos_terms)\n",
    "D_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `L_train` and `L_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1645)\n",
      "(27896, 1557)\n",
      "CPU times: user 32.3 s, sys: 808 ms, total: 33.2 s\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from snorkel.annotations import merge_annotations\n",
    "from utils import binarize_LF_matrix, get_binarized_score\n",
    "\n",
    "L_TRAIN_BLOCKS = ['1', '2', '3', '4.1', '4 T2', '4 N', '5', '6']\n",
    "L_DEV_BLOCKS   = ['1', '2', '3.1', '4', '4 T2', '4 N', '5', '6']\n",
    "\n",
    "L_train_blocks = [label_manager.load(session, train, 'LF Training Labels %s' % lfn) for lfn in L_TRAIN_BLOCKS]\n",
    "L_dev_blocks   = [label_manager.load(session, dev, 'LF Development Labels %s' % lfn) for lfn in L_DEV_BLOCKS]\n",
    "\n",
    "L_train   = merge_annotations(L_train_blocks)\n",
    "L_train_b = binarize_LF_matrix(L_train)\n",
    "L_dev     = merge_annotations(L_dev_blocks)\n",
    "L_dev_b   = binarize_LF_matrix(L_dev)\n",
    "print L_train.shape\n",
    "print L_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `F_train` and `F_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 69885)\n",
      "(27896, 69885)\n",
      "CPU times: user 42.5 s, sys: 1.93 s, total: 44.4 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "\n",
    "F_train = feature_manager.load(session, train, 'Train Features')\n",
    "F_dev   = feature_manager.load(session, dev, 'Train Features')\n",
    "print F_train.shape\n",
    "print F_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "\n",
    "We used the discriminative model, trained using the training_marginals from the binary gen model over the training set, to filter both the training and test sets to predicted positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/__init__.py:1173: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t28087\n",
      "Features:\t\t\t1645\n",
      "================================================================================\n",
      "CPU times: user 29.4 s, sys: 8 ms, total: 29.4 s\n",
      "Wall time: 29.4 s\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t20038\n",
      "Features:\t\t\t69885\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 13889.283204\tGradient magnitude = 9832.035530\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 3078.241784\tGradient magnitude = 379.275662\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 2894.743086\tGradient magnitude = 1296.907839\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 2494.032915\tGradient magnitude = 297.457588\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 2394.454863\tGradient magnitude = 31.977057\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 2337.136536\tGradient magnitude = 28.324998\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 2295.414531\tGradient magnitude = 25.754725\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 2263.718238\tGradient magnitude = 23.827790\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 2238.906221\tGradient magnitude = 22.330616\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 2219.038251\tGradient magnitude = 21.137956\n",
      "\tLearning epoch = 1000\tStep size = 0.000367695424771\n",
      "\tLoss = 2202.843808\tGradient magnitude = 20.169672\n",
      "\tLearning epoch = 1100\tStep size = 0.000332687932862\n",
      "\tLoss = 2189.454311\tGradient magnitude = 19.371671\n",
      "\tLearning epoch = 1200\tStep size = 0.000301013429093\n",
      "\tLoss = 2178.254659\tGradient magnitude = 18.705967\n",
      "\tLearning epoch = 1300\tStep size = 0.000272354586819\n",
      "\tLoss = 2168.796602\tGradient magnitude = 18.145076\n",
      "\tLearning epoch = 1400\tStep size = 0.000246424291385\n",
      "\tLoss = 2160.745394\tGradient magnitude = 17.668571\n",
      "\tLearning epoch = 1500\tStep size = 0.000222962763703\n",
      "\tLoss = 2153.845745\tGradient magnitude = 17.260959\n",
      "\tLearning epoch = 1600\tStep size = 0.000201734957697\n",
      "\tLoss = 2147.899787\tGradient magnitude = 16.910263\n",
      "\tLearning epoch = 1700\tStep size = 0.000182528205523\n",
      "\tLoss = 2142.751331\tGradient magnitude = 16.607075\n",
      "\tLearning epoch = 1800\tStep size = 0.000165150086984\n",
      "\tLoss = 2138.275687\tGradient magnitude = 16.343897\n",
      "\tLearning epoch = 1900\tStep size = 0.000149426501798\n",
      "\tLoss = 2134.372054\tGradient magnitude = 16.114692\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg, NaiveBayes\n",
    "\n",
    "gen_model_b = NaiveBayes()\n",
    "%time gen_model_b.train(L_train_b, n_iter=10000, rate=1e-1, verbose=False)\n",
    "\n",
    "train_marginals = gen_model_b.marginals(L_train_b)\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-3, mu=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.845507246377\n",
      "R :\t0.753746770026\n",
      "F1:\t0.796994535519\n"
     ]
    }
   ],
   "source": [
    "yp_d_train = disc_model.predict(F_train, b=0.5)\n",
    "get_binarized_score(yp_d_train, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.838600797791\n",
      "R :\t0.687374245473\n",
      "F1:\t0.755494125777\n"
     ]
    }
   ],
   "source": [
    "yp_d_dev = disc_model.predict(F_dev, b=0.5)\n",
    "get_binarized_score(yp, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "\n",
    "We run the multinomial generative model over the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training for rate=0.01, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.236760\n",
      "Final gradient magnitude for rate=0.01, mu=1e-06: 0.258\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.learning_mn import assemble_mn_format, LogReg\n",
    "\n",
    "Xs, mn_maps, mn_inv_maps, nz_idxs = assemble_mn_format(L_train, mask=yp_d_train)\n",
    "gen_model = LogReg()\n",
    "gen_model.train(Xs, n_iter=100, rate=1e-2, w0=np.ones(L_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.746175243394\n",
      "R :\t0.554521963824\n",
      "F1:\t0.636228876371\n"
     ]
    }
   ],
   "source": [
    "from utils import get_mn_score\n",
    "\n",
    "train_marginals = gen_model.marginals(Xs)\n",
    "N_pos_train = sum([1 for i in range(L_gold_train.shape[0]) if L_gold_train[i,0] > 0])\n",
    "predicted   = [mn_inv_maps[i][np.argmax(m)] for i,m in enumerate(train_marginals)]\n",
    "get_mn_score(predicted, L_gold_train[nz_idxs], N_total_pos=N_pos_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "\n",
    "We construct the training phrases (`X_train`) and marginals (`Y_train`) based on the output of the multinomial generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2896x271513 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5984 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = cd_vectorizer.vectorize_phrases([train[i].disease.get_span().lower() for i in nz_idxs])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2896x4790 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "Np      = len(train_marginals)\n",
    "K       = len(set(cd.sid_to_cid.values()))\n",
    "Y_train = lil_matrix((Np, K))\n",
    "\n",
    "for i in range(Np):\n",
    "    for j in range(len(train_marginals[i])):\n",
    "        Y_train[i, int(mn_inv_maps[i][j])] = train_marginals[i][j]\n",
    "Y_train = Y_train.tocsr()\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:\n",
    "\n",
    "We train the SSI model using the training marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cid_sets = [set([cd.sid_to_cid[sid] for sid in cd.term_to_sids[t] if sid in cd.sid_to_cid]) for t in cd.pos_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from entity_norm import SSIModel\n",
    "\n",
    "model = SSIModel(D_pos, cid_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "\t2750Iteration: 1\n",
      "\t2750Iteration: 2\n",
      "\t2750Iteration: 3\n",
      "\t2750Iteration: 4\n",
      "\t2750Iteration: 5\n",
      "\t2750Iteration: 6\n",
      "\t750"
     ]
    }
   ],
   "source": [
    "%time model.train(X_train, Y_train, rate=1e-2, n_iter=10, n_iter_sample=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_dev           = L_gold_dev.shape[0]\n",
    "dev_pos_phrases = []\n",
    "dev_pos_labels  = []\n",
    "for i in range(N_dev):\n",
    "    if yp_d_dev[i] > 0:\n",
    "        dev_pos_phrases.append(dev[i].disease.get_span().lower())\n",
    "        dev_pos_labels.append(L_gold_dev[i,0])\n",
    "        \n",
    "X_dev = cd_vectorizer.vectorize_phrases(dev_pos_phrases)\n",
    "X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_pos_dev = sum([1 for i in range(L_gold_dev.shape[0]) if L_gold_dev[i,0] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_labels = np.array([L_gold_train[i,0] for i in nz_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_pos_train_pred = sum([1 for p in predicted if p > 0])\n",
    "N_pos_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_f1s   = []\n",
    "train_f1s = []\n",
    "dev_f1s   = []\n",
    "for W, b in zip(model.Ws, model.bs):\n",
    "    prec, recall, f1_g = get_set_scores(model, X_train, predicted, N_pos_train_pred, W=W, b=b, display=False)\n",
    "    gen_f1s.append(f1_g)\n",
    "    prec, recall, f1_t = get_set_scores(model, X_train, train_pos_labels, N_pos_train, W=W, b=b, display=False)\n",
    "    train_f1s.append(f1_t)\n",
    "    prec, recall, f1_d = get_set_scores(model, X_dev, dev_pos_labels, N_pos_dev, W=W, b=b, display=False)\n",
    "    dev_f1s.append(f1_d)\n",
    "    print f1_g, f1_t, f1_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iters = range(len(model.Ws))\n",
    "plt.plot(iters, gen_f1s)\n",
    "plt.plot(iters, train_f1s)\n",
    "plt.plot(iters, dev_f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902286902287 0.651492757907 0.616645824649\n",
      "0.90887040887 0.652379544783 0.612477421148\n",
      "0.910256410256 0.650901566657 0.613033208281\n",
      "0.913374913375 0.645580845403 0.605807975545\n",
      "0.9158004158 0.644989654153 0.606085869112\n",
      "0.916493416493 0.644989654153 0.606363762679\n",
      "0.916146916147 0.643511676027 0.607475336946\n",
      "0.917186417186 0.643807271652 0.607475336946\n",
      "0.920997920998 0.642033697901 0.606363762679\n",
      "0.921690921691 0.644102867278 0.605252188412\n"
     ]
    }
   ],
   "source": [
    "gen_f1s   = []\n",
    "train_f1s = []\n",
    "dev_f1s   = []\n",
    "for W, b in zip(model.Ws, model.bs):\n",
    "    prec, recall, f1_g = get_set_scores(model, X_train, predicted, N_pos_train_pred, W=W, b=b, display=False)\n",
    "    gen_f1s.append(f1_g)\n",
    "    prec, recall, f1_t = get_set_scores(model, X_train, train_pos_labels, N_pos_train, W=W, b=b, display=False)\n",
    "    train_f1s.append(f1_t)\n",
    "    prec, recall, f1_d = get_set_scores(model, X_dev, dev_pos_labels, N_pos_dev, W=W, b=b, display=False)\n",
    "    dev_f1s.append(f1_d)\n",
    "    print f1_g, f1_t, f1_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fab2e2ce750>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF09JREFUeJzt3WtsXOd95/HvcIakRVFXW5FqSbEa17Vjt0hTF6qwSZrZ\nxnCUblIHeeM6RbFpCsMoajTpIo1XBQqzKNqNUQRpgN0FhMRJs1s3CprLrhdtfAs8iXO1tPU1sQTJ\nthJKtuSLIsnUheLMnL54zogzoyHPGV40o4ffD3BwLs/zDB9R1O+c+Z/DEUiSJEmSJEmSJEmSJEmS\nJC1Z24G9wH7grg7ta4BvAE8BPwJuaGo7CDwNPAE8vqizlCR1pQgcALYAg8CTwFvb+vwd8Jfp9rXA\nI01tLwJrF3eKkqROBjLatxIC/iAwBewCbmnr81bg0XR7H+FksK6pvTDfSUqSupcV8BuB8ab9Q+mx\nZk8BH0q3twJXAZvS/YRwRb8HuH1eM5UkdaWU0Z7keI1PAZ8l1NmfSde1tO2dwEuEK/qHCbX8x+Y0\nU0lSV7IC/jCwuWl/M+EqvtkbwEeb9l8EXki3X0rXrxJuxG6lLeCvvvrq5Pnnn+9iypIk4Hngl2br\nkFWi2QNcQ6irDwG3Ave39VmVtkEow3wbmABGgBXp8eXAzYQr/NYZPv88SZL01XL33Xf3fA6Xyryc\nk3NaCvPqxzkBV2fkd+YVfBW4E3iQ8ETNvcBzwB1p+07geuAfCOWcZ4E/StvWE67aG1/nPuChrAlJ\nkhZGVsADfDNdmu1s2v4B4fHIdi8CvzbHeUmS5imrRLMklcvlXk+ho36cl3PKxznl14/z6sc55dEP\nz6gnaT1JkpRToVCAjAz3Cl6SImXAS1KkDHhJipQBL0mRMuAlKVIGvCRFyoCXpEgZ8JIUKQNekiJl\nwEtSpAx4SYpUnk+TlKTo1etw8iT8/OfTy/HjYT05CbVa9lKt5uu3EEseftiYpGhMTU2HcntIt2+3\n7588CaOjsGZNWFavnl5fdhkUi/mWUil/3/ks11+f/WFjBrykvpEkcPbszCGctX/2bGswN8I6z/7K\nlSGcLxV5Pk3SgFcUkiS8jT51Kv/b6YVY8r4lTxIoFGBgoH/WEOZfrYYr38a6eTtrvdB9p6bC3OYS\n0KtXw4oV4c+3FBjw6huNK7PTp0MInzo1vd3pWJ7t9mOlEixfDkNDF+9tct6vUyiE70GShFpvP6yT\nJMx/cHDm9WxtCzGm07Hh4V7/tF4aDHjNSb0eQvONN0Jd8uTJ1u3m/YmJfEF9+nT4xzsyEkK4sZ7P\ndvuxS+nttTRfBvwS0rhCzhPKWdsTE7BsWXi7u3Ll9NK8v2JFWEZH8wWyASwtLAP+IqvX4dy5sExO\nTm/nXWYbMzkZgne2gC4WOwdxt9srVoTXktS/DPgMU1Nw+DCMj7cuR460hm3esK7VQv1waKjzMltb\nnjGjo7OHsrVLaelY0gFfq8HLL18Y3uPjcOhQWL/2GmzYAJs2webN08sv/EIoUeQN3sbSuJkmSYtt\noQJ+O/D3QBH4PHBPW/sa4AvAW4CzwEeBH+ccC3MI+HodXnll5uBuXIVffnlrcLcvGzZYF5Z0aVqI\ngC8C+4CbgMPAbuA24LmmPn8HnAT+GrgW+B9p/zxjoS3gkwRef33m4B4fD2WVlStnD+8rrwxX1ZIU\nozwBn3X9uhU4ABxM93cBt9Aa0m8FPpVu7wO2AG8Crs4xFoCPfKQ1zIeHLwzsm28O602bwrJsWcbM\nJWmJywr4jcB40/4h4Dfb+jwFfAj4LuGEcBWwKedYAN71rtYwHx3N/weQJHWWFfB5iuOfAj4LPAE8\nk65rOccCMD4+xnh6KiiXy5TL5bxDJWlJqFQqVCqVrsZk1eC3AWOEm6UAO4A6nW+WNrwI/CrwKznH\nRvMcvCRdLHlq8Fn/4cce4BpCXX0IuBW4v63PqrQN4Hbg28BEzrGSpEWSVaKpAncCDxKeirmXcJP0\njrR9J3A98A+EksyzwB9ljJUkXQT98Gs5lmgkqUsLUaKRJF2iDHhJipQBL0mRMuAlKVIGvCRFyoCX\npEgZ8JIUKQNekiJlwEtSpAx4SYqUAS9JkTLgJSlSBrwkRcqAl6RIGfCSFCkDXpIiZcBLUqQMeEmK\nlAEvSZEy4CUpUga8JEXKgJekSBnwkhSpPAG/HdgL7Afu6tB+BfAA8CTwLPCRpraDwNPAE8Dj85in\nJKlLhYz2IrAPuAk4DOwGbgOea+ozBgwDOwhhvw9YD1SBF4EbgWOzfI0kSZI5TF2Slq5CoQAZGZ51\nBb8VOEC4Ep8CdgG3tPV5GViZbq8EXieE+/l55JqtJGlBZQX8RmC8af9QeqzZ54AbgJeAp4CPNbUl\nwCPAHuD2ec1UktSVUkZ7ntrJXxDq72XgauBh4G3AG8A7CFf469Lje4HH2l9gbGzs/Ha5XKZcLuf4\nspK0dFQqFSqVSldjsson2wg19u3p/g6gDtzT1Odfgb8Bvpfuf4twM3ZP22vdDUwAn247bg1ekrq0\nEDX4PcA1wBZgCLgVuL+tz17CTVgIN1evBV4ARoAV6fHlwM3AM7lmLkmat6wSTRW4E3iQ8ETNvYQn\naO5I23cCfwt8kVB/HwA+SXhq5i3A15u+zn3AQws4d0nSLPrhCRdLNJLUpYUo0UiSLlEGvCRFyoCX\npEgZ8JIUKQNekiJlwEtSpAx4SYqUAS9JkTLgJSlSBrwkRcqAl6RIGfCSFCkDXpIiZcBLUqQMeEmK\nlAEvSZEy4CUpUga8JEXKgJekSBnwkhQpA16SImXAS1KkDHhJilSegN8O7AX2A3d1aL8CeAB4EngW\n+EgXYyVJi6SQ0V4E9gE3AYeB3cBtwHNNfcaAYWAHIez3AeuBJMdYgCRJkvn8GSRpySkUCpCR4VlX\n8FuBA8BBYArYBdzS1udlYGW6vRJ4HajmHCtJWiRZAb8RGG/aP5Qea/Y54AbgJeAp4GNdjJUkLZJS\nRnue2slfEOrvZeBq4GHgbd1MYmxs7Px2uVymXC53M1ySolepVKhUKl2NyarBbyPU2Len+zuAOnBP\nU59/Bf4G+F66/y3CDdVSjrFgDV6SurYQNfg9wDXAFmAIuBW4v63PXsKNVAg3V68FXsg5VpK0SLJK\nNFXgTuBBwhM19xKegrkjbd8J/C3wRUL9fQD4JHAsbe80VpJ0EWSVaC4GSzSS1KWFKNFIki5RBrwk\nRcqAl6RIGfCSFCkDXpIiZcBLUqQMeEmKlAEvSZEy4CUpUga8JEXKgJekSBnwkhQpA16SImXAS1Kk\nDHhJipQBL0mRMuAlKVIGvCRFyoCXpEgZ8JIUKQNekiJlwEtSpAx4SYpUnoDfDuwF9gN3dWj/BPBE\nujwDVIHVadtB4Om07fF5zlWS1IVCRnsR2AfcBBwGdgO3Ac/N0P/9wMfT/gAvAjcCx2b5GkmSJHnn\nK0kCCoUCZGR41hX8VuAA4Up8CtgF3DJL/w8DX26fR8bXkCQtgqyA3wiMN+0fSo91MgK8F/ha07EE\neATYA9w+xzlKkuaglNHeTe3kA8B3geNNx94BvAysAx4m1PIfax84NjZ2frtcLlMul7v4spIUv0ql\nQqVS6WpMVvlkGzBGuNEKsAOoA/d06PsN4CuEMk4ndwMTwKfbjluDl6QuLUQNfg9wDbAFGAJuBe7v\n0G8V8FvA/206NgKsSLeXAzcTnrKRJF0EWSWaKnAn8CDhiZp7CU/Q3JG270zXH0z7nGkau55wVd/4\nOvcBD81/ypKkPPrhCRdLNJLUpYUo0UiSLlEGvCRFyoCXpEgZ8JIUKQNekiJlwEtSpAx4SYqUAS9J\nkTLgJSlSBrwkRcqAl6RIGfCSFCkDXpIiZcBLUqQMeEmKlAEvSZEy4CUpUga8JEXKgJekSBnwkhQp\nA16SImXAS1KkDHhJilSegN8O7AX2A3d1aP8E8ES6PANUgdU5x0qSFkkho70I7ANuAg4Du4HbgOdm\n6P9+4ONp/7xjkyRJ5jJ3SVqyCoUCZGR41hX8VuAAcBCYAnYBt8zS/8PAl+c4VpK0gLICfiMw3rR/\nKD3WyQjwXuBrcxgrSVpgpYz2bmonHwC+CxzvduzY2Nj57XK5TLlc7uLLSlL8KpUKlUqlqzFZNfht\nwBjhZinADqAO3NOh7zeArxBKMd2MtQYvSV3KU4PPCvgS4Ubpe4CXgMfpfKN0FfACsAk40+VYA16S\nupQn4LNKNFXgTuBBwlMx9xIC+o60fWe6/mDa50yOsZKkiyDrCv5i8Apekrq0EI9JSpIuUQa8JEXK\ngJekSBnwkhQpA16SImXAS1KkDHhJipQBL0mRMuAlKVIGvCRFyoCXpEgZ8JIUKQNekiJlwEtSpAx4\nSYqUAS9JkTLgJSlSBrwkRcqAl6RIGfCSFCkDXpIiZcBLUqQMeEmKVJ6A3w7sBfYDd83Qpww8ATwL\nVJqOHwSeTtsen+McJUlzUMhoLwL7gJuAw8Bu4DbguaY+q4HvAe8FDgFXAK+lbS8CNwLHZvkaSZIk\nXU98vpIkoZbUqNar1Oph3VjqSZ3B4iDDxWGGikMMFYcoFLK+VZJ08aSZNGswlTJeYytwgHAlDrAL\nuIXWgP8w8DVCuMN0uJ+fR9ZE/+yBP2sJ2GpSbdlvD+D2pRHUM7Z3GF9LahQLRYoDRUoDpZalQIGp\n+hTnaueYrE4yVZ9icGCQ4VII/Ebwz7R/wbGBmfvmfa3h0jDrRtZx+cjlDBSsrEnKlhXwG4Hxpv1D\nwG+29bkGGAQeBVYAnwX+d9qWAI8ANWAn8LlOX+TNq958Qcg2lk4B3NJeyGifYXyxUMx9VZ4kCedq\n50Lg1ybPB/989o+fPX5hn1nGnqme4bXTr3Fy8iRXjFzBhtENrF++nvWj69mwfAPrR9ezfvn6cHw0\nrNcuW+vJQFrCsgI+T+1kEPh14D3ACPAD4IeEmv07gZeAdcDDhFr+Y+0vcOLBE+e3y+Uy5XI5x5e9\neAqFAsOlcBW9ghU9ncu52jlePfUqRyaOcPTUUY5OHOXIxBF+duJn7H5pdzg+cZSjp45ycvIk60bW\nnQ/98yeAxokh3d4wuoE1y9Z4MpD6WKVSoVKpdDUm6xJ2GzBGuNEKsAOoA/c09bkLWJb2A/g88ADw\n1bbXuhuYAD7ddrwnNfil4FztHK+ceuX8SaD5hHD0VDgJNE4IE+cmWLd8Xa53BmsuW+M9CanH8tTg\ns/6Vlgg3Wd9DuBJ/nAtvsl4H/HfCTdZh4EfArYS6fRF4A1gOPAT8VbpuZsD3gcnqZDgZtJ8EJo5y\n5NT0u4IjE0c4PXWadSPrWD+6npHBEYqFIgOFAYoD6bppv1PbBf267Z/RVqDQdyegAoXM+y6z3Yvx\n3ZXaLcRN1ipwJ/AgIazvJYT7HWn7TkLZ5QHC45B1Qp39J8BbgK83fZ37uDDc1SeGS8NsXrWZzas2\nZ/ZtPhmcmTpDPalTS2rU6rXz2/WkTq1ea9meb79ztXOZ/Wr1GkmuyuLFVUtqTNWmct+jaT9WGijN\n6SZ9y8mjww38JEmoJ3USEpIkISHd77Dd3jfvuFlfg9a2hIShgSEuK13WsgyXhi88VuxwrEO/Xp0g\nkyRhsjbJmakznKmeybU+PXW6c1uHY3n0w2WOV/DSLJIkoVqvLtgN/uZjA4UBCoXC+Xc9A4WBjtsF\nCi19Z9qe62s0+gLn53e2erZlmazlPNY2drI2yVBxqLuTQ7F1v1qvtgZwjsA+Wz1LaaDEstIylg0u\ny1yPlEZy9Wusb7zyRphnieZiMOAlLZrGU3BzPTmcrZ6lWCiGEB4cyR3Ay0rLKA4UF+3PtRA1+IvB\ngJekLuUJeO/cSFKkDHhJipQBL0mRMuAlKVIGvCRFyoCXpEgZ8JIUKQNekiJlwEtSpAx4SYqUAS9J\nkTLgJSlSBrwkRSrrP/y4OL7/fVi7dnop9ce0JOlS1h8fF7xtGxw7Bq+/DsePw/LlIegvv3w69Gfa\nbuyvWeOJQdKScWl+Hny9DidPhrA/dmx6ad7vtN04MXRzUli79tI4MSRJWAasqEkKLs2An6tOJ4aZ\ntttPDKOjrcG/cmV4zVotvO5M69naFrIPQKEAb3oTbNkCV10V1o3lqqvCsnz5/L+Pki4JSyvg56pe\nhxMnWoP/xIlwtTwwAMXi7Os8fbrpO9Oxeh2OHIGDB8Py05+2bv/0p7BixYUngMb2VVeFdklRMOCX\nknodXnnlwvBv3h8Z6Rz+je1Vq3o2fUndMeA1LUng1VdnDv+DB2FwsHP4N/ZXrw6lIi2+JAnluamp\nC5dqtfPxbvs0yn/9plgMP4uzLaXS3PsUi1H8HC9UwG8H/h4oAp8H7unQpwx8BhgEXkv384414PtB\nkoQS1Uzhf/Bg+EfRXvcfGZm+CZwk4Z3EfPYX4jXyvOZ8js1lXL3efSgPDCx8uPV70M12Yluok1y9\nvrDfz6zxizS2sGYNzDPgi8A+4CbgMLAbuA14rqnPauB7wHuBQ8AVhJDPMzb8lfZZwFcqFcrlcq+n\ncYGezitJwg3ptvCvvPAC5Y0bQ1AMDIR1Y+l2f4Feo7J/P+Xrruvu68x1PjmPVZ56ivLWrd0FySI/\nNbVkf86bT7Z5ThRTU1T27KF8ww3dn2yyXn8eYwsnT0JGhmc9H7gVOAAcTPd3AbfQGtIfBr5GCHcI\n4Z53bF9asj/4sykUwiOla9bA298+PaexMcpjY72Z0wwqY2OU//iPez2NFpVHH6W8bVuvp9Fiyf6c\nDwzA8HBY8s7pW9+ifPPNizenucjx7ivrEmEjMN60fyg91uwaYC3wKLAH+IMuxkqSFknWFXye2skg\n8OvAe4AR4AfAD3OOlSQtkqxr/G3AGOFmKcAOoE7rzdK7gGVpPwg3Ux8gXLFnjYVQxrm624lL0hL3\nPPBL83mBUvoiW4Ah4EngrW19rgMeIdxUHQGeAa7POVaS1EPvIzwNc4BwFQ5wR7o0fAL4MSHc/zRj\nrCRJkqRL1XZgL7CfUMvvtS8ARwnvRPrFZsITSj8GnqX1HVKvXAb8iFB2+wnw33o7nRZF4Ang//V6\nIk0OAk8T5vV4b6dy3mrgq4THln9CuN/WS9cSvj+N5QT98bO+g+nqxD8B+Z+tXDwfI8zn2XS7LxUJ\npZsthCdx+qFG/y7g7fRXwG8Afi3dHiWUvHr9fYJwvwXCvZYfAu/s4Vya/RfgPuD+Xk+kyYuER4n7\nyZeAj6bbJaCfPohoAHiZcHHTS1uAF5gO9a8A/7lnswl+hZBPlxEy9GFmeUillx8w3vyLUFNM/yJU\nLz0G/LzHc2h3hHDyA5ggXHFd2bvpnHc6XQ8RftCO9XAuDZuA3yE8ydVnv4PfV/NZRbiY+UK6XyVc\nMfeLmwgPaIxndVxkJwnZNEI4CY4Qfiu/l64jvHs+C9SAbwMfmqlzLwPeX4Tq3hbCO4wf9XgeEH52\nniSUtB4lvM3vtc8Af054HLefJIQnzfYAt/d4LgC/CLwKfBH4N+BzTL8j6we/RyiH9Nox4NPAz4CX\ngOOEv8deepZwcl5L+Dv7T4QLm456GfD+IlR3Rgk1048RruR7rU4oHW0CfovpD5jrlfcDrxDqt/10\ntQzwDsKJ+X3AnxD+gfZSifDLif8zXZ8C/mtPZzRtCPgA8M+9ngih9PFxwoXVlYR/g7/fywkR7lne\nAzwEfJPw8z7jBU0vA/4wrTW2zUx/no1aDRI+7+cfgf/T47m0OwH8C/AbPZ7HfwB+l1Dv/jLw28D/\n6umMpr2crl8FvkEoT/bSoXTZne5/lRD0/eB9wP8nfK967TeA7wOvE8pYXyf8nPXaFwhzezfhXcW+\n3k6ns379Ragt9NdN1gIhqD7T64k0uYLwFAaE32L+DuGjKvrFu+mfp2hGgMZ/pbWc8Mmr/fCpVd8B\nfjndHqPzR3n3wi56fyOz4W2Eksgywr/DLxHegfXam9L1mwn35Fb2cC6z6rdfhPoyodY2Sbg/8Ie9\nnQ4Qnk6pE06AjUfIts86YvH9KqF2+yTh8b8/7+10LvBu+ucpml8kfJ+eJIRFP/ycQwiv3cBThCvT\nfniKZjnh02j76f+W/CTTj0l+ifBuute+Q5jTk8B/7PFcJEmSJEmSJEmSJEmSJEmSJEmSJGl2/w7c\nfjI2BenJCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab2df743d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = range(len(model.Ws))\n",
    "plt.plot(iters, gen_f1s)\n",
    "plt.plot(iters, train_f1s)\n",
    "plt.plot(iters, dev_f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "I = sparse.identity(X_train.shape[1], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.890003459011\n",
      "R:\t0.894645340751\n",
      "F1:\t0.8923183631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.890003459010723, 0.8946453407510431, 0.8923183631003989)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_set_scores(model, X_train, predicted, N_pos_train_pred, W=I, b=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.75717744725\n",
      "R:\t0.565633074935\n",
      "F1:\t0.647537346546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7571774472500865, 0.5656330749354005, 0.647537346546369)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_set_scores(model, X_train, train_pos_labels, N_pos_train, W=I, b=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.690721649485\n",
      "R:\t0.556086519115\n",
      "F1:\t0.616134875296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6907216494845361, 0.5560865191146881, 0.6161348752960847)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_set_scores(model, X_dev, dev_pos_labels, N_pos_dev, W=I, b=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3976, 271513)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8191)\t1.0\n",
      "set([2040])\n",
      "2040.0\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print X_dev.getrow(i)\n",
    "print model.predict(X_dev.getrow(i))\n",
    "print dev_pos_labels[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_set_scores(model, X, X_labels, N_pos, W=None, b=None, display=True):\n",
    "    predicted = 0\n",
    "    correct   = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        yp = model.predict(X.getrow(i), W=W, b=b)\n",
    "        if yp is not None:\n",
    "            predicted += 1\n",
    "        \n",
    "            # NOTE: we assume we're doing disambiguation perfectly here!!!\n",
    "            if X_labels[i] in yp:\n",
    "                correct += 1\n",
    "\n",
    "    prec   = correct / float(predicted)\n",
    "    recall = correct / float(N_pos)\n",
    "    f1     = (2 * prec * recall) / (prec +  recall)\n",
    "    if display:\n",
    "        print \"P:\\t\", prec\n",
    "        print \"R:\\t\", recall\n",
    "        print \"F1:\\t\", f1\n",
    "    return prec, recall, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
