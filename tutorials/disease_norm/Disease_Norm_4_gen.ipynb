{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Norm\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* diseases from Pubmed abstracts, using annotations from the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial, which has 5 parts, walks through the process of constructing a model to classify _candidate_ disease mentions as either true (i.e., that it is truly a mention of a disease) or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of action:\n",
    "\n",
    "Two types of LFs:\n",
    "1. TYPE I: Leveraging sources of WS (e.g. DS)\n",
    "2. TYPE II: Expressing heuristics (e.g. magnifying user effort)\n",
    "\n",
    "TYPE I:\n",
    "- Need to break up MESH into subtrees and have each one be an LF!\n",
    "- Need to provide negative signal\n",
    "\n",
    "TYPE II:\n",
    "- Conduct \"simulated expert\" experiment: go through, label examples, write LFs- what is the effective multiplier over binary labeling??\n",
    "    * E.g. \"renal failure\"; add {\"renal\" -> \"kidney\"} to synonym map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30067\n",
      "29853\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "print len(train)\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()\n",
    "print len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30067, 1)\n",
      "(29853, 1)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "\n",
    "L_gold_train = label_manager.load(session, train, \"CDR Training Label Set\")\n",
    "print L_gold_train.shape\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")\n",
    "print L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing some multinomial LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPE I LF: Subsets of MESH dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28472 entries\n"
     ]
    }
   ],
   "source": [
    "from cPickle import load\n",
    "from utils import load_mesh_raw\n",
    "\n",
    "MESH_to_CID = load(open('MESH_to_CID.pkl', 'rb'))\n",
    "mesh_entries = load_mesh_raw('data/desc2017.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MESH exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_tree = defaultdict(list)\n",
    "for entry in mesh_entries:\n",
    "    mid, tree_nums, terms = entry\n",
    "    for tn in tree_nums:\n",
    "        path = [tn[0]] + tn[1:].split(\".\")\n",
    "        for term in terms:\n",
    "            mesh_tree[term].append((mid, path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmenting MESH with UMLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mid_to_paths = defaultdict(list)\n",
    "for entry in mesh_entries:\n",
    "    mid, tree_nums, terms = entry\n",
    "    for tn in tree_nums:\n",
    "        path = [tn[0]] + tn[1:].split(\".\")\n",
    "        mid_to_paths[mid].append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231583"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mesh_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('cui2mesh.tsv', 'rb') as f:\n",
    "    for line in f:\n",
    "        term, cui, mid = line.rstrip('\\n').split('\\t')\n",
    "        for path in mid_to_paths[mid]:\n",
    "            x = (mid, path)\n",
    "            if x not in mesh_tree[term]:\n",
    "                mesh_tree[term].append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478507"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mesh_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS_DEPTH = 2\n",
    "NEG_DEPTH = 1\n",
    "\n",
    "def LFG_MESH_exact(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    if p in mesh_tree:\n",
    "        seen = set()\n",
    "        for mid, path in mesh_tree[p]:\n",
    "            value = MESH_to_CID[mid] if path[0] in ['C', 'F'] else -1\n",
    "            key   = \"_\".join(path[:POS_DEPTH]) if value > 0 else \"_\".join(path[:NEG_DEPTH])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                yield key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 28s, sys: 15.9 s, total: 1min 44s\n",
      "Wall time: 1min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<30067x41 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 9454 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Training Labels -- MESH + UMLS Exact + Cosine', f=LFG_MESH_exact)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD if already computed\n",
    "L_train = label_manager.load(session, train, 'LF Training Labels -- MESH Exact + Cosine')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MESH TF-IDF cosine match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 49753\n",
      "CPU times: user 2min 54s, sys: 1.02 s, total: 2min 55s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from entity_norm import CanonDictVectorizer\n",
    "\n",
    "# Compile all terms into one dictionary\n",
    "all_diseases = {}\n",
    "for term, entries in mesh_tree.iteritems():\n",
    "    if len(entries) > 0:\n",
    "        mid, path = entries[0]  # Hack: should take the most frequent?\n",
    "        all_diseases[term] = mid\n",
    "\n",
    "# Create a vectorizer based around this \n",
    "cd_vectorizer = CanonDictVectorizer(all_diseases, other_phrases=[])\n",
    "\n",
    "# Vectorize the dictionary\n",
    "disease_phrases = []\n",
    "disease_cids    = []\n",
    "for term, mid in all_diseases.iteritems():\n",
    "    disease_phrases.append(term)\n",
    "    disease_cids.append(mid)   \n",
    "D  = cd_vectorizer.vectorize_phrases(disease_phrases)\n",
    "Dt = D.T\n",
    "Dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49754x478503 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1202586 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh_tree_index = []\n",
    "for dp in disease_phrases:\n",
    "    mesh_tree_index.append(mesh_tree[dp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESH = 0.75\n",
    "\n",
    "def LFG_MESH_cosine(c):\n",
    "    \n",
    "    # Vectorize the phrase\n",
    "    p  = c.disease.get_span().lower()\n",
    "    cx = cd_vectorizer.vectorize_phrases([p])\n",
    "    m  = cx * Dt\n",
    "    \n",
    "    # Keep track of the highest-score match so far _for each LF_\n",
    "    highest_score = defaultdict(float)\n",
    "    \n",
    "    # Iterate over non-zero dictionary term matches > THRESH\n",
    "    for i, j in zip(*m.nonzero()):\n",
    "        s = m[i,j]\n",
    "        if s > THRESH:\n",
    "            for entry in mesh_tree_index[j]:\n",
    "                mid, path = entry\n",
    "                \n",
    "                # We define each LF by a tree path code\n",
    "                key = \"_\".join(path[:2]) + \"_cosine\"\n",
    "                \n",
    "                # Only yield this value if higher than highest current emitted\n",
    "                # Note: This will just update the current value in the DB\n",
    "                if s > highest_score[key]:\n",
    "                    highest_score[key] = s\n",
    "                    yield key, MESH_to_CID[mid] if path[0] in ['C', 'F'] else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 54min 15s, sys: 1min 31s, total: 55min 46s\n",
      "Wall time: 55min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<30067x155 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 55855 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = label_manager.update(session, train, 'LF Training Labels -- MESH + UMLS Exact + Cosine', True, LFG_MESH_cosine)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD if already computed\n",
    "L_train = label_manager.load(session, train, 'LF Training Labels -- MESH Exact + Cosine')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running gen. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def binarize_LF_matrix(X):\n",
    "    X_b = lil_matrix(X.shape)\n",
    "    for i, j in zip(*X.nonzero()):\n",
    "        X_b[i,j] = np.sign(X[i,j])\n",
    "    return X_b.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_score(predicted, gold):\n",
    "    tp = 0\n",
    "    pp = 0\n",
    "    p  = 0\n",
    "    for i in range(gold.shape[0]):\n",
    "        if gold[i] > 0:\n",
    "            p += 1\n",
    "        \n",
    "        if predicted[i] == 1:\n",
    "            pp += 1\n",
    "            if gold[i] > 0:\n",
    "                tp += 1\n",
    "    \n",
    "    prec   = tp / float(pp)\n",
    "    recall = tp / float(p)\n",
    "    f1     = (2*prec*recall) / (prec+recall)\n",
    "    print \"P :\\t\", prec\n",
    "    print \"R :\\t\", recall\n",
    "    print \"F1:\\t\", f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30067x155 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 55855 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train_b = binarize_LF_matrix(L_train)\n",
    "L_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t30067\n",
      "Features:\t\t\t155\n",
      "================================================================================\n",
      "CPU times: user 18.9 s, sys: 57.8 ms, total: 18.9 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "%time gen_model.train(L_train_b, n_iter=10000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.672828740844\n",
      "R :\t0.496780839557\n",
      "F1:\t0.571555555556\n"
     ]
    }
   ],
   "source": [
    "yp = gen_model.predict(L_train_b)\n",
    "get_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.737365368683\n",
      "R :\t0.458408447077\n",
      "F1:\t0.565348578688\n"
     ]
    }
   ],
   "source": [
    "yp = gen_model.predict(L_train_b)\n",
    "get_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.798275862069\n",
      "R :\t0.357713108421\n",
      "F1:\t0.49404232616\n"
     ]
    }
   ],
   "source": [
    "yp = gen_model.predict(L_train_b)\n",
    "get_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import odds_to_prob\n",
    "\n",
    "L_dev.lf_stats(labels=L_gold_dev, est_accs=odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yp = gen_model.predict(L_dev_b)\n",
    "get_score(yp, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.utils import matrix_accuracy\n",
    "\n",
    "eaccs = matrix_accuracy(L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import odds_to_prob\n",
    "\n",
    "L_dev.lf_stats(labels=L_gold_dev, est_accs=odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30067"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPs: 938\n",
      "FNs: 1954\n"
     ]
    }
   ],
   "source": [
    "fps = []\n",
    "fns = []\n",
    "for i,c in enumerate(train):\n",
    "    if L_gold_train[i] < 0 and yp[i] > 0:\n",
    "        fps.append(c)\n",
    "    elif L_gold_train[i] > 0 and yp[i] <= 0:\n",
    "        fns.append(c)\n",
    "print \"FPs:\", len(fps)\n",
    "print \"FNs:\", len(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "shuffle(fps)\n",
    "shuffle(fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index the gold MESH IDs\n",
    "CID_to_MESH = {}\n",
    "for mid, cid in MESH_to_CID.iteritems():\n",
    "    CID_to_MESH[cid] = mid\n",
    "    \n",
    "mesh_label_by_candidate_id = {}\n",
    "for i, c in enumerate(train):\n",
    "    l = int(L_gold_train[i,0])\n",
    "    mesh_label_by_candidate_id[c.id] = CID_to_MESH[l] if l > 0 else l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_to_terms = defaultdict(set)\n",
    "for term, entries in mesh_tree.iteritems():\n",
    "    for entry in entries:\n",
    "        mid, path = entry\n",
    "        mesh_to_terms[mid].add(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"jupyter-js-widgets\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "sv = SentenceNgramViewer(fns[:100], session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments to run:\n",
    "* Clean up!\n",
    "* Partial matches (first k words)\n",
    "* TF-IDF at various thresholds\n",
    "* Split dictionary more!\n",
    "* Remove JJ?\n",
    "* **NEED TO CORRECT FOR GOLD ANNOTATIONS NOT IN OUR CANDIDATE SET!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disease(Span(\"advanced encephalopathy\", parent=1242, chars=[17,39], words=[3,4]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = sv.get_selected()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D001927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BRAIN DIS',\n",
       " 'Brain Disease',\n",
       " 'Brain Diseases',\n",
       " 'Brain Disorder',\n",
       " 'Brain Disorders',\n",
       " 'CNS DIS INTRACRANIAL',\n",
       " 'CNS Disorder, Intracranial',\n",
       " 'CNS Disorders, Intracranial',\n",
       " 'CNS INTRACRANIAL DIS',\n",
       " 'Central Nervous System Disorders, Intracranial',\n",
       " 'Central Nervous System Intracranial Disorders',\n",
       " 'ENCEPHALON DIS',\n",
       " 'Encephalon Disease',\n",
       " 'Encephalon Diseases',\n",
       " 'INTRACRANIAL CNS DIS',\n",
       " 'Intracranial CNS Disorder',\n",
       " 'Intracranial CNS Disorders',\n",
       " 'Intracranial Central Nervous System Disorders',\n",
       " 'brain disease',\n",
       " 'brain diseases',\n",
       " 'brain disorder',\n",
       " 'brain disorders',\n",
       " 'central nervous system disorders, intracranial',\n",
       " 'central nervous system intracranial disorders',\n",
       " 'cns disorder, intracranial',\n",
       " 'cns disorders, intracranial',\n",
       " 'encephalon disease',\n",
       " 'encephalon diseases',\n",
       " 'encephalopathies',\n",
       " 'encephalopathy',\n",
       " 'intracranial central nervous system disorders',\n",
       " 'intracranial cns disorder',\n",
       " 'intracranial cns disorders'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid = mesh_label_by_candidate_id[sv.get_selected().id]\n",
    "print mid\n",
    "mesh_to_terms[mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(LFG_MESH_exact(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(LFG_MESH_cosine(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* Looking at FNs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Creating Features\n",
    "Recall that our goal is to distinguish between true and false mentions of chemical-disease relations. To train a model for this task, we first embed our `ChemicalDisease` candidates in a feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 18min 58s, sys: 23.3 s, total: 19min 22s\n",
      "Wall time: 19min 8s\n"
     ]
    }
   ],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Train Features 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.load(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the `scipy.sparse.csr_matrix` class, with some special features which we demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30067x72203 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1230157 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 11min 2s, sys: 30.3 s, total: 11min 32s\n",
      "Wall time: 11min 19s\n"
     ]
    }
   ],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features 3', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train.get_candidate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train.get_key(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t17361\n",
      "Features:\t\t\t72203\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 12033.728202\tGradient magnitude = 8418.569490\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 3574.614580\tGradient magnitude = 1667.630374\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 2788.945606\tGradient magnitude = 462.129656\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 2609.218558\tGradient magnitude = 37.593165\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 2525.500892\tGradient magnitude = 31.789598\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 2469.144214\tGradient magnitude = 27.994361\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 2428.639760\tGradient magnitude = 25.295902\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 2398.222866\tGradient magnitude = 23.281157\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 2374.639587\tGradient magnitude = 21.724859\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 2355.904544\tGradient magnitude = 20.491736\n",
      "\tLearning epoch = 1000\tStep size = 0.000367695424771\n",
      "\tLoss = 2340.734435\tGradient magnitude = 19.495169\n",
      "\tLearning epoch = 1100\tStep size = 0.000332687932862\n",
      "\tLoss = 2328.261813\tGradient magnitude = 18.676981\n",
      "\tLearning epoch = 1200\tStep size = 0.000301013429093\n",
      "\tLoss = 2317.878742\tGradient magnitude = 17.996614\n",
      "\tLearning epoch = 1300\tStep size = 0.000272354586819\n",
      "\tLoss = 2309.146093\tGradient magnitude = 17.424869\n",
      "\tLearning epoch = 1400\tStep size = 0.000246424291385\n",
      "\tLoss = 2301.738987\tGradient magnitude = 16.940223\n",
      "\tLearning epoch = 1500\tStep size = 0.000222962763703\n",
      "\tLoss = 2295.411062\tGradient magnitude = 16.526422\n",
      "\tLearning epoch = 1600\tStep size = 0.000201734957697\n",
      "\tLoss = 2289.972756\tGradient magnitude = 16.170966\n",
      "\tLearning epoch = 1700\tStep size = 0.000182528205523\n",
      "\tLoss = 2285.275430\tGradient magnitude = 15.864088\n",
      "\tLearning epoch = 1800\tStep size = 0.000165150086984\n",
      "\tLoss = 2281.201061\tGradient magnitude = 15.598042\n",
      "\tLearning epoch = 1900\tStep size = 0.000149426501798\n",
      "\tLoss = 2277.654473\tGradient magnitude = 15.366593\n",
      "\tLearning epoch = 2000\tStep size = 0.000135199925397\n",
      "\tLoss = 2274.558322\tGradient magnitude = 15.164665\n",
      "\tLearning epoch = 2100\tStep size = 0.00012232783079\n",
      "\tLoss = 2271.848949\tGradient magnitude = 14.988100\n",
      "\tLearning epoch = 2200\tStep size = 0.000110681260672\n",
      "\tLoss = 2269.473630\tGradient magnitude = 14.833451\n",
      "\tLearning epoch = 2300\tStep size = 0.000100143535489\n",
      "\tLoss = 2267.388230\tGradient magnitude = 14.697835\n",
      "\tLearning epoch = 2400\tStep size = 9.06090844946e-05\n",
      "\tLoss = 2265.555502\tGradient magnitude = 14.578825\n",
      "\tLearning epoch = 2500\tStep size = 8.19823881078e-05\n",
      "\tLoss = 2263.943867\tGradient magnitude = 14.474364\n",
      "\tLearning epoch = 2600\tStep size = 7.41770209616e-05\n",
      "\tLoss = 2262.526435\tGradient magnitude = 14.382697\n",
      "\tLearning epoch = 2700\tStep size = 6.71147860624e-05\n",
      "\tLoss = 2261.280033\tGradient magnitude = 14.302322\n",
      "\tLearning epoch = 2800\tStep size = 6.07249313844e-05\n",
      "\tLoss = 2260.184705\tGradient magnitude = 14.231941\n",
      "\tLearning epoch = 2900\tStep size = 5.49434410507e-05\n",
      "\tLoss = 2259.223250\tGradient magnitude = 14.170436\n",
      "\tLearning epoch = 3000\tStep size = 4.9712393998e-05\n",
      "\tLoss = 2258.380700\tGradient magnitude = 14.116831\n",
      "\tLearning epoch = 3100\tStep size = 4.49793837036e-05\n",
      "\tLoss = 2257.643964\tGradient magnitude = 14.070286\n",
      "\tLearning epoch = 3200\tStep size = 4.06969931571e-05\n",
      "\tLoss = 2257.001462\tGradient magnitude = 14.030055\n",
      "\tLearning epoch = 3300\tStep size = 3.68223198197e-05\n",
      "\tLoss = 2256.443098\tGradient magnitude = 13.995492\n",
      "\tLearning epoch = 3400\tStep size = 3.33165458113e-05\n",
      "\tLoss = 2255.960000\tGradient magnitude = 13.966029\n",
      "\tLearning epoch = 3500\tStep size = 3.01445490191e-05\n",
      "\tLoss = 2255.544313\tGradient magnitude = 13.941154\n",
      "\tLearning epoch = 3600\tStep size = 2.72745512307e-05\n",
      "\tLoss = 2255.189150\tGradient magnitude = 13.920441\n",
      "\tLearning epoch = 3700\tStep size = 2.46777997696e-05\n",
      "\tLoss = 2254.888265\tGradient magnitude = 13.903506\n",
      "\tLearning epoch = 3800\tStep size = 2.23282794396e-05\n",
      "\tLoss = 2254.636180\tGradient magnitude = 13.890003\n",
      "\tLearning epoch = 3900\tStep size = 2.02024518955e-05\n",
      "\tLoss = 2254.427998\tGradient magnitude = 13.879632\n",
      "\tLearning epoch = 4000\tStep size = 1.82790198275e-05\n",
      "\tLoss = 2254.259375\tGradient magnitude = 13.872129\n",
      "\tLearning epoch = 4100\tStep size = 1.65387135968e-05\n",
      "\tLoss = 2254.126422\tGradient magnitude = 13.867258\n",
      "\tLearning epoch = 4200\tStep size = 1.49640981858e-05\n",
      "\tLoss = 2254.025625\tGradient magnitude = 13.864818\n",
      "\tLearning epoch = 4300\tStep size = 1.35393985271e-05\n",
      "\tLoss = 2253.953874\tGradient magnitude = 13.864628\n",
      "\tLearning epoch = 4400\tStep size = 1.2250341464e-05\n",
      "\tLoss = 2253.908386\tGradient magnitude = 13.866533\n",
      "\tLearning epoch = 4500\tStep size = 1.10840127561e-05\n",
      "\tLoss = 2253.886608\tGradient magnitude = 13.870397\n",
      "\tLearning epoch = 4600\tStep size = 1.00287277002e-05\n",
      "\tLoss = 2253.886299\tGradient magnitude = 13.876107\n",
      "\tLearning epoch = 4700\tStep size = 9.0739140687e-06\n",
      "\tLoss = 2253.905421\tGradient magnitude = 13.883569\n",
      "\tLearning epoch = 4800\tStep size = 8.21000619294e-06\n",
      "\tLoss = 2253.942193\tGradient magnitude = 13.892640\n",
      "\tLearning epoch = 4900\tStep size = 7.42834913113e-06\n",
      "\tLoss = 2253.994947\tGradient magnitude = 13.903311\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "train_marginals = gen_model.marginals(L_train_b)\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=5000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.669799008092\n",
      "R :\t0.66082925573\n",
      "F1:\t0.665283899404\n"
     ]
    }
   ],
   "source": [
    "yp = disc_model.predict(F_train)\n",
    "get_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.728406610539\n",
      "R :\t0.60159670358\n",
      "F1:\t0.658956276446\n"
     ]
    }
   ],
   "source": [
    "yp = disc_model.predict(F_train)\n",
    "get_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.692197360872\n",
      "R :\t0.603853853854\n",
      "F1:\t0.645014701951\n"
     ]
    }
   ],
   "source": [
    "yp = disc_model.predict(F_dev)\n",
    "get_score(yp, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.754307374225\n",
      "R :\t0.547797797798\n",
      "F1:\t0.634676717889\n"
     ]
    }
   ],
   "source": [
    "yp = disc_model.predict(F_dev)\n",
    "get_score(yp, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "0. _DONE: Add negative labels to candidates..._\n",
    "1. _DONE: Get empirical LF accs up and running..._\n",
    "2. _DONE: Binarize LFs + run in binary gen model_\n",
    "0. _DONE: Add TF-IDF matching LFs_\n",
    "3. _DONE: Add in simple DDLIB + WS feats from new-features -> run disc. model_\n",
    "2. **Conduct TYPE II \"experiment\"!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Labeling Functions\n",
    "Labeling functions are a core tool of data programming. They are heuristic functions that aim to classify candidates correctly. Their outputs will be automatically combined and denoised to estimate the probabilities of training labels for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from lf_terms import *\n",
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load some publicly-available biomedical dictionaries, which we will leverage in some of our LFs below as a source of weak supervision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "umls_dict              = load_umls_dictionary()\n",
    "chemicals              = load_chemdner_dictionary()\n",
    "abbrv2text, text2abbrv = load_specialist_abbreviations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document-Level Labeling Functions\n",
    "We start with some labeling functions that label candidates based on document-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_doc_candidate_spans\n",
    "\n",
    "def LF_undefined_abbreviation(c):\n",
    "    '''Candidate is a known abbreviation, but no corresponding full name in document'''\n",
    "    doc_spans = get_doc_candidate_spans(c)\n",
    "    phrase = c[0].get_span().lower()\n",
    "    mentions = set([s.get_span().lower() for s in doc_spans])\n",
    "    if len(phrase) > 1 and phrase in abbrv2text and not set(abbrv2text[phrase].keys()).intersection(mentions):\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence-Level Labeling Functions\n",
    "We also include some labeling functions that label candidates based on sentence-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_sent_candidate_spans\n",
    "\n",
    "def LF_contiguous_mentions(c):\n",
    "    '''Contiguous candidates are likely wrong'''\n",
    "    neighbor_spans = get_sent_candidate_spans(c)\n",
    "    start, end = c[0].get_word_start(), c[0].get_word_end()\n",
    "    for s in neighbor_spans:\n",
    "        if s.get_word_end() + 1 == start or s.get_word_start() - 1 == end:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mention-Level Labeling Functions\n",
    "We now define a number of labeling functions that label candidates based on attributes related to the mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens\n",
    "\n",
    "def LF_tumors_growths(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"^(\\w* ){0,2}(['] )*(tumor|tumour|polyp|pilomatricoma|cyst|lipoma)$\", phrase) else 0\n",
    "\n",
    "def LF_cancer(c):\n",
    "    '''<TYPE> cancer'''\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"\\w* cancer\",phrase) else 0\n",
    "\n",
    "def LF_disease_syndrome(c):\n",
    "    '''<TYPE> disease or <TYPE> syndrome'''\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"\\w* (disease|syndrome)+\",phrase) else 0\n",
    "\n",
    "def LF_indicators(c):\n",
    "    '''Indicator words'''\n",
    "    return 1 if \" \".join(c[0].get_attrib_tokens()).lower() in indicators else 0\n",
    "\n",
    "def LF_common_disease(c):\n",
    "    '''Common disease'''\n",
    "    return 1 if \" \".join(c[0].get_attrib_tokens()).lower() in common_disease else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For a few more examples of LFs of this style that we'll use, see [Disease_Tagging_Tutorial_LFs.py](Disease_Tagging_Tutorial_LFs.py).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary Labeling Functions\n",
    "We can use existing dictionaries for distant supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_SNOWMED_CT_sign_or_symptom(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"snomedct\"][\"sign_or_symptom\"] else 0\n",
    "\n",
    "def LF_SNOWMED_CT_disease_or_syndrome(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"snomedct\"][\"disease_or_syndrome\"] else 0\n",
    "\n",
    "def LF_MESH_disease_or_syndrome(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"mesh\"][\"disease_or_syndrome\"] else 0\n",
    "\n",
    "def LF_MESH_sign_or_symptom(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"mesh\"][\"sign_or_symptom\"] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Labeling Functions\n",
    "When writing labeling functions, it is important to provide negative supervision in addition to positive supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_organs(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in organs else 0      \n",
    "\n",
    "def LF_chemical_name(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens())\n",
    "    return -1 if phrase in chemicals and not phrase.isupper() else 0\n",
    "\n",
    "def LF_bodysym(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in bodysym else 0  \n",
    "\n",
    "def LF_protein_chemical_abbrv(c):\n",
    "    '''Gene/protein/chemical name'''\n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"\\d+\",lemma) else 0\n",
    "\n",
    "def LF_base_pair_seq(c): \n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"^[GACT]{2,}$\",lemma) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For a few more examples of LFs of this style that we'll use, see [Disease_Tagging_Tutorial_LFs.py](Disease_Tagging_Tutorial_LFs.py).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maintain a list of all LFs for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Disease_Tagging_Tutorial_LFs import *\n",
    "\n",
    "LFs_doc = [LF_undefined_abbreviation]\n",
    "\n",
    "LFs_sent = [LF_contiguous_mentions]\n",
    "\n",
    "LFs_mention = [LF_tumors_growths,\n",
    "               LF_cancer,\n",
    "               LF_disease_syndrome,\n",
    "               LF_indicators,\n",
    "               LF_common_disease,\n",
    "               LF_common_disease_acronyms,\n",
    "               LF_deficiency_of,\n",
    "               LF_positive_indicator,\n",
    "               LF_left_positive_argument,\n",
    "               LF_right_negative_argument,\n",
    "               LF_medical_afixes,\n",
    "               LF_adj_diseases\n",
    "              ]\n",
    "\n",
    "LFs_dicts =  [LF_SNOWMED_CT_sign_or_symptom,\n",
    "              LF_SNOWMED_CT_disease_or_syndrome,\n",
    "              LF_MESH_disease_or_syndrome,\n",
    "              LF_MESH_sign_or_symptom\n",
    "            ]\n",
    "\n",
    "LFs_false = [LF_chemical_name,\n",
    "             LF_organs,\n",
    "             LF_bodysym,\n",
    "             LF_protein_chemical_abbrv,\n",
    "             LF_base_pair_seq,\n",
    "             LF_too_vague,\n",
    "             LF_neg_surfix,\n",
    "             LF_non_common_disease,\n",
    "             LF_non_disease_acronyms,\n",
    "             LF_pos_in,\n",
    "             LF_gene_chromosome_link,\n",
    "             LF_right_window_incomplete,\n",
    "             LF_negative_indicator\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Labeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct a `CandidateLabeler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the `CandidateLabeler` to to apply the labeling functions to the training `CandidateSet`.  We'll start with some of our labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LFs = LFs_mention + LFs_dicts + LFs_false\n",
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** load if we've already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.load(session, train, 'LF Labels')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add or rerun a single labeling function (or more!) with the below command. Note that we set the argument `expand_key_set` to `True` to indicate that the set of matrix columns should be allowed to expand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs_2   = LFs_doc + LFs_sent\n",
    "L_train = label_manager.update(session, train, 'LF Labels', True, f=LFs_2)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view statistics about the resulting label matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Generative Model\n",
    "We estimate the accuracies of the labeling functions without supervision. Specifically, we estimate the parameters of a `NaiveBayes` generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.save(session, 'Generative Params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model\n",
    "We use the estimated probabilites to train a discriminative model that classifies each `Candidate` as a true or false mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=5000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc_model.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Development `CandidateSet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create features for the development set.\n",
    "\n",
    "Note that we use the training features feature set, because those are the only features for which we have learned parameters. Features that were not encountered during training, e.g., a token that does not appear in the training set, are ignored, because we do not have any information about them.\n",
    "\n",
    "To do so with the `FeatureManager`, we call update with the new `CandidateSet`, the name of the training `AnnotationKeySet`, and the value `False` for the parameter `extend_key_set` to indicate that the `AnnotationKeySet` should not be expanded with new `Feature` keys encountered during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the development set labels and gold candidates we made in Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Labels -- Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_dev_set = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the discriminative model on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_dev, L_gold_dev, gold_dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Examples\n",
    "After evaluating on the development `CandidateSet`, the labeling functions can be modified. Try changing the labeling functions to improve performance. You can view the true positives, false positives, true negatives, and false negatives using the `Viewer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# NOTE: This if-then statement is only to avoid opening the viewer during automated testing of this notebook\n",
    "# You should ignore this!\n",
    "import os\n",
    "if 'CI' not in os.environ:\n",
    "    sv = SentenceNgramViewer(tp, session, annotator_name=\"Tutorial Part IV User\")\n",
    "else:\n",
    "    sv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part V, we will test our model on the test `CandidateSet`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
