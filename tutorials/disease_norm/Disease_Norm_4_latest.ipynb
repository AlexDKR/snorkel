{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Norm\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* diseases from Pubmed abstracts, using annotations from the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial, which has 5 parts, walks through the process of constructing a model to classify _candidate_ disease mentions as either true (i.e., that it is truly a mention of a disease) or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Candidates + Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28087\n",
      "27896\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "print len(train)\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()\n",
    "print len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1)\n",
      "(27896, 1)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "\n",
    "L_gold_train = label_manager.load(session, train, \"CDR Training Label Set\")\n",
    "print L_gold_train.shape\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")\n",
    "print L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process / Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 18min 32s, sys: 18.3 s, total: 18min 50s\n",
      "Wall time: 18min 38s\n"
     ]
    }
   ],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 13min 29s, sys: 21.1 s, total: 13min 50s\n",
      "Wall time: 13min 38s\n"
     ]
    }
   ],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, load if already processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.load(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MESH ID -> CID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cPickle import load\n",
    "MESH_to_CID = load(open('MESH_to_CID.pkl', 'rb'))\n",
    "diseases    = load(open('diseases.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh_to_terms = defaultdict(set)\n",
    "for term, mid in diseases.iteritems():\n",
    "    mesh_to_terms[mid].add(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a canonical dictionary (CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import CanonicalDictionary\n",
    "cd = CanonicalDictionary(MESH_to_CID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MESH to CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 27885 entries\n"
     ]
    }
   ],
   "source": [
    "# Load MESH\n",
    "from utils import load_mesh_raw\n",
    "mesh_entries = load_mesh_raw('data/desc2016.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151006"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add MESH to cd\n",
    "for entry in mesh_entries:\n",
    "    mid, ps, terms = entry\n",
    "    paths = [[p[0]] + p[1:].split('.') for p in ps]\n",
    "    for term in terms:\n",
    "        cd.add_term(term, mid, tree_paths=paths)\n",
    "\n",
    "len(cd.term_to_sids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MEDIC to CD\n",
    "\n",
    "Custom CTD diseases dictionary made from MESH category C + OMIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11864 MEDIC entries\n"
     ]
    }
   ],
   "source": [
    "from utils import load_MEDIC, load_mesh_raw\n",
    "medic_entries, MEDIC_to_CID = load_MEDIC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add MESH to cd\n",
    "for entry in medic_entries:\n",
    "    if entry.id.startswith(\"MESH\"):\n",
    "        mid = entry.id.split(\":\")[1]\n",
    "    elif len(entry.parent_ids) > 0 and entry.parent_ids[0].startswith(\"MESH\"):\n",
    "        mid = entry.parent_ids[0].split(\":\")[1]\n",
    "    else:\n",
    "        raise KeyError(entry)\n",
    "    \n",
    "    paths = []\n",
    "    for p in entry.tree_nums:\n",
    "        x = p.split(\"/\")[0]\n",
    "        paths.append([x[0]] + x[1:].split('.'))\n",
    "    \n",
    "    terms = [entry.name] + entry.synonyms\n",
    "    for term in terms:\n",
    "        cd.add_term(term, mid, tree_paths=paths)\n",
    "        \n",
    "len(cd.term_to_sids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add UMLS to CD\n",
    "\n",
    "This may or may not be all of the UMLS... file from Jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801566"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('cui2mesh.tsv', 'rb') as f:\n",
    "    for line in f:\n",
    "        term, cui, mid = line.rstrip('\\n').split('\\t')\n",
    "        cd.add_term(term, mid)\n",
    "\n",
    "len(cd.term_to_sids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cPickle import dump\n",
    "dump(cd, open('cd.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Add MESH supp?  No paths though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing some multinomial LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Beware of LF rollback bug!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPE I LF: Subsets of MESH dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEEN_GLOBAL = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MESH exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS_DEPTH = 3\n",
    "NEG_DEPTH = 3\n",
    "def LFG_CD_match(c, p, key_mod=None, seen_global=None, max_paths_per_sid=1):\n",
    "    \"\"\"\n",
    "    Given a candidate c, some transformed candidate disease phrase p,\n",
    "    and an optional key name modifier key_mod to be appended, return a generator\n",
    "    of key, value pairs\n",
    "    \"\"\"\n",
    "    if p in cd.term_to_sids:\n",
    "        for sid in cd.term_to_sids[p]:\n",
    "            cid   = cd.sid_to_cid[sid] if sid in cd.sid_to_cid else -1\n",
    "            paths = cd.tree_paths[sid]\n",
    "            for path in paths[:max_paths_per_sid]:\n",
    "                    \n",
    "                # NOTE: path may be shorter than max depth if higher up in the tree (e.g. 'cancer', 'ischemia')!\n",
    "                key = \"-\".join(path[:POS_DEPTH]) if cid > 0 else \"-\".join(path[:NEG_DEPTH])\n",
    "                        \n",
    "                # CHECK AGAINST / ADD TO GLOBAL SEEN SET!\n",
    "                # To make sure that relaxations of an LF don't overlap with each other on any given candidate\n",
    "                if seen_global is None or c.id not in seen_global[key]:\n",
    "                    if seen_global is not None:\n",
    "                        seen_global[key].add(c.id)\n",
    "                    if key_mod:\n",
    "                        key += \"-\" + key_mod\n",
    "                    yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LFG_MESH_exact(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return LFG_CD_match(c, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 34s, sys: 18.3 s, total: 1min 52s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x382 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 7688 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_1 = label_manager.create(session, train, 'LF Training Labels 1', f=LFG_MESH_exact)\n",
    "L_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_1 = label_manager.create(session, dev, 'LF Development Labels 1', f=LFG_MESH_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_1 = label_manager.load(session, train, 'LF Training Labels 1')\n",
    "L_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop JJs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MOD_RGX = r'JJ.*|VB.*|RB.*'\n",
    "\n",
    "def LFG_drop_leading_modifiers(c):\n",
    "    words    = c.disease.get_attrib_tokens()\n",
    "    pos_tags = c.disease.get_attrib_tokens('pos_tags')\n",
    "    while re.match(MOD_RGX, pos_tags[0]):\n",
    "        words    = words[1:]\n",
    "        pos_tags = pos_tags[1:]\n",
    "        p   = \" \".join(words)\n",
    "        \n",
    "        # Hackey, but works for now...\n",
    "        g = LFG_CD_match(c, p, key_mod=\"DJ\")\n",
    "        if len(list(g)) > 0:\n",
    "            for key, cid in LFG_CD_match(c, p, key_mod=\"DJ\"):\n",
    "                yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 39s, sys: 19.6 s, total: 1min 59s\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x282 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 3490 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_2 = label_manager.create(session, train, 'LF Training Labels 2', LFG_drop_leading_modifiers)\n",
    "L_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_2 = label_manager.create(session, dev, 'LF Development Labels 2', LFG_drop_leading_modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_2 = label_manager.load(session, train, 'LF Training Labels 2')\n",
    "L_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REMOVE_COMMON = r'.*induced|patient.*|drug|inhibitor|\\d+|human|mouse|mice|rats?|with|syndrome|famil.*|s$|low(er)?|upper|left|right|top|bottom|subjects?'\n",
    "def remove_common(c):\n",
    "    p = re.sub(r'\\s\\s+', ' ', re.sub(REMOVE_COMMON, '', c.disease.get_span().lower())).strip()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFG_MESH_exact_remove_common(c):\n",
    "    p = remove_common(c)\n",
    "    return LFG_CD_match(c, p, key_mod=\"RC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 33s, sys: 17 s, total: 1min 50s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x341 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6033 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_3 = label_manager.create(session, train, 'LF Training Labels 3', LFG_MESH_exact_remove_common)\n",
    "L_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_3 = label_manager.create(session, dev, 'LF Development Labels 3.1', LFG_MESH_exact_remove_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_3 = label_manager.load(session, train, 'LF Training Labels 3')\n",
    "L_train_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MESH TF-IDF cosine match: POSITIVE terms\n",
    "\n",
    "Only cosine match with _positive_ (i.e. C, F03 MESH disease terms) here!\n",
    "\n",
    "**Note: we want to avoid positive reinforcement amongst these, so track seen / only emit one:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEEN_COSINE_POS = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 271512\n",
      "CPU times: user 1min 25s, sys: 1.66 s, total: 1min 27s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from entity_norm import CanonDictVectorizer \n",
    "\n",
    "# Create a vectorizer based around this \n",
    "cd_vectorizer = CanonDictVectorizer(cd.term_to_sids, other_phrases=[])\n",
    "\n",
    "# Vectorize the dictionary\n",
    "D_pos   = cd_vectorizer.vectorize_phrases(cd.pos_terms)\n",
    "D_pos_t = D_pos.T\n",
    "D_pos_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POS_DEPTH = 3\n",
    "NEG_DEPTH = 3\n",
    "THRESH    = 0.75\n",
    "def LFG_CD_cosine_match(c, p, vectorizer, D_t, terms, thresh=THRESH, seen_global=None, max_paths_per_sid=1, key_mod=None):\n",
    "    cx = vectorizer.vectorize_phrases([p])\n",
    "    m  = cx * D_t\n",
    "    m  = m.tocoo()\n",
    "\n",
    "    best_match = defaultdict(lambda : (0, None))\n",
    "    for i, s in enumerate(m.data):\n",
    "        if s > thresh:\n",
    "            j = m.col[i]\n",
    "            t = terms[j]\n",
    "            for sid in cd.term_to_sids[t]:\n",
    "                cid = cd.sid_to_cid[sid] if sid in cd.sid_to_cid else -1\n",
    "                for path in cd.tree_paths[sid][:max_paths_per_sid]:\n",
    "                    key  = \"-\".join(path[:POS_DEPTH]) if cid > 0 else \"-\".join(path[:NEG_DEPTH])\n",
    "                    if s > best_match[key][0]:\n",
    "                        best_match[key] = (s, cid)\n",
    "\n",
    "    for key, x in best_match.iteritems():\n",
    "        s, cid = x\n",
    "        \n",
    "        # CHECK AGAINST / ADD TO GLOBAL SEEN SET!\n",
    "        # To make sure that relaxations of an LF don't overlap with each other on any given candidate\n",
    "        if seen_global is None or c.id not in seen_global[key]:\n",
    "            if seen_global is not None:\n",
    "                seen_global[key].add(c.id)\n",
    "            key += \"-c\"\n",
    "            if key_mod:\n",
    "                key += key_mod\n",
    "            yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFG_CD_cosine_match_pos(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return LFG_CD_cosine_match(c,p, cd_vectorizer, D_pos_t, cd.pos_terms, seen_global=SEEN_COSINE_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 3min 47s, sys: 21.8 s, total: 4min 9s\n",
      "Wall time: 3min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x150 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5745 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_4 = label_manager.create(session, train, 'LF Training Labels 4.1', LFG_CD_cosine_match_pos)\n",
    "L_train_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_4 = label_manager.create(session, dev, 'LF Development Labels 4', LFG_CD_cosine_match_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_4 = label_manager.load(session, train, 'LF Training Labels 4')\n",
    "L_train_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -> pos. cosine match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFG_CD_cosine_match_DJ(c):\n",
    "    words    = c.disease.get_attrib_tokens()\n",
    "    pos_tags = c.disease.get_attrib_tokens('pos_tags')\n",
    "    while re.match(MOD_RGX, pos_tags[0]):\n",
    "        words    = words[1:]\n",
    "        pos_tags = pos_tags[1:]\n",
    "        p   = \" \".join(words)\n",
    "        \n",
    "        # Very hackey, but works for now...\n",
    "        g = LFG_CD_cosine_match(c, p, cd_vectorizer, D_pos_t, cd.pos_terms, key_mod=\"-DJ\", seen_global=SEEN_COSINE_POS)\n",
    "        if len(list(g)) > 0:\n",
    "            for key, cid in LFG_CD_cosine_match(c, p, cd_vectorizer, D_pos_t, cd.pos_terms, key_mod=\"-DJ\", seen_global=SEEN_COSINE_POS):\n",
    "                yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 2min 30s, sys: 17.4 s, total: 2min 48s\n",
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x0 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_4_T1 = label_manager.create(session, train, 'LF Training Labels 4 T1', LFG_CD_cosine_match_DJ)\n",
    "L_train_4_T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_train_4_T1 = label_manager.create(session, train, 'LF Training Labels 4 T1', LFG_CD_cosine_match_DJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_4_T1 = label_manager.create(session, dev, 'LF Development Labels 4 T1', LFG_CD_cosine_match_DJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFG_CD_cosine_match_RC(c):\n",
    "    p = remove_common(c)\n",
    "    if p != c.disease.get_span().lower():\n",
    "        for key, cid in LFG_CD_cosine_match(c, p, cd_vectorizer, D_pos_t, cd.pos_terms, key_mod=\"-RC\", seen_global=SEEN_COSINE_POS):\n",
    "            yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 2min 13s, sys: 16.9 s, total: 2min 29s\n",
      "Wall time: 2min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x69 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 451 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_4_T2 = label_manager.create(session, train, 'LF Training Labels 4 T2', LFG_CD_cosine_match_RC)\n",
    "L_train_4_T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_4_T2 = label_manager.create(session, dev, 'LF Development Labels 4 T2', LFG_CD_cosine_match_RC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neg cosine match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<271513x737772 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2508478 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the dictionary\n",
    "D_neg   = cd_vectorizer.vectorize_phrases(cd.neg_terms)\n",
    "D_neg_t = D_neg.T\n",
    "D_neg_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFG_CD_cosine_match_neg(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return LFG_CD_cosine_match(c, p, cd_vectorizer, D_neg_t, cd.neg_terms, thresh=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 25min 30s, sys: 2min 43s, total: 28min 13s\n",
      "Wall time: 27min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x406 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 11389 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_4_N = label_manager.create(session, train, 'LF Training Labels 4 N', LFG_CD_cosine_match_neg)\n",
    "L_train_4_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_4_N = label_manager.create(session, dev, 'LF Development Labels 4 N', LFG_CD_cosine_match_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting in some negative LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from lf_terms import *\n",
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens\n",
    "from utils import *\n",
    "from Disease_Tagging_Tutorial_LFs import *\n",
    "chemicals = load_chemdner_dictionary()\n",
    "\n",
    "def LF_organs(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in organs else 0      \n",
    "\n",
    "def LF_chemical_name(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens())\n",
    "    return -1 if phrase in chemicals and not phrase.isupper() and phrase.lower() not in cd.term_to_sids else 0\n",
    "\n",
    "def LF_bodypart(c):\n",
    "    phrase = re.sub(r's$', '', \" \".join(c[0].get_attrib_tokens()).lower())\n",
    "    return -1 if phrase in bodypart else 0  \n",
    "\n",
    "def LF_protein_chemical_abbrv(c):\n",
    "    '''Gene/protein/chemical name'''\n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"\\d+\",lemma) else 0\n",
    "\n",
    "def LF_base_pair_seq(c): \n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"^[GACT]{2,}$\",lemma) else 0\n",
    "\n",
    "LFs_false = [LF_chemical_name,\n",
    "             LF_organs,\n",
    "             LF_bodypart,\n",
    "             LF_protein_chemical_abbrv,\n",
    "             LF_base_pair_seq,\n",
    "             #LF_too_vague,\n",
    "             #LF_neg_surfix,\n",
    "             LF_non_common_disease,\n",
    "             LF_non_disease_acronyms,\n",
    "             #LF_pos_in,\n",
    "             LF_gene_chromosome_link,\n",
    "             LF_right_window_incomplete,\n",
    "             #LF_negative_indicator\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 4min 12s, sys: 15.8 s, total: 4min 28s\n",
      "Wall time: 4min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x9 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2768 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_5 = label_manager.create(session, train, 'LF Training Labels 5', LFs_false)\n",
    "L_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_5 = label_manager.create(session, dev, 'LF Development Labels 5', LFs_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_5 = label_manager.load(session, train, 'LF Training Labels 5.1')\n",
    "L_train_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More neg. LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NEG_COMMON_RGX = r'(finding|disease|syndrome|marker|defecit|.*event|mean|median|mg)s?'\n",
    "def LF_common_neg_phrases(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return -1 if re.match(NEG_COMMON_RGX, p) else 0\n",
    "\n",
    "NEG_AFTER_WORDS = frozenset(['of', 'to'])\n",
    "def LF_neg_after(c):\n",
    "    rw = get_right_tokens(c, window=1, attrib='lemmas')\n",
    "    return -1 if len(rw) > 0 and rw[0] in NEG_AFTER_WORDS and c.disease.get_span().lower() not in cd.term_to_sids else 0\n",
    "\n",
    "def LF_after_num(c):\n",
    "    lw = get_left_tokens(c, window=1, attrib='lemmas')\n",
    "    return -1 if len(lw) > 0 and re.match(r'\\d+', lw[0]) else 0\n",
    "\n",
    "def LF_too_short(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return -1 if len(p) < 3 else 0\n",
    "\n",
    "BAD_ENDINGS_RGX = r'(type|trait|cell)s?$'\n",
    "def LF_bad_endings(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return -1 if re.search(BAD_ENDINGS_RGX, p) else 0\n",
    "\n",
    "BAD_MESH_TERMS = frozenset(['disease', 'diseases', 'conversion'])\n",
    "def LF_bad_MESH_entries(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return -1 if p in BAD_MESH_TERMS else 0\n",
    "\n",
    "LFs_false_2 = [\n",
    "    LF_common_neg_phrases,\n",
    "    LF_neg_after,\n",
    "    LF_after_num,\n",
    "    LF_too_short,\n",
    "    LF_bad_endings,\n",
    "    LF_bad_MESH_entries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 3min 12s, sys: 15.6 s, total: 3min 28s\n",
      "Wall time: 3min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x6 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 7946 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_6 = label_manager.create(session, train, 'LF Training Labels 6', LFs_false_2)\n",
    "L_train_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n"
     ]
    }
   ],
   "source": [
    "L_dev_6 = label_manager.create(session, dev, 'LF Development Labels 6', LFs_false_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running gen. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28087x1645 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 45510 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import binarize_LF_matrix, get_binarized_score\n",
    "from snorkel.annotations import merge_annotations\n",
    "\n",
    "L_train = merge_annotations([\n",
    "        L_train_1\n",
    "        , L_train_2\n",
    "        , L_train_3\n",
    "        , L_train_4\n",
    "        #, L_train_4_T1\n",
    "        , L_train_4_T2\n",
    "        , L_train_4_N\n",
    "        , L_train_5\n",
    "        , L_train_6\n",
    "    ])\n",
    "\n",
    "L_train_b = binarize_LF_matrix(L_train)\n",
    "L_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t28087\n",
      "Features:\t\t\t1645\n",
      "================================================================================\n",
      "Begin training for rate=0.1, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.075126\n",
      "\tLearning epoch = 250\tGradient mag. = 0.095146\n",
      "\tLearning epoch = 500\tGradient mag. = 0.115617\n",
      "\tLearning epoch = 750\tGradient mag. = 0.142812\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.148422\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.137011\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.136266\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.137535\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.133239\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.129043\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.124353\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.120547\n",
      "\tLearning epoch = 3000\tGradient mag. = 0.117536\n",
      "\tLearning epoch = 3250\tGradient mag. = 0.113501\n",
      "\tLearning epoch = 3500\tGradient mag. = 0.109784\n",
      "\tLearning epoch = 3750\tGradient mag. = 0.105936\n",
      "\tLearning epoch = 4000\tGradient mag. = 0.102319\n",
      "\tLearning epoch = 4250\tGradient mag. = 0.099151\n",
      "\tLearning epoch = 4500\tGradient mag. = 0.094547\n",
      "\tLearning epoch = 4750\tGradient mag. = 0.091691\n",
      "\tLearning epoch = 5000\tGradient mag. = 0.089294\n",
      "\tLearning epoch = 5250\tGradient mag. = 0.086317\n",
      "\tLearning epoch = 5500\tGradient mag. = 0.083406\n",
      "\tLearning epoch = 5750\tGradient mag. = 0.080705\n",
      "\tLearning epoch = 6000\tGradient mag. = 0.077940\n",
      "\tLearning epoch = 6250\tGradient mag. = 0.075398\n",
      "\tLearning epoch = 6500\tGradient mag. = 0.073211\n",
      "\tLearning epoch = 6750\tGradient mag. = 0.071359\n",
      "\tLearning epoch = 7000\tGradient mag. = 0.069471\n",
      "\tLearning epoch = 7250\tGradient mag. = 0.067821\n",
      "\tLearning epoch = 7500\tGradient mag. = 0.066299\n",
      "\tLearning epoch = 7750\tGradient mag. = 0.064810\n",
      "\tLearning epoch = 8000\tGradient mag. = 0.063435\n",
      "\tLearning epoch = 8250\tGradient mag. = 0.062181\n",
      "\tLearning epoch = 8500\tGradient mag. = 0.061064\n",
      "\tLearning epoch = 8750\tGradient mag. = 0.059892\n",
      "\tLearning epoch = 9000\tGradient mag. = 0.058352\n",
      "\tLearning epoch = 9250\tGradient mag. = 0.056667\n",
      "\tLearning epoch = 9500\tGradient mag. = 0.055347\n",
      "\tLearning epoch = 9750\tGradient mag. = 0.054255\n",
      "Final gradient magnitude for rate=0.1, mu=1e-06: 0.053\n",
      "CPU times: user 22.4 s, sys: 121 ms, total: 22.5 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model_train = NaiveBayes()\n",
    "%time gen_model_train.train(L_train_b, n_iter=10000, rate=1e-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.862817089453\n",
      "R :\t0.667958656331\n",
      "F1:\t0.75298572677\n"
     ]
    }
   ],
   "source": [
    "yp_gt_train = gen_model_train.predict(L_train_b, b=0.5)\n",
    "get_binarized_score(yp_gt_train, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print LF stats...\n",
    "from snorkel.learning import odds_to_prob\n",
    "lfs = L_train.lf_stats(labels=L_gold_train, est_accs=odds_to_prob(gen_model.w))\n",
    "lfs.nlargest(50, \"coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis\n",
    "_F1=63_\n",
    "\n",
    "ROUND 1:\n",
    "* _DONE: Take out 'F' category? [6]_\n",
    "* _DONE: Take out supplemental entries [2]_\n",
    "* _DONE: Don't emit all tree paths?  **This essentially gives many more votes if it has multiple tree paths!!!** [3]_\n",
    "\n",
    "**_--> F1=69_**\n",
    "\n",
    "ROUND 2:\n",
    "* _DONE: Take out LF-negative-indicator: no longer appropriate here! [1]_\n",
    "* _DONE: Common transforms [3]_\n",
    "* _DONE: Remove leading VB(N|D) also! [2]_\n",
    "* _DONE: Iterate over all JJs removed; stop at first (longest) match [2]_\n",
    "* _DONE: Try \"no reinforcing deps\" setting where we avoid the positive reinforcement of cascading overlap?_\n",
    "\n",
    "**_--> F1=72_**\n",
    "\n",
    "ROUND 3:\n",
    "* _DONE: Negative cosine matches tend to have super-high weight... **take these out??**_\n",
    "    - _**In particular, we match e.g. the disease + associated proteins, body parts, etc...**_\n",
    "    - _We are missing some **exact matches**...!!!  Just override model here?_\n",
    "    - _Or, add multiple threshs again for cosine match (e.g. milk fever case...)?_\n",
    "* _DONE: Weird words in chemicals dictionary (\"hepatitis\", \"leprosy\")? Take chemicals - diseases instead? [2]_\n",
    "\n",
    "**_--> F1=73_**\n",
    "\n",
    "ROUND 4:\n",
    "* _DONE: `LF-neg-after` is broken! [2]_\n",
    "* _DONE: Try to avoid `LF-after-num` errors by checking for exact match [2]_\n",
    "* _DONE: Try running transforms through vector matcher as well?_\n",
    "\n",
    "**_--> F1=74_**\n",
    "\n",
    "ROUND 5:\n",
    "* Positive reinforcement between vector transform matches seems to be an issue... [2]\n",
    "* Check for the word before \"X (Y)\" [1]\n",
    "\n",
    "\n",
    "#### Other ideas:\n",
    "* \"C-induced D\", \"C D\": explicitly create LF for this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "N_train = L_gold_train.shape[0]\n",
    "\n",
    "fps    = []\n",
    "fns    = []\n",
    "fns_na = []\n",
    "for i in range(N_train):\n",
    "    if yp[i] > 0 and L_gold_train[i] < 0:\n",
    "        fps.append(i)\n",
    "    elif yp[i] <= 0 and L_gold_train[i] > 0:\n",
    "        if yp[i] == 0:\n",
    "            fns_na.append(i)\n",
    "        else:\n",
    "            fns.append(i)\n",
    "\n",
    "shuffle(fps)\n",
    "shuffle(fns)\n",
    "shuffle(fns_na)\n",
    "\n",
    "print len(fps)\n",
    "print len(fns)\n",
    "print len(fns_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "fp_cands = [L_train.get_candidate(i) for i in fps[:100]]\n",
    "svp      = SentenceNgramViewer(fp_cands, session)\n",
    "svp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = svp.get_selected()\n",
    "print c\n",
    "print c.disease.get_attrib_tokens('pos_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "[stemmer.stem(w) for w in c.disease.get_attrib_tokens()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Label\n",
    "session.query(Label).filter(Label.candidate == c).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.gen_learning import odds_to_prob\n",
    "i = L_train.get_row_index(c)\n",
    "\n",
    "for j in L_train.getrow(i).nonzero()[1]:\n",
    "    print L_train.get_key(j), odds_to_prob(gen_model.w[j]), int(L_train[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_to_terms[cd.cid_to_sid[755]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESH            = 0.75\n",
    "def vector_matches(p, Dt, vectorizer, thresh=THRESH):\n",
    "    cx  = cd_vectorizer.vectorize_phrases([p])\n",
    "    m   = cx * Dt\n",
    "    m   = m.tocoo()\n",
    "    out = []\n",
    "    for i, s in enumerate(m.data):\n",
    "        if s > THRESH:\n",
    "            j    = m.col[i]\n",
    "            t    = cd.pos_terms[j]\n",
    "            sids = cd.term_to_sids[t]\n",
    "            out.append((s, j, t, sids))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find most common words\n",
    "word_fs = [(len(cids), word) for word, cids in cd_vectorizer.word_to_cids.iteritems()]\n",
    "word_fs.sort(key=lambda x : -x[0])\n",
    "word_fs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running gen. model: Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<27896x1557 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 44845 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import binarize_LF_matrix, get_binarized_score\n",
    "from snorkel.annotations import merge_annotations\n",
    "\n",
    "L_dev = merge_annotations([\n",
    "        L_dev_1\n",
    "        , L_dev_2\n",
    "        , L_dev_3\n",
    "        , L_dev_4\n",
    "        #, L_dev_4_T1\n",
    "        , L_dev_4_T2\n",
    "        , L_dev_4_N\n",
    "        , L_dev_5\n",
    "        , L_dev_6\n",
    "    ])\n",
    "\n",
    "L_dev_b = binarize_LF_matrix(L_dev)\n",
    "L_dev_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t27896\n",
      "Features:\t\t\t1557\n",
      "================================================================================\n",
      "Begin training for rate=0.1, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.077622\n",
      "\tLearning epoch = 250\tGradient mag. = 0.097931\n",
      "\tLearning epoch = 500\tGradient mag. = 0.117168\n",
      "\tLearning epoch = 750\tGradient mag. = 0.141006\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.157745\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.153413\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.149396\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.142963\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.134517\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.127591\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.122599\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.118446\n",
      "\tLearning epoch = 3000\tGradient mag. = 0.113645\n",
      "\tLearning epoch = 3250\tGradient mag. = 0.109864\n",
      "\tLearning epoch = 3500\tGradient mag. = 0.105658\n",
      "\tLearning epoch = 3750\tGradient mag. = 0.102304\n",
      "\tLearning epoch = 4000\tGradient mag. = 0.099610\n",
      "\tLearning epoch = 4250\tGradient mag. = 0.097014\n",
      "\tLearning epoch = 4500\tGradient mag. = 0.094186\n",
      "\tLearning epoch = 4750\tGradient mag. = 0.091380\n",
      "\tLearning epoch = 5000\tGradient mag. = 0.088431\n",
      "\tLearning epoch = 5250\tGradient mag. = 0.084175\n",
      "\tLearning epoch = 5500\tGradient mag. = 0.080532\n",
      "\tLearning epoch = 5750\tGradient mag. = 0.078004\n",
      "\tLearning epoch = 6000\tGradient mag. = 0.076076\n",
      "\tLearning epoch = 6250\tGradient mag. = 0.074496\n",
      "\tLearning epoch = 6500\tGradient mag. = 0.073219\n",
      "\tLearning epoch = 6750\tGradient mag. = 0.072016\n",
      "\tLearning epoch = 7000\tGradient mag. = 0.070583\n",
      "\tLearning epoch = 7250\tGradient mag. = 0.069142\n",
      "\tLearning epoch = 7500\tGradient mag. = 0.067768\n",
      "\tLearning epoch = 7750\tGradient mag. = 0.066507\n",
      "\tLearning epoch = 8000\tGradient mag. = 0.065417\n",
      "\tLearning epoch = 8250\tGradient mag. = 0.064415\n",
      "\tLearning epoch = 8500\tGradient mag. = 0.063398\n",
      "\tLearning epoch = 8750\tGradient mag. = 0.062321\n",
      "\tLearning epoch = 9000\tGradient mag. = 0.061075\n",
      "\tLearning epoch = 9250\tGradient mag. = 0.059870\n",
      "\tLearning epoch = 9500\tGradient mag. = 0.058730\n",
      "\tLearning epoch = 9750\tGradient mag. = 0.057652\n",
      "Final gradient magnitude for rate=0.1, mu=1e-06: 0.057\n",
      "CPU times: user 22.4 s, sys: 106 ms, total: 22.5 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model_dev = NaiveBayes()\n",
    "%time gen_model_dev.train(L_dev_b, n_iter=10000, rate=1e-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.848303393214\n",
      "R :\t0.641348088531\n",
      "F1:\t0.730449727872\n"
     ]
    }
   ],
   "source": [
    "yp_gd_dev = gen_model_dev.predict(L_dev_b, b=0.5)\n",
    "get_binarized_score(yp_gd_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t20038\n",
      "Features:\t\t\t69885\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 13889.283204\tGradient magnitude = 9831.201766\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 3049.872338\tGradient magnitude = 365.791692\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 2926.206468\tGradient magnitude = 1374.522873\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 2493.111263\tGradient magnitude = 293.460134\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 2393.886256\tGradient magnitude = 31.987879\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 2336.523571\tGradient magnitude = 28.337040\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 2294.764978\tGradient magnitude = 25.766155\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 2263.040483\tGradient magnitude = 23.838157\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 2238.207216\tGradient magnitude = 22.339846\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 2218.323199\tGradient magnitude = 21.146131\n",
      "\tLearning epoch = 1000\tStep size = 0.000367695424771\n",
      "\tLoss = 2202.116619\tGradient magnitude = 20.176929\n",
      "\tLearning epoch = 1100\tStep size = 0.000332687932862\n",
      "\tLoss = 2188.717813\tGradient magnitude = 19.378147\n",
      "\tLearning epoch = 1200\tStep size = 0.000301013429093\n",
      "\tLoss = 2177.511082\tGradient magnitude = 18.711788\n",
      "\tLearning epoch = 1300\tStep size = 0.000272354586819\n",
      "\tLoss = 2168.047330\tGradient magnitude = 18.150341\n",
      "\tLearning epoch = 1400\tStep size = 0.000246424291385\n",
      "\tLoss = 2159.991647\tGradient magnitude = 17.673371\n",
      "\tLearning epoch = 1500\tStep size = 0.000222962763703\n",
      "\tLoss = 2153.088505\tGradient magnitude = 17.265375\n",
      "\tLearning epoch = 1600\tStep size = 0.000201734957697\n",
      "\tLoss = 2147.139627\tGradient magnitude = 16.914362\n",
      "\tLearning epoch = 1700\tStep size = 0.000182528205523\n",
      "\tLoss = 2141.988812\tGradient magnitude = 16.610903\n",
      "\tLearning epoch = 1800\tStep size = 0.000165150086984\n",
      "\tLoss = 2137.511148\tGradient magnitude = 16.347497\n",
      "\tLearning epoch = 1900\tStep size = 0.000149426501798\n",
      "\tLoss = 2133.605804\tGradient magnitude = 16.118094\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "train_marginals = gen_model_train.marginals(L_train_b)\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-3, mu=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.84604233111\n",
      "R :\t0.754005167959\n",
      "F1:\t0.797376690805\n"
     ]
    }
   ],
   "source": [
    "yp_d_train = disc_model.predict(F_train)\n",
    "get_binarized_score(yp_d_train, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.837987112611\n",
      "R :\t0.686871227364\n",
      "F1:\t0.754941257775\n"
     ]
    }
   ],
   "source": [
    "yp_d_dev = disc_model.predict(F_dev, b=0.5)\n",
    "get_binarized_score(yp_d_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly-supervised ET baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t28087\n",
      "Features:\t\t\t69885\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 19468.424860\tGradient magnitude = 14785.293512\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 1524.705832\tGradient magnitude = 296.134661\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 1049.483908\tGradient magnitude = 59.100446\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 837.540392\tGradient magnitude = 46.218910\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 711.786007\tGradient magnitude = 38.758125\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 628.601384\tGradient magnitude = 33.831222\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 569.803256\tGradient magnitude = 30.325525\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 526.304388\tGradient magnitude = 27.711398\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 493.015905\tGradient magnitude = 25.699114\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 466.863620\tGradient magnitude = 24.112226\n",
      "\tLearning epoch = 1000\tStep size = 0.000367695424771\n",
      "\tLoss = 445.885515\tGradient magnitude = 22.836158\n",
      "\tLearning epoch = 1100\tStep size = 0.000332687932862\n",
      "\tLoss = 428.773173\tGradient magnitude = 21.793454\n",
      "\tLearning epoch = 1200\tStep size = 0.000301013429093\n",
      "\tLoss = 414.621767\tGradient magnitude = 20.930070\n",
      "\tLearning epoch = 1300\tStep size = 0.000272354586819\n",
      "\tLoss = 402.786019\tGradient magnitude = 20.207255\n",
      "\tLearning epoch = 1400\tStep size = 0.000246424291385\n",
      "\tLoss = 392.793504\tGradient magnitude = 19.596532\n",
      "\tLearning epoch = 1500\tStep size = 0.000222962763703\n",
      "\tLoss = 384.290324\tGradient magnitude = 19.076506\n",
      "\tLearning epoch = 1600\tStep size = 0.000201734957697\n",
      "\tLoss = 377.006232\tGradient magnitude = 18.630816\n",
      "\tLearning epoch = 1700\tStep size = 0.000182528205523\n",
      "\tLoss = 370.731389\tGradient magnitude = 18.246731\n",
      "\tLearning epoch = 1800\tStep size = 0.000165150086984\n",
      "\tLoss = 365.300239\tGradient magnitude = 17.914193\n",
      "\tLearning epoch = 1900\tStep size = 0.000149426501798\n",
      "\tLoss = 360.580474\tGradient magnitude = 17.625154\n"
     ]
    }
   ],
   "source": [
    "disc_model = LogReg()\n",
    "\n",
    "gold_marginals_train = np.array([1.0 if L_gold_train[i,0] > 0.0 else 0.0 for i in range(L_gold_train.shape[0])])\n",
    "\n",
    "disc_model.train(F_train, gold_marginals_train, n_iter=2000, rate=1e-3, mu=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.989754098361\n",
      "R :\t0.998449612403\n",
      "F1:\t0.994082840237\n"
     ]
    }
   ],
   "source": [
    "yp = disc_model.predict(F_train)\n",
    "get_binarized_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.901342833653\n",
      "R :\t0.827213279678\n",
      "F1:\t0.86268852459\n"
     ]
    }
   ],
   "source": [
    "yp = disc_model.predict(F_dev, b=0.5)\n",
    "get_binarized_score(yp, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_gold_dev[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supervised_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(disc_model.marginals(F_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.gen_learning import odds_to_prob\n",
    "plt.hist(odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats(labels=L_gold_train, est_accs=odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try overriding with any exact matches...\n",
    "yp_d_dev_um = np.zeros(L_gold_dev.shape[0])\n",
    "for i,c in enumerate(dev):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for lf_name, label in LFG_MESH_exact(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    for lf_name, label in LFG_drop_leading_modifiers(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    for lf_name, label in LFG_MESH_exact_remove_common(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    if neg > 0 and pos == 0:\n",
    "        yp_d_dev_um[i] = -1\n",
    "    elif pos > 0 and neg == 0:\n",
    "        yp_d_dev_um[i] = 1\n",
    "    else:\n",
    "        yp_d_dev_um[i] = yp_d_dev[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.838038209296\n",
      "R :\t0.739185110664\n",
      "F1:\t0.785513831351\n"
     ]
    }
   ],
   "source": [
    "get_binarized_score(yp_d_dev_um, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact match baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try overriding with any exact matches...\n",
    "yp_em = np.zeros(L_gold_dev.shape[0])\n",
    "for i,c in enumerate(dev):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for lf_name, label in LFG_MESH_exact(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    if neg > 0:\n",
    "        yp_em[i] = -1\n",
    "    elif pos > 0:\n",
    "        yp_em[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.879276952873\n",
      "R :\t0.342555331992\n",
      "F1:\t0.493031674208\n"
     ]
    }
   ],
   "source": [
    "get_binarized_score(yp_em, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, getting CIDs in simple heuristic way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = L_gold_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 19, 22, 30, 82]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_idxs = [i for i in range(N) if yp[i] == 1 and L_gold_train[i] > 0]\n",
    "pp_idxs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotationKey (C-17-800) 1.9844840388 61.0\n",
      "AnnotationKey (C-17-800-RC) 1.94488694522 61.0\n",
      "AnnotationKey (C-04-557-c) 0.432414162861 3163.0\n",
      "AnnotationKey (C-17-800-c) 0.764422180699 61.0\n"
     ]
    }
   ],
   "source": [
    "i = 18\n",
    "for j in L_train.getrow(i).nonzero()[1]:\n",
    "    print L_train.get_key(j), gen_model.w[j], L_train[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotationKey (C-04-182) 1.17840563711 2216.0\n",
      "AnnotationKey (C-04-182-RC) 1.00830578462 2216.0\n",
      "AnnotationKey (C-04-182-c) 1.06969451628 2216.0\n"
     ]
    }
   ],
   "source": [
    "i = 19\n",
    "for j in L_train.getrow(i).nonzero()[1]:\n",
    "    print L_train.get_key(j), gen_model.w[j], L_train[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2216.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_gold_train[19,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print L_train.get_key(558)\n",
    "print gen_model.w[558]\n",
    "print L_train[18,558]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "Take the weighted-sum max (i.e. if same CID appears multiple times, add them up!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.670943826632\n",
      "R:\t0.591800804829\n",
      "F1:\t0.628892155553\n"
     ]
    }
   ],
   "source": [
    "N         = L_gold_dev.shape[0]\n",
    "correct   = 0\n",
    "predicted = 0\n",
    "total     = 0\n",
    "for i in range(N):\n",
    "    if L_gold_dev[i,0] > 0:\n",
    "        total += 1\n",
    "    \n",
    "    if yp_d_dev_um[i] > 0:\n",
    "        predicted += 1\n",
    "        \n",
    "        scored = defaultdict(float)\n",
    "        for j in L_dev.getrow(i).nonzero()[1]:\n",
    "            scored[L_dev[i,j]] += gen_model_dev.w[j]\n",
    "        scores = list(scored.iteritems())\n",
    "        if len(scores) > 0:\n",
    "            scores.sort(key=lambda x : -x[1])\n",
    "            cid = scores[0][0]\n",
    "        else:\n",
    "            cid = -1\n",
    "        \n",
    "        if cid == L_gold_dev[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.659133709981\n",
      "R:\t0.528169014085\n",
      "F1:\t0.586428371963\n"
     ]
    }
   ],
   "source": [
    "N         = L_gold_dev.shape[0]\n",
    "correct   = 0\n",
    "predicted = 0\n",
    "total     = 0\n",
    "for i in range(N):\n",
    "    if L_gold_dev[i,0] > 0:\n",
    "        total += 1\n",
    "        \n",
    "    scored = defaultdict(float)\n",
    "    for j in L_dev.getrow(i).nonzero()[1]:\n",
    "        scored[L_dev[i,j]] += gen_model_dev.w[j]\n",
    "    scores = list(scored.iteritems())\n",
    "    if len(scores) > 0:\n",
    "        scores.sort(key=lambda x : -x[1])\n",
    "        cid = scores[0][0]\n",
    "    else:\n",
    "        cid = -1\n",
    "    \n",
    "    if cid > 0:\n",
    "        predicted += 1\n",
    "        if cid == L_gold_dev[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.651839178785\n",
      "R:\t0.574949698189\n",
      "F1:\t0.610984899105\n"
     ]
    }
   ],
   "source": [
    "N         = L_gold_dev.shape[0]\n",
    "correct   = 0\n",
    "predicted = 0\n",
    "total     = 0\n",
    "for i in range(N):\n",
    "    if L_gold_dev[i,0] > 0:\n",
    "        total += 1\n",
    "    \n",
    "    if yp_d_dev_um[i] > 0:\n",
    "        predicted += 1\n",
    "        \n",
    "        max_w = 0.0\n",
    "        cid   = -1\n",
    "        for j in L_dev.getrow(i).nonzero()[1]:\n",
    "            if gen_model_dev.w[j] > max_w:\n",
    "                max_w = gen_model_dev.w[j]\n",
    "                cid   = L_dev[i,j]\n",
    "        \n",
    "        if cid == L_gold_dev[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.661619486504\n",
      "R:\t0.505533199195\n",
      "F1:\t0.573139435415\n"
     ]
    }
   ],
   "source": [
    "N         = L_gold_dev.shape[0]\n",
    "correct   = 0\n",
    "predicted = 0\n",
    "total     = 0\n",
    "for i in range(N):\n",
    "    if L_gold_dev[i,0] > 0:\n",
    "        total += 1\n",
    "        \n",
    "    max_w = 0.0\n",
    "    cid   = -1\n",
    "    for j in L_dev.getrow(i).nonzero()[1]:\n",
    "        if gen_model_dev.w[j] > max_w:\n",
    "            max_w = gen_model_dev.w[j]\n",
    "            cid   = L_dev[i,j]\n",
    "    \n",
    "    if cid > 0:\n",
    "        predicted += 1\n",
    "        if cid == L_gold_dev[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.677807486631\n",
      "R:\t0.524031007752\n",
      "F1:\t0.5910813174\n"
     ]
    }
   ],
   "source": [
    "correct   = 0\n",
    "predicted = 0\n",
    "total     = 0\n",
    "for i in range(N):\n",
    "    if L_gold_train[i,0] > 0:\n",
    "        total += 1\n",
    "        \n",
    "    max_w = 0.0\n",
    "    cid   = -1\n",
    "    for j in L_train.getrow(i).nonzero()[1]:\n",
    "        if gen_model.w[j] > max_w:\n",
    "            max_w = gen_model.w[j]\n",
    "            cid   = L_train[i,j]\n",
    "        \n",
    "    if cid > 0:\n",
    "        predicted += 1  \n",
    "        if cid == L_gold_train[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different cut levels:\n",
    "\n",
    "Note: G = gen model on training set, D = disc. model on test set\n",
    "\n",
    "* Pos: 1, Neg: 1, Pos-cosine: 1, Neg-cosine: 1, Thresh-cosine: 0.75 = 56 F1 G / 63 F1 D\n",
    "* TODO...\n",
    "* Pos: 3, Neg: 3, Pos-cosine: 3, Neg-cosine: 3, Thresh-cosine: 0.75 = 61 F1 G / 68 F1 D\n",
    "* Pos: 3, Neg: 3, Pos-cosine: 3, Neg-cosine: 3, Thresh-cosine: [0.5, 0.75] = 63 F1 G / 65 F1 D\n",
    "* Pos: 4, Neg: 4, Pos-cosine: 4, Neg-cosine: 4, Thresh-cosine: 0.75 = 60 F1 G / 64 F1 D\n",
    "\n",
    "### Adding in drop_JJs + NEG LFs:\n",
    "\n",
    "* Pos: 2, Neg: 2, Pos-cosine: 2, Neg-cosine: 2, Thresh-cosine: 0.75 = 69 F1 G / 71 F1 D\n",
    "* Pos: 3, Neg: 3, Pos-cosine: 3, Neg-cosine: 3, Thresh-cosine: 0.75 = 70 F1 G / 73 F1 D\n",
    "\n",
    "\n",
    "#### Note: we're not yet dealing with acronyms!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hf = np.ones(L_train_b.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(L_train_b.shape[0]):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train_b.getrow(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train_b.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.utils import sparse_abs\n",
    "sparse_abs(L_train_b).sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hf = np.where(L_train_b.sum(1) == sparse_abs(L_train_b).sum(1), np.sign(L_train_b.sum(1)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_train_b = np.sign(L_gold_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_train_b.T.dot(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_train_b_sum = L_train_b.sum(1)\n",
    "L_train_b_abs_sum = sparse_abs(L_train_b).sum(1)\n",
    "L_train_b_sum_abs = sparse_abs(L_train_b.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "wrong   = 0\n",
    "for i in range(L_train_b.shape[0]):\n",
    "    if L_train_b_sum[i] < 0 and L_train_b_sum_abs[i] == L_train_b_abs_sum[i]:\n",
    "        if L_gold_train[i] < 0:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "            \n",
    "print correct\n",
    "print wrong\n",
    "print correct / float(correct + wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = L_train.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = 0\n",
    "correct  = 0\n",
    "for i,c in enumerate(train):\n",
    "    if i % 1000 == 0:\n",
    "        if filtered > 0:\n",
    "            print i, filtered, correct, correct / float(filtered)\n",
    "        else:\n",
    "            print i, filtered, correct\n",
    "    \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for lf_name, label in LFG_MESH_exact(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    for lf_name, label in LFG_MESH_exact_drop_JJs(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    #if neg > 0 and pos == 0:\n",
    "    if neg > pos:\n",
    "        filtered += 1\n",
    "        if L_gold_train[i] < 0:\n",
    "            correct += 1\n",
    "\n",
    "print filtered\n",
    "print correct\n",
    "print correct / float(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = 0\n",
    "correct  = 0\n",
    "for i,c in enumerate(train):\n",
    "    if i % 1000 == 0:\n",
    "        if filtered > 0:\n",
    "            print i, filtered, correct, correct / float(filtered)\n",
    "        else:\n",
    "            print i, filtered, correct\n",
    "    \n",
    "    if len(c.disease.get_attrib_tokens()) == 1 and c.disease.get_span().lower() not in cd.term_to_sids:\n",
    "        filtered += 1\n",
    "        if L_gold_train[i] < 0:\n",
    "            correct += 1\n",
    "\n",
    "print filtered\n",
    "print correct\n",
    "print correct / float(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LF STATS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lfs = L_train.lf_stats(labels=L_gold_train, est_accs=odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BAD_LFs = [578, 627, 603, 687, 573, 579]\n",
    "for i in BAD_LFs:\n",
    "    gen_model.w[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lfs.nsmallest(50, \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for lf in lfs.iterrows():\n",
    "    lf_name, s = lf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "N_dev = L_gold_dev.shape[0]\n",
    "\n",
    "fps = []\n",
    "fns = []\n",
    "for i in range(N_dev):\n",
    "    if yp[i] > 0 and L_gold_dev[i] < 0:\n",
    "        fps.append(i)\n",
    "    elif yp[i] < 0 and L_gold_dev[i] > 0:\n",
    "        fns.append(i)\n",
    "\n",
    "shuffle(fps)\n",
    "shuffle(fns)\n",
    "\n",
    "print len(fps)\n",
    "print len(fns)\n",
    "\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "fn_cands = [F_dev.get_candidate(i) for i in fns[:100]]\n",
    "svn      = SentenceNgramViewer(fn_cands, session)\n",
    "svn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exact_match = 0\n",
    "for i in fns:\n",
    "    c = F_dev.get_candidate(i)\n",
    "    if c.disease.get_span() in mesh_tree:\n",
    "        exact_match += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = svn.get_selected()\n",
    "\n",
    "mesh_tree[c.disease.get_span()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.disease.get_attrib_tokens('pos_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_tree['alcohol abuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Label\n",
    "\n",
    "l = session.query(Label).filter(Label.candidate == c).one()\n",
    "CID_to_MESH[l.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = F_dev.get_row_index(c)\n",
    "[(F_dev.get_key(k), disc_model.w[k]) for k in F_dev.getrow(i).nonzero()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_dev.get_key(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why is Parkinson's disease not caught?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "fp_cands = [F_dev.get_candidate(i) for i in fps[:100]]\n",
    "sv       = SentenceNgramViewer(fp_cands, session)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEG_PHRASES = [\n",
    "    'stenosis',\n",
    "    'further attention',\n",
    "    'presence',\n",
    "    'absence',\n",
    "    'syndrome',\n",
    "    'association',\n",
    "    'strain',\n",
    "    'progression'\n",
    "]\n",
    "\n",
    "NEG_END_WORDS = [\n",
    "    'therapies',\n",
    "    'muscles',\n",
    "    'concentrations',\n",
    "    'normal',\n",
    "    'heart',\n",
    "    'side',\n",
    "    'sinus',\n",
    "    'convulsants',\n",
    "    'latencies',\n",
    "    'findings',\n",
    "    'doses',\n",
    "    'remission'\n",
    "]\n",
    "\n",
    "def end_in_plural(c):\n",
    "    pass\n",
    "\n",
    "def body_part(c):\n",
    "    pass\n",
    "\n",
    "def not_exact_single_word(d):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {
    "0af25bde6e484e439a621adc322a166c": {
     "views": [
      {
       "cell_index": 75
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
