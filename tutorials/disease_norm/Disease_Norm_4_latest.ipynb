{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Norm\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* diseases from Pubmed abstracts, using annotations from the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial, which has 5 parts, walks through the process of constructing a model to classify _candidate_ disease mentions as either true (i.e., that it is truly a mention of a disease) or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Candidates + Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28087\n",
      "27896\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "print len(train)\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()\n",
    "print len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1)\n",
      "(27896, 1)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "\n",
    "L_gold_train = label_manager.load(session, train, \"CDR Training Label Set\")\n",
    "print L_gold_train.shape\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")\n",
    "print L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process / Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, load if already processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.load(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MESH ID -> CID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cPickle import load\n",
    "MESH_to_CID = load(open('MESH_to_CID.pkl', 'rb'))\n",
    "diseases    = load(open('diseases.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh_to_terms = defaultdict(set)\n",
    "for term, mid in diseases.iteritems():\n",
    "    mesh_to_terms[mid].add(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a canonical dictionary (CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import CanonicalDictionary\n",
    "cd = CanonicalDictionary(MESH_to_CID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MESH to CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 27885 entries\n"
     ]
    }
   ],
   "source": [
    "# Load MESH\n",
    "from utils import load_mesh_raw\n",
    "mesh_entries = load_mesh_raw('data/desc2016.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151006"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add MESH to cd\n",
    "for entry in mesh_entries:\n",
    "    mid, ps, terms = entry\n",
    "    paths = [[p[0]] + p[1:].split('.') for p in ps]\n",
    "    for term in terms:\n",
    "        cd.add_term(term, mid, tree_paths=paths)\n",
    "\n",
    "len(cd.term_to_sids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add MEDIC to CD\n",
    "\n",
    "Custom CTD diseases dictionary made from MESH category C + OMIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11864 MEDIC entries\n"
     ]
    }
   ],
   "source": [
    "from utils import load_MEDIC, load_mesh_raw\n",
    "medic_entries, MEDIC_to_CID = load_MEDIC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add MESH to cd\n",
    "for entry in medic_entries:\n",
    "    if entry.id.startswith(\"MESH\"):\n",
    "        mid = entry.id.split(\":\")[1]\n",
    "    elif len(entry.parent_ids) > 0 and entry.parent_ids[0].startswith(\"MESH\"):\n",
    "        mid = entry.parent_ids[0].split(\":\")[1]\n",
    "    else:\n",
    "        raise KeyError(entry)\n",
    "    \n",
    "    paths = []\n",
    "    for p in entry.tree_nums:\n",
    "        x = p.split(\"/\")[0]\n",
    "        paths.append([x[0]] + x[1:].split('.'))\n",
    "    \n",
    "    terms = [entry.name] + entry.synonyms\n",
    "    for term in terms:\n",
    "        cd.add_term(term, mid, tree_paths=paths)\n",
    "        \n",
    "len(cd.term_to_sids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add UMLS to CD\n",
    "\n",
    "This may or may not be all of the UMLS... file from Jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801566"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('cui2mesh.tsv', 'rb') as f:\n",
    "    for line in f:\n",
    "        term, cui, mid = line.rstrip('\\n').split('\\t')\n",
    "        cd.add_term(term, mid)\n",
    "\n",
    "len(cd.term_to_sids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Add MESH supp?  No paths though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing some multinomial LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Beware of LF rollback bug!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPE I LF: Subsets of MESH dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEEN_GLOBAL = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MESH exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS_DEPTH = 3\n",
    "NEG_DEPTH = 3\n",
    "def LFG_CD_match(c, p, key_mod=None, seen_global=None, max_paths_per_sid=1):\n",
    "    \"\"\"\n",
    "    Given a candidate c, some transformed candidate disease phrase p,\n",
    "    and an optional key name modifier key_mod to be appended, return a generator\n",
    "    of key, value pairs\n",
    "    \"\"\"\n",
    "    if p in cd.term_to_sids:\n",
    "        for sid in cd.term_to_sids[p]:\n",
    "            cid   = cd.sid_to_cid[sid] if sid in cd.sid_to_cid else -1\n",
    "            paths = cd.tree_paths[sid]\n",
    "            for path in paths[:max_paths_per_sid]:\n",
    "                    \n",
    "                # NOTE: path may be shorter than max depth if higher up in the tree (e.g. 'cancer', 'ischemia')!\n",
    "                key = \"-\".join(path[:POS_DEPTH]) if cid > 0 else \"-\".join(path[:NEG_DEPTH])\n",
    "                        \n",
    "                # CHECK AGAINST / ADD TO GLOBAL SEEN SET!\n",
    "                # To make sure that relaxations of an LF don't overlap with each other on any given candidate\n",
    "                if seen_global is None or c.id not in seen_global[key]:\n",
    "                    if seen_global is not None:\n",
    "                        seen_global[key].add(c.id)\n",
    "                    if key_mod:\n",
    "                        key += \"-\" + key_mod\n",
    "                    yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LFG_MESH_exact(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return LFG_CD_match(c, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 32s, sys: 17.9 s, total: 1min 50s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x382 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 7688 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_1 = label_manager.create(session, train, 'LF Training Labels 1', f=LFG_MESH_exact)\n",
    "L_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_1 = label_manager.load(session, train, 'LF Training Labels 1')\n",
    "L_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop JJs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MOD_RGX = r'JJ.*|VB.*'\n",
    "\n",
    "def LFG_drop_leading_modifiers(c):\n",
    "    words    = c.disease.get_attrib_tokens()\n",
    "    pos_tags = c.disease.get_attrib_tokens('pos_tags')\n",
    "    while re.match(MOD_RGX, pos_tags[0]):\n",
    "        words    = words[1:]\n",
    "        pos_tags = pos_tags[1:]\n",
    "        p   = \" \".join(words)\n",
    "        \n",
    "        # Hackey, but works for now...\n",
    "        g = LFG_CD_match(c, p, key_mod=\"DJ\")\n",
    "        if len(list(g)) > 0:\n",
    "            for key, cid in LFG_CD_match(c, p, key_mod=\"DJ\"):\n",
    "                yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 34s, sys: 18.8 s, total: 1min 53s\n",
      "Wall time: 1min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x279 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 3367 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_2 = label_manager.create(session, train, 'LF Training Labels 2', LFG_drop_leading_modifiers)\n",
    "L_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_2 = label_manager.load(session, train, 'LF Training Labels 2')\n",
    "L_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REMOVE_COMMON = r'.*induced|patient.*|drug|inhibitor|\\d+|human|mouse|mice|rats?|with|syndrome|famil.*|s$|low(er)?|upper|left|right|top|bottom'\n",
    "def remove_common(c):\n",
    "    p = re.sub(r'\\s\\s+', ' ', re.sub(REMOVE_COMMON, '', c.disease.get_span())).strip()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFG_MESH_exact_remove_common(c):\n",
    "    p = remove_common(c)\n",
    "    return LFG_CD_match(c, p, key_mod=\"RC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 28s, sys: 16.7 s, total: 1min 44s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x314 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5130 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_3 = label_manager.create(session, train, 'LF Training Labels 3.1', LFG_MESH_exact_remove_common)\n",
    "L_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_3 = label_manager.load(session, train, 'LF Training Labels 3')\n",
    "L_train_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MESH TF-IDF cosine match: POSITIVE terms\n",
    "\n",
    "Only cosine match with _positive_ (i.e. C, F03 MESH disease terms) here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 271512\n",
      "CPU times: user 1min 17s, sys: 1.19 s, total: 1min 18s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from entity_norm import CanonDictVectorizer \n",
    "\n",
    "# Create a vectorizer based around this \n",
    "cd_vectorizer = CanonDictVectorizer(cd.term_to_sids, other_phrases=[])\n",
    "\n",
    "# Vectorize the dictionary\n",
    "D_pos   = cd_vectorizer.vectorize_phrases(cd.pos_terms)\n",
    "D_pos_t = D_pos.T\n",
    "D_pos_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POS_DEPTH         = 3\n",
    "NEG_DEPTH         = 3\n",
    "THRESH            = 0.75\n",
    "seen_global       = None\n",
    "max_paths_per_sid = 1\n",
    "\n",
    "def LFG_CD_cosine_match_pos(c):\n",
    "    p  = c.disease.get_span().lower()\n",
    "    cx = cd_vectorizer.vectorize_phrases([p])\n",
    "    m  = cx * D_pos_t\n",
    "    m  = m.tocoo()\n",
    "\n",
    "    best_match = defaultdict(lambda : (0, None))\n",
    "    for i, s in enumerate(m.data):\n",
    "        if s > THRESH:\n",
    "            j = m.col[i]\n",
    "            t = cd.pos_terms[j]\n",
    "            for sid in cd.term_to_sids[t]:\n",
    "                cid = cd.sid_to_cid[sid] if sid in cd.sid_to_cid else -1\n",
    "                for path in cd.tree_paths[sid][:max_paths_per_sid]:\n",
    "                    key  = \"-\".join(path[:POS_DEPTH]) if cid > 0 else \"-\".join(path[:NEG_DEPTH])\n",
    "                    if s > best_match[key][0]:\n",
    "                        best_match[key] = (s, cid)\n",
    "\n",
    "    for key, x in best_match.iteritems():\n",
    "        s, cid = x\n",
    "        \n",
    "        # CHECK AGAINST / ADD TO GLOBAL SEEN SET!\n",
    "        # To make sure that relaxations of an LF don't overlap with each other on any given candidate\n",
    "        if seen_global is None or c.id not in seen_global[key]:\n",
    "            if seen_global is not None:\n",
    "                seen_global[key].add(c.id)\n",
    "            key += \"-c\"\n",
    "            yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 3min 18s, sys: 17.2 s, total: 3min 35s\n",
      "Wall time: 3min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x150 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5745 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_4 = label_manager.create(session, train, 'LF Training Labels 4.1', LFG_CD_cosine_match_pos)\n",
    "L_train_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_4 = label_manager.load(session, train, 'LF Training Labels 4')\n",
    "L_train_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neg cosine match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<271513x737772 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2508478 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the dictionary\n",
    "D_neg   = cd_vectorizer.vectorize_phrases(cd.neg_terms)\n",
    "D_neg_t = D_neg.T\n",
    "D_neg_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESH            = 0.85\n",
    "\n",
    "def LFG_CD_cosine_match_neg(c):\n",
    "    p  = c.disease.get_span().lower()\n",
    "    cx = cd_vectorizer.vectorize_phrases([p])\n",
    "    m  = cx * D_neg_t\n",
    "    m  = m.tocoo()\n",
    "\n",
    "    best_match = defaultdict(lambda : (0, None))\n",
    "    for i, s in enumerate(m.data):\n",
    "        if s > THRESH:\n",
    "            j = m.col[i]\n",
    "            t = cd.neg_terms[j]\n",
    "            for sid in cd.term_to_sids[t]:\n",
    "                cid = cd.sid_to_cid[sid] if sid in cd.sid_to_cid else -1\n",
    "                for path in cd.tree_paths[sid][:max_paths_per_sid]:\n",
    "                    key  = \"-\".join(path[:POS_DEPTH]) if cid > 0 else \"-\".join(path[:NEG_DEPTH])\n",
    "                    if s > best_match[key][0]:\n",
    "                        best_match[key] = (s, cid)\n",
    "\n",
    "    for key, x in best_match.iteritems():\n",
    "        s, cid = x\n",
    "        \n",
    "        # CHECK AGAINST / ADD TO GLOBAL SEEN SET!\n",
    "        # To make sure that relaxations of an LF don't overlap with each other on any given candidate\n",
    "        if seen_global is None or c.id not in seen_global[key]:\n",
    "            if seen_global is not None:\n",
    "                seen_global[key].add(c.id)\n",
    "            key += \"-c\"\n",
    "            yield key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 26min 1s, sys: 2min 36s, total: 28min 38s\n",
      "Wall time: 28min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x406 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 11389 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_4_N = label_manager.create(session, train, 'LF Training Labels 4 N', LFG_CD_cosine_match_neg)\n",
    "L_train_4_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting in some negative LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from lf_terms import *\n",
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens\n",
    "from utils import *\n",
    "from Disease_Tagging_Tutorial_LFs import *\n",
    "chemicals = load_chemdner_dictionary()\n",
    "\n",
    "def LF_organs(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in organs else 0      \n",
    "\n",
    "def LF_chemical_name(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens())\n",
    "    return -1 if phrase in chemicals and not phrase.isupper() and phrase.lower() not in cd.term_to_sids else 0\n",
    "\n",
    "def LF_bodypart(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in bodypart else 0  \n",
    "\n",
    "def LF_protein_chemical_abbrv(c):\n",
    "    '''Gene/protein/chemical name'''\n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"\\d+\",lemma) else 0\n",
    "\n",
    "def LF_base_pair_seq(c): \n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"^[GACT]{2,}$\",lemma) else 0\n",
    "\n",
    "LFs_false = [LF_chemical_name,\n",
    "             LF_organs,\n",
    "             LF_bodypart,\n",
    "             LF_protein_chemical_abbrv,\n",
    "             LF_base_pair_seq,\n",
    "             #LF_too_vague,\n",
    "             #LF_neg_surfix,\n",
    "             LF_non_common_disease,\n",
    "             LF_non_disease_acronyms,\n",
    "             #LF_pos_in,\n",
    "             LF_gene_chromosome_link,\n",
    "             LF_right_window_incomplete,\n",
    "             #LF_negative_indicator\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 3min 52s, sys: 14.9 s, total: 4min 7s\n",
      "Wall time: 3min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x9 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 2727 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_5 = label_manager.create(session, train, 'LF Training Labels 5', LFs_false)\n",
    "L_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Or load if already computed:\n",
    "%time L_train_5 = label_manager.load(session, train, 'LF Training Labels 5.1')\n",
    "L_train_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More neg. LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEG_COMMON_RGX = r'(finding|disease|syndrome|marker|defecit|.*event|mean|median|mg)s?'\n",
    "def LF_common_neg_phrases_2(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return -1 if re.match(NEG_COMMON_RGX, p) else 0\n",
    "\n",
    "NEG_AFTER_WORDS = frozenset(['of', 'to'])\n",
    "def LF_neg_after_2(c):\n",
    "    rw = get_right_tokens(c, window=1, attrib='lemmas')\n",
    "    return -1 if len(rw) > 0 and rw[0] in NEG_AFTER_WORDS else 0\n",
    "\n",
    "def LF_after_num_2(c):\n",
    "    lw = get_left_tokens(c, window=1, attrib='lemmas')\n",
    "    return -1 if len(lw) > 0 and re.match(r'\\d+', lw[0]) else 0\n",
    "\n",
    "def LF_too_short_2(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    return -1 if len(p) < 3 else 0\n",
    "\n",
    "LFs_false_2 = [\n",
    "    LF_common_neg_phrases_2,\n",
    "    LF_neg_after_2,\n",
    "    LF_after_num_2,\n",
    "    LF_too_short_2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 2min 34s, sys: 16.8 s, total: 2min 51s\n",
      "Wall time: 2min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28087x4 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 8708 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train_6 = label_manager.create(session, train, 'LF Training Labels 6.3', LFs_false_2)\n",
    "L_train_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running gen. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28087x1544 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 44754 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import binarize_LF_matrix, get_binarized_score\n",
    "from snorkel.annotations import merge_annotations\n",
    "\n",
    "L_train = merge_annotations([\n",
    "        L_train_1\n",
    "        , L_train_2\n",
    "        , L_train_3\n",
    "        , L_train_4\n",
    "        , L_train_4_N\n",
    "        , L_train_5\n",
    "        , L_train_6\n",
    "    ])\n",
    "\n",
    "L_train_b = binarize_LF_matrix(L_train)\n",
    "L_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t28087\n",
      "Features:\t\t\t1544\n",
      "================================================================================\n",
      "Begin training for rate=0.1, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.080097\n",
      "\tLearning epoch = 250\tGradient mag. = 0.099166\n",
      "\tLearning epoch = 500\tGradient mag. = 0.118439\n",
      "\tLearning epoch = 750\tGradient mag. = 0.145059\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.144527\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.130869\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.129422\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.129358\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.128045\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.125770\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.122429\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.118965\n",
      "\tLearning epoch = 3000\tGradient mag. = 0.115031\n",
      "\tLearning epoch = 3250\tGradient mag. = 0.110108\n",
      "\tLearning epoch = 3500\tGradient mag. = 0.106268\n",
      "\tLearning epoch = 3750\tGradient mag. = 0.103078\n",
      "\tLearning epoch = 4000\tGradient mag. = 0.099877\n",
      "\tLearning epoch = 4250\tGradient mag. = 0.095215\n",
      "\tLearning epoch = 4500\tGradient mag. = 0.092106\n",
      "\tLearning epoch = 4750\tGradient mag. = 0.089677\n",
      "Final gradient magnitude for rate=0.1, mu=1e-06: 0.087\n",
      "CPU times: user 9.81 s, sys: 62 ms, total: 9.87 s\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "%time gen_model.train(L_train_b, n_iter=5000, rate=1e-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.869129834254\n",
      "R :\t0.650387596899\n",
      "F1:\t0.74401418859\n"
     ]
    }
   ],
   "source": [
    "yp = gen_model.predict(L_train_b, b=0.5)\n",
    "get_binarized_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.843413978495\n",
      "R :\t0.64857881137\n",
      "F1:\t0.733274905054\n"
     ]
    }
   ],
   "source": [
    "yp = gen_model.predict(L_train_b, b=0.5)\n",
    "get_binarized_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.747949080622\n",
      "R :\t0.683204134367\n",
      "F1:\t0.714112086428\n"
     ]
    }
   ],
   "source": [
    "yp = gen_model.predict(L_train_b, b=0.5)\n",
    "get_binarized_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7515789473684211"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*0.84*0.68) / (0.84+0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print LF stats...\n",
    "from snorkel.learning import odds_to_prob\n",
    "lfs = L_train.lf_stats(labels=L_gold_train, est_accs=odds_to_prob(gen_model.w))\n",
    "lfs.nlargest(50, \"coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis\n",
    "_F1=63_\n",
    "\n",
    "ROUND 1:\n",
    "* _DONE: Take out 'F' category? [6]_\n",
    "* _DONE: Take out supplemental entries [2]_\n",
    "* _DONE: Don't emit all tree paths?  **This essentially gives many more votes if it has multiple tree paths!!!** [3]_\n",
    "\n",
    "**_--> F1=69_**\n",
    "\n",
    "ROUND 2:\n",
    "* _DONE: Take out LF-negative-indicator: no longer appropriate here! [1]_\n",
    "* _DONE: Common transforms [3]_\n",
    "* _DONE: Remove leading VB(N|D) also! [2]_\n",
    "* _DONE: Iterate over all JJs removed; stop at first (longest) match [2]_\n",
    "* _DONE: Try \"no reinforcing deps\" setting where we avoid the positive reinforcement of cascading overlap?_\n",
    "\n",
    "**_--> F1=72_**\n",
    "\n",
    "ROUND 3:\n",
    "* _DONE: Negative cosine matches tend to have super-high weight... **take these out??**_\n",
    "    - _**In particular, we match e.g. the disease + associated proteins, body parts, etc...**_\n",
    "    - _We are missing some **exact matches**...!!!  Just override model here?_\n",
    "    - _Or, add multiple threshs again for cosine match (e.g. milk fever case...)?_\n",
    "* _DONE: Weird words in chemicals dictionary (\"hepatitis\", \"leprosy\")? Take chemicals - diseases instead? [2]_\n",
    "\n",
    "**_--> F1=73_**\n",
    "\n",
    "ROUND 4:\n",
    "* _DONE: `LF-neg-after` is broken! [2]_\n",
    "* **Use stemming?** (e.g. \"spontaneously hypertensive rats\" -> \"hypertension\")\n",
    "* Try running transforms through vector matcher as well?\n",
    "* \"C-induced D\", \"C D\": explicitly create LF for this case!\n",
    "\n",
    "**_--> F1=74_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "470\n",
      "883\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "N_train = L_gold_train.shape[0]\n",
    "\n",
    "fps    = []\n",
    "fns    = []\n",
    "fns_na = []\n",
    "for i in range(N_train):\n",
    "    if yp[i] > 0 and L_gold_train[i] < 0:\n",
    "        fps.append(i)\n",
    "    elif yp[i] <= 0 and L_gold_train[i] > 0:\n",
    "        if yp[i] == 0:\n",
    "            fns_na.append(i)\n",
    "        else:\n",
    "            fns.append(i)\n",
    "\n",
    "shuffle(fps)\n",
    "shuffle(fns)\n",
    "shuffle(fns_na)\n",
    "\n",
    "print len(fps)\n",
    "print len(fns)\n",
    "print len(fns_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"jupyter-js-widgets\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "fn_cands = [L_train.get_candidate(i) for i in fns[:100]]\n",
    "svn      = SentenceNgramViewer(fn_cands, session)\n",
    "svn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease(Span(\"autonomic neuropathy\", parent=740, chars=[41,60], words=[7,8]))\n",
      "[u'JJ', u'NN']\n"
     ]
    }
   ],
   "source": [
    "c = svn.get_selected()\n",
    "print c\n",
    "print c.disease.get_attrib_tokens('pos_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Label (CDR Training Label = 1922),\n",
       " Label (C-10-668-c = 732),\n",
       " Label (LF_neg_after = -1)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.models import Label\n",
    "session.query(Label).filter(Label.candidate == c).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotationKey (C-10-597-c) 0.810728840474 1936\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.gen_learning import odds_to_prob\n",
    "i = L_train.get_row_index(c)\n",
    "\n",
    "for j in L_train.getrow(i).nonzero()[1]:\n",
    "    print L_train.get_key(j), odds_to_prob(gen_model.w[j]), int(L_train[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "THRESH            = 0.75\n",
    "def vector_matches(p, Dt, vectorizer, thresh=THRESH):\n",
    "    cx  = cd_vectorizer.vectorize_phrases([p])\n",
    "    m   = cx * Dt\n",
    "    m   = m.tocoo()\n",
    "    out = []\n",
    "    for i, s in enumerate(m.data):\n",
    "        if s > THRESH:\n",
    "            j    = m.col[i]\n",
    "            t    = cd.terms[j]\n",
    "            sids = cd.term_to_sids[t]\n",
    "            out.append((s, j, t, sids))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = c.disease.get_span().lower()\n",
    "vector_matches(p, Dt, cd_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd.cid_to_sid[712]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd_vectorizer.word_to_cids[stemmer.stem(\"amiodarone\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cd.cid_to_sid[2097]\n",
    "mesh_to_terms[cd.cid_to_sid[2097]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd.sid_to_cid[list(cd.term_to_sids['hypomanic episode'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd.cid_to_sid[3624]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_to_terms[cd.cid_to_sid[1419]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd.sid_to_cid[list(cd.term_to_sids[\"vein occlusion\"])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd.sid_to_cid['D012514']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find most common words\n",
    "word_fs = [(len(cids), word) for word, cids in cd_vectorizer.word_to_cids.iteritems()]\n",
    "word_fs.sort(key=lambda x : -x[0])\n",
    "word_fs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_common(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, cid in LFG_MESH_exact(c):\n",
    "    print key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, cid in LFG_CD_cosine_match(c):\n",
    "    print key, cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mt = 0.5\n",
    "m  = m.tocoo()\n",
    "for i, s in enumerate(m.data):\n",
    "    if s > mt:\n",
    "        j = m.col[i]\n",
    "        t = cd.terms[j]\n",
    "        print t, s\n",
    "        for sid in cd.term_to_sids[t]:\n",
    "            cid = cd.sid_to_cid[sid] if sid in cd.sid_to_cid else -1\n",
    "            print \"\\t\", sid, cid\n",
    "            for path in cd.tree_paths[sid]:\n",
    "                key  = \"-\".join(path[:POS_DEPTH]) if cid > 0 else \"-\".join(path[:NEG_DEPTH])\n",
    "                print \"\\t\\t\", key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in m.nonzero()[1]:\n",
    "    t = cd.terms[j]\n",
    "    print t, cd.term_to_sids[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd.sid_to_cid['C566870']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[cd.sid_to_cid[sid] for sid in cd.term_to_sids['toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd.cid_to_sid[5593]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "* _DONE: Re-write the cosine matcher_\n",
    "* _DONE: Switch to MESH 2016_\n",
    "* _DONE: Add in supplementary records!_\n",
    "* **Try labeling in cascading if-then fashion...?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "train_marginals = gen_model.marginals(L_train_b)\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-3, mu=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yp = disc_model.predict(F_train)\n",
    "get_binarized_score(yp, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yp = disc_model.predict(F_dev, b=0.4)\n",
    "get_binarized_score(yp, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(disc_model.marginals(F_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.gen_learning import odds_to_prob\n",
    "plt.hist(odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats(labels=L_gold_train, est_accs=odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try overriding with any exact matches...\n",
    "ype = np.zeros(L_gold_train.shape[0])\n",
    "for i,c in enumerate(dev):\n",
    "    if i % 5000 == 0:\n",
    "        print i\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for lf_name, label in LFG_MESH_exact(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    for lf_name, label in LFG_MESH_exact_drop_JJs(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    if neg > 0 and pos == 0:\n",
    "        ype[i] = -1\n",
    "    elif pos > 0 and neg == 0:\n",
    "        ype[i] = 1\n",
    "    else:\n",
    "        ype[i] = yp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_binarized_score(ype, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, getting CIDs in simple heuristic way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = L_gold_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp_idxs = [i for i in range(N) if yp[i] == 1 and L_gold_train[i] > 0]\n",
    "pp_idxs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 32\n",
    "for j in L_train.getrow(i).nonzero()[1]:\n",
    "    print L_train.get_key(j), gen_model.w[j], L_train[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 53\n",
    "for j in L_train.getrow(i).nonzero()[1]:\n",
    "    print L_train.get_key(j), gen_model.w[j], L_train[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_train[53,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print L_train.get_key(558)\n",
    "print gen_model.w[558]\n",
    "print L_train[18,558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct   = 0\n",
    "predicted = 0\n",
    "total     = 0\n",
    "for i in range(N):\n",
    "    if L_gold_train[i,0] > 0:\n",
    "        total += 1\n",
    "    \n",
    "    if yp[i] > 0:\n",
    "        predicted += 1\n",
    "        \n",
    "        max_w = 0.0\n",
    "        cid   = -1\n",
    "        for j in L_train.getrow(i).nonzero()[1]:\n",
    "            if gen_model.w[j] > max_w:\n",
    "                max_w = gen_model.w[j]\n",
    "                cid   = L_train[i,j]\n",
    "        \n",
    "        if cid == L_gold_train[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct   = 0\n",
    "predicted = 0\n",
    "total     = 0\n",
    "for i in range(N):\n",
    "    if L_gold_train[i,0] > 0:\n",
    "        total += 1\n",
    "        \n",
    "    max_w = 0.0\n",
    "    cid   = -1\n",
    "    for j in L_train.getrow(i).nonzero()[1]:\n",
    "        if gen_model.w[j] > max_w:\n",
    "            max_w = gen_model.w[j]\n",
    "            cid   = L_train[i,j]\n",
    "        \n",
    "    if cid > 0:\n",
    "        predicted += 1  \n",
    "        if cid == L_gold_train[i,0]:\n",
    "            correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different cut levels:\n",
    "\n",
    "Note: G = gen model on training set, D = disc. model on test set\n",
    "\n",
    "* Pos: 1, Neg: 1, Pos-cosine: 1, Neg-cosine: 1, Thresh-cosine: 0.75 = 56 F1 G / 63 F1 D\n",
    "* TODO...\n",
    "* Pos: 3, Neg: 3, Pos-cosine: 3, Neg-cosine: 3, Thresh-cosine: 0.75 = 61 F1 G / 68 F1 D\n",
    "* Pos: 3, Neg: 3, Pos-cosine: 3, Neg-cosine: 3, Thresh-cosine: [0.5, 0.75] = 63 F1 G / 65 F1 D\n",
    "* Pos: 4, Neg: 4, Pos-cosine: 4, Neg-cosine: 4, Thresh-cosine: 0.75 = 60 F1 G / 64 F1 D\n",
    "\n",
    "### Adding in drop_JJs + NEG LFs:\n",
    "\n",
    "* Pos: 2, Neg: 2, Pos-cosine: 2, Neg-cosine: 2, Thresh-cosine: 0.75 = 69 F1 G / 71 F1 D\n",
    "* Pos: 3, Neg: 3, Pos-cosine: 3, Neg-cosine: 3, Thresh-cosine: 0.75 = 70 F1 G / 73 F1 D\n",
    "\n",
    "\n",
    "#### Note: we're not yet dealing with acronyms!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hf = np.ones(L_train_b.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(L_train_b.shape[0]):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train_b.getrow(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train_b.sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.utils import sparse_abs\n",
    "sparse_abs(L_train_b).sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hf = np.where(L_train_b.sum(1) == sparse_abs(L_train_b).sum(1), np.sign(L_train_b.sum(1)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_train_b = np.sign(L_gold_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_train_b.T.dot(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hf.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_train_b_sum = L_train_b.sum(1)\n",
    "L_train_b_abs_sum = sparse_abs(L_train_b).sum(1)\n",
    "L_train_b_sum_abs = sparse_abs(L_train_b.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "wrong   = 0\n",
    "for i in range(L_train_b.shape[0]):\n",
    "    if L_train_b_sum[i] < 0 and L_train_b_sum_abs[i] == L_train_b_abs_sum[i]:\n",
    "        if L_gold_train[i] < 0:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "            \n",
    "print correct\n",
    "print wrong\n",
    "print correct / float(correct + wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = L_train.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = 0\n",
    "correct  = 0\n",
    "for i,c in enumerate(train):\n",
    "    if i % 1000 == 0:\n",
    "        if filtered > 0:\n",
    "            print i, filtered, correct, correct / float(filtered)\n",
    "        else:\n",
    "            print i, filtered, correct\n",
    "    \n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for lf_name, label in LFG_MESH_exact(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    for lf_name, label in LFG_MESH_exact_drop_JJs(c):\n",
    "        if label > 0:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    \n",
    "    #if neg > 0 and pos == 0:\n",
    "    if neg > pos:\n",
    "        filtered += 1\n",
    "        if L_gold_train[i] < 0:\n",
    "            correct += 1\n",
    "\n",
    "print filtered\n",
    "print correct\n",
    "print correct / float(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered = 0\n",
    "correct  = 0\n",
    "for i,c in enumerate(train):\n",
    "    if i % 1000 == 0:\n",
    "        if filtered > 0:\n",
    "            print i, filtered, correct, correct / float(filtered)\n",
    "        else:\n",
    "            print i, filtered, correct\n",
    "    \n",
    "    if len(c.disease.get_attrib_tokens()) == 1 and c.disease.get_span().lower() not in cd.term_to_sids:\n",
    "        filtered += 1\n",
    "        if L_gold_train[i] < 0:\n",
    "            correct += 1\n",
    "\n",
    "print filtered\n",
    "print correct\n",
    "print correct / float(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LF STATS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lfs = L_train.lf_stats(labels=L_gold_train, est_accs=odds_to_prob(gen_model.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BAD_LFs = [578, 627, 603, 687, 573, 579]\n",
    "for i in BAD_LFs:\n",
    "    gen_model.w[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lfs.nsmallest(50, \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for lf in lfs.iterrows():\n",
    "    lf_name, s = lf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "N_dev = L_gold_dev.shape[0]\n",
    "\n",
    "fps = []\n",
    "fns = []\n",
    "for i in range(N_dev):\n",
    "    if yp[i] > 0 and L_gold_dev[i] < 0:\n",
    "        fps.append(i)\n",
    "    elif yp[i] < 0 and L_gold_dev[i] > 0:\n",
    "        fns.append(i)\n",
    "\n",
    "shuffle(fps)\n",
    "shuffle(fns)\n",
    "\n",
    "print len(fps)\n",
    "print len(fns)\n",
    "\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "fn_cands = [F_dev.get_candidate(i) for i in fns[:100]]\n",
    "svn      = SentenceNgramViewer(fn_cands, session)\n",
    "svn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exact_match = 0\n",
    "for i in fns:\n",
    "    c = F_dev.get_candidate(i)\n",
    "    if c.disease.get_span() in mesh_tree:\n",
    "        exact_match += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = svn.get_selected()\n",
    "\n",
    "mesh_tree[c.disease.get_span()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.disease.get_attrib_tokens('pos_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_tree['alcohol abuse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Label\n",
    "\n",
    "l = session.query(Label).filter(Label.candidate == c).one()\n",
    "CID_to_MESH[l.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = F_dev.get_row_index(c)\n",
    "[(F_dev.get_key(k), disc_model.w[k]) for k in F_dev.getrow(i).nonzero()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_dev.get_key(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why is Parkinson's disease not caught?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "fp_cands = [F_dev.get_candidate(i) for i in fps[:100]]\n",
    "sv       = SentenceNgramViewer(fp_cands, session)\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEG_PHRASES = [\n",
    "    'stenosis',\n",
    "    'further attention',\n",
    "    'presence',\n",
    "    'absence',\n",
    "    'syndrome',\n",
    "    'association',\n",
    "    'strain',\n",
    "    'progression'\n",
    "]\n",
    "\n",
    "NEG_END_WORDS = [\n",
    "    'therapies',\n",
    "    'muscles',\n",
    "    'concentrations',\n",
    "    'normal',\n",
    "    'heart',\n",
    "    'side',\n",
    "    'sinus',\n",
    "    'convulsants',\n",
    "    'latencies',\n",
    "    'findings',\n",
    "    'doses',\n",
    "    'remission'\n",
    "]\n",
    "\n",
    "def end_in_plural(c):\n",
    "    pass\n",
    "\n",
    "def body_part(c):\n",
    "    pass\n",
    "\n",
    "def not_exact_single_word(d):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {
    "b604d52f3c1b4bdda8d54db31e9b7e34": {
     "views": [
      {
       "cell_index": 72
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
