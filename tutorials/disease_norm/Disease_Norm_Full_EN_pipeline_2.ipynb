{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28087\n",
      "27896\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "print len(train)\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()\n",
    "print len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1)\n",
      "(27896, 1)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "\n",
    "L_gold_train = label_manager.load(session, train, \"CDR Training Label Set\")\n",
    "print L_gold_train.shape\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")\n",
    "print L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `L_train` and `L_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 1645)\n",
      "(27896, 1557)\n",
      "CPU times: user 20.5 s, sys: 740 ms, total: 21.2 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from snorkel.annotations import merge_annotations\n",
    "from utils import binarize_LF_matrix, get_binarized_score\n",
    "\n",
    "L_TRAIN_BLOCKS = ['1', '2', '3', '4.1', '4 T2', '4 N', '5', '6']\n",
    "L_DEV_BLOCKS   = ['1', '2', '3.1', '4', '4 T2', '4 N', '5', '6']\n",
    "\n",
    "L_train_blocks = [label_manager.load(session, train, 'LF Training Labels %s' % lfn) for lfn in L_TRAIN_BLOCKS]\n",
    "L_dev_blocks   = [label_manager.load(session, dev, 'LF Development Labels %s' % lfn) for lfn in L_DEV_BLOCKS]\n",
    "\n",
    "L_train   = merge_annotations(L_train_blocks)\n",
    "L_train_b = binarize_LF_matrix(L_train)\n",
    "L_dev     = merge_annotations(L_dev_blocks)\n",
    "L_dev_b   = binarize_LF_matrix(L_dev)\n",
    "print L_train.shape\n",
    "print L_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load `F_train` and `F_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28087, 69885)\n",
      "(27896, 69885)\n",
      "CPU times: user 32.6 s, sys: 1.55 s, total: 34.1 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "\n",
    "F_train = feature_manager.load(session, train, 'Train Features')\n",
    "F_dev   = feature_manager.load(session, dev, 'Train Features')\n",
    "print F_train.shape\n",
    "print F_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load canonical & secondary dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cPickle import load\n",
    "cd = load(open('cd.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 2: DP LR Pre-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/pymodules/python2.7/matplotlib/__init__.py:1173: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t28087\n",
      "Features:\t\t\t1645\n",
      "================================================================================\n",
      "CPU times: user 28 s, sys: 12 ms, total: 28.1 s\n",
      "Wall time: 28.1 s\n",
      "================================================================================\n",
      "Training marginals (!= 0.5):\t20038\n",
      "Features:\t\t\t69885\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 13889.283204\tGradient magnitude = 9832.035530\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 3078.241784\tGradient magnitude = 379.275662\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 2894.743086\tGradient magnitude = 1296.907839\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 2494.032915\tGradient magnitude = 297.457588\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 2394.454863\tGradient magnitude = 31.977057\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 2337.136536\tGradient magnitude = 28.324998\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 2295.414531\tGradient magnitude = 25.754725\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 2263.718238\tGradient magnitude = 23.827790\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 2238.906221\tGradient magnitude = 22.330616\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 2219.038251\tGradient magnitude = 21.137956\n",
      "\tLearning epoch = 1000\tStep size = 0.000367695424771\n",
      "\tLoss = 2202.843808\tGradient magnitude = 20.169672\n",
      "\tLearning epoch = 1100\tStep size = 0.000332687932862\n",
      "\tLoss = 2189.454311\tGradient magnitude = 19.371671\n",
      "\tLearning epoch = 1200\tStep size = 0.000301013429093\n",
      "\tLoss = 2178.254659\tGradient magnitude = 18.705967\n",
      "\tLearning epoch = 1300\tStep size = 0.000272354586819\n",
      "\tLoss = 2168.796602\tGradient magnitude = 18.145076\n",
      "\tLearning epoch = 1400\tStep size = 0.000246424291385\n",
      "\tLoss = 2160.745394\tGradient magnitude = 17.668571\n",
      "\tLearning epoch = 1500\tStep size = 0.000222962763703\n",
      "\tLoss = 2153.845745\tGradient magnitude = 17.260959\n",
      "\tLearning epoch = 1600\tStep size = 0.000201734957697\n",
      "\tLoss = 2147.899787\tGradient magnitude = 16.910263\n",
      "\tLearning epoch = 1700\tStep size = 0.000182528205523\n",
      "\tLoss = 2142.751331\tGradient magnitude = 16.607075\n",
      "\tLearning epoch = 1800\tStep size = 0.000165150086984\n",
      "\tLoss = 2138.275687\tGradient magnitude = 16.343897\n",
      "\tLearning epoch = 1900\tStep size = 0.000149426501798\n",
      "\tLoss = 2134.372054\tGradient magnitude = 16.114692\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg, NaiveBayes\n",
    "\n",
    "gen_model_b = NaiveBayes()\n",
    "%time gen_model_b.train(L_train_b, n_iter=10000, rate=1e-1, verbose=False)\n",
    "\n",
    "train_marginals = gen_model_b.marginals(L_train_b)\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-3, mu=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.838600797791\n",
      "R :\t0.687374245473\n",
      "F1:\t0.755494125777\n"
     ]
    }
   ],
   "source": [
    "yp = disc_model.predict(F_dev, b=0.5)\n",
    "get_binarized_score(yp, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 2.i: Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.880952380952\n",
      "R:\t0.279175050302\n",
      "F1:\t0.423987776929\n"
     ]
    }
   ],
   "source": [
    "correct   = 0\n",
    "predicted = 0\n",
    "total_pos = 0\n",
    "for i,c in enumerate(dev):\n",
    "    if L_gold_dev[i,0] > 0:\n",
    "        total_pos += 1\n",
    "    \n",
    "    # Check for exact *positive* matches to the canonical dictionary\n",
    "    if yp[i] > 0:\n",
    "        p    = c.disease.get_span().lower()\n",
    "        sids = cd.term_to_sids[p]\n",
    "        cids = set([cd.sid_to_cid[sid] for sid in sids if sid in cd.sid_to_cid])\n",
    "        if len(cids) > 0:\n",
    "            predicted += 1\n",
    "            cid = list(cids)[0]\n",
    "            if cid == L_gold_dev[i,0]:\n",
    "                correct += 1\n",
    "\n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total_pos)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 2.ii: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 271630\n",
      "CPU times: user 40.7 s, sys: 864 ms, total: 41.6 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from entity_norm import CanonDictVectorizer \n",
    "\n",
    "# Create a vectorizer based around this \n",
    "cd_vectorizer = CanonDictVectorizer(cd.term_to_sids, other_phrases=[])\n",
    "\n",
    "# Vectorize the dictionary\n",
    "D_pos   = cd_vectorizer.vectorize_phrases(cd.pos_terms)\n",
    "D_pos_t = D_pos.T\n",
    "D_pos_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_pos_vector_matches(candidates):\n",
    "    best_match = defaultdict(lambda : (0.0, -1))\n",
    "    for c in candidates:\n",
    "        p  = c.disease.get_span().lower()\n",
    "        cx = cd_vectorizer.vectorize_phrases([p])\n",
    "        m  = cx * D_pos_t\n",
    "        m  = m.tocoo()\n",
    "        for i, s in enumerate(m.data):\n",
    "            j    = m.col[i]\n",
    "            t    = cd.pos_terms[j]\n",
    "            sids = cd.term_to_sids[t]\n",
    "            cid  = list(set([cd.sid_to_cid[sid] for sid in sids if sid in cd.sid_to_cid]))[0]\n",
    "            if s > best_match[c.id][0]:\n",
    "                best_match[c.id] = (s, cid)\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 2s, sys: 2.52 s, total: 3min 4s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%time best_match = get_pos_vector_matches(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.67873580853\n",
      "R:\t0.556338028169\n",
      "F1:\t0.611472011057\n"
     ]
    }
   ],
   "source": [
    "correct   = 0\n",
    "predicted = 0\n",
    "total_pos = 0\n",
    "for i,c in enumerate(dev):\n",
    "    if L_gold_dev[i,0] > 0:\n",
    "        total_pos += 1\n",
    "        \n",
    "    if yp[i] > 0:\n",
    "        s, cid = best_match[c.id]\n",
    "        predicted += 1\n",
    "        if cid == L_gold_dev[i,0]:\n",
    "            correct += 1\n",
    "    \n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(total_pos)\n",
    "f1     = (2*prec*recall) / (prec+recall)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 2.iii: Using the Gen. Model directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only consider the points predicted positive by the discriminative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "N, M        = L_dev.shape\n",
    "mn_maps     = []\n",
    "mn_inv_maps = []\n",
    "nz_idxs     = []\n",
    "Xs          = []\n",
    "for i in range(N):\n",
    "    if yp[i] > 0:\n",
    "        nz = L_dev.getrow(i).nonzero()[1]\n",
    "        if len(nz) > 0:\n",
    "            nz_idxs.append(i)\n",
    "    \n",
    "            # Construct the map from CID -> column index, and reverse\n",
    "            mn_map     = {}\n",
    "            mn_inv_map = []\n",
    "            for j in nz:\n",
    "                label = L_dev[i,j]\n",
    "                if label not in mn_map:\n",
    "                    mn_map[label] = len(mn_map)\n",
    "                    mn_inv_map.append(label)\n",
    "            mn_maps.append(mn_map)\n",
    "            mn_inv_maps.append(mn_inv_map)\n",
    "    \n",
    "            # Construct the candidate label matrix\n",
    "            X = np.zeros((M, len(mn_map)))\n",
    "            for j in nz:\n",
    "                k = mn_map[L_dev[i,j]]\n",
    "                X[j, k] = 1\n",
    "            Xs.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training for rate=0.01, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.251152\n",
      "Final gradient magnitude for rate=0.01, mu=1e-06: 0.275\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.learning_mn import LogReg\n",
    "\n",
    "gen_model = LogReg()\n",
    "gen_model.train(Xs, n_iter=100, rate=1e-2, w0=np.ones(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.7896\n",
      "R:\t0.496478873239\n",
      "F1:\t0.609635577517\n"
     ]
    }
   ],
   "source": [
    "N_pos_dev = sum([1 for i in range(L_gold_dev.shape[0]) if L_gold_dev[i,0] > 0])\n",
    "marginals = gen_model.marginals(Xs)\n",
    "\n",
    "predicted = 0\n",
    "correct   = 0\n",
    "total_pos = 0\n",
    "for i,m in enumerate(marginals):\n",
    "    cid = mn_inv_maps[i][np.argmax(m)]\n",
    "    if cid > 0:\n",
    "        predicted += 1\n",
    "        if cid == L_gold_dev[nz_idxs][i,0]:\n",
    "            correct += 1\n",
    "            \n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(N_pos_dev)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup 2.iv: SSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "\n",
    "We used the discriminative model, trained using the training_marginals from the binary gen model over the training set, to filter both the training and test sets to predicted positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.845507246377\n",
      "R :\t0.753746770026\n",
      "F1:\t0.796994535519\n"
     ]
    }
   ],
   "source": [
    "yp_d_train = disc_model.predict(F_train, b=0.5)\n",
    "get_binarized_score(yp_d_train, L_gold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P :\t0.838600797791\n",
      "R :\t0.687374245473\n",
      "F1:\t0.755494125777\n"
     ]
    }
   ],
   "source": [
    "yp_d_dev = disc_model.predict(F_dev, b=0.5)\n",
    "get_binarized_score(yp_d_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "\n",
    "We construct a vectorizer for positive disease terms, and vectorize the canonical dictionary, training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V| = 19468\n",
      "CPU times: user 9.86 s, sys: 380 ms, total: 10.2 s\n",
      "Wall time: 9.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from entity_norm import CanonDictVectorizer \n",
    "\n",
    "pos_term_to_sids = dict((t, sids) for t, sids in cd.term_to_sids.iteritems() if len(sids) > 0 and any([sid in cd.sid_to_cid for sid in sids]))\n",
    "\n",
    "# Create a vectorizer *only* based on positive terms\n",
    "cd_vectorizer = CanonDictVectorizer(pos_term_to_sids, other_phrases=[])\n",
    "\n",
    "# Vectorize the dictionary\n",
    "D_pos   = cd_vectorizer.vectorize_phrases(cd.pos_terms)\n",
    "D_pos_t = D_pos.T\n",
    "D_pos_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3450, 19469)\n",
      "(3259, 19469)\n",
      "CPU times: user 24.8 s, sys: 476 ms, total: 25.3 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Vectorize the train & dev candidates that were predicted positive by the stage I LR model\n",
    "X_train = cd_vectorizer.vectorize_phrases([c.disease.get_span().lower() for i,c in enumerate(train) if yp_d_train[i] > 0])\n",
    "X_dev   = cd_vectorizer.vectorize_phrases([c.disease.get_span().lower() for i,c in enumerate(dev) if yp_d_dev[i] > 0])\n",
    "print X_train.shape\n",
    "print X_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:\n",
    "\n",
    "We run the multinomial generative model over the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "N, M        = L_train.shape\n",
    "mn_maps     = []\n",
    "mn_inv_maps = []\n",
    "nz_idxs     = []\n",
    "Xs          = []\n",
    "for i in range(N):\n",
    "    if yp_d_train[i] > 0:\n",
    "        nz = L_train.getrow(i).nonzero()[1]\n",
    "        if len(nz) > 0:\n",
    "            nz_idxs.append(i)\n",
    "    \n",
    "            # Construct the map from CID -> column index, and reverse\n",
    "            mn_map     = {}\n",
    "            mn_inv_map = []\n",
    "            for j in nz:\n",
    "                label = L_train[i,j]\n",
    "                if label not in mn_map:\n",
    "                    mn_map[label] = len(mn_map)\n",
    "                    mn_inv_map.append(label)\n",
    "            mn_maps.append(mn_map)\n",
    "            mn_inv_maps.append(mn_inv_map)\n",
    "    \n",
    "            # Construct the candidate label matrix\n",
    "            X = np.zeros((M, len(mn_map)))\n",
    "            for j in nz:\n",
    "                k = mn_map[L_train[i,j]]\n",
    "                X[j, k] = 1\n",
    "            Xs.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training for rate=0.01, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.236760\n",
      "Final gradient magnitude for rate=0.01, mu=1e-06: 0.258\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.learning_mn import LogReg\n",
    "\n",
    "gen_model = LogReg()\n",
    "gen_model.train(Xs, n_iter=100, rate=1e-2, w0=np.ones(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\t0.746175243394\n",
      "R:\t0.554521963824\n",
      "F1:\t0.636228876371\n"
     ]
    }
   ],
   "source": [
    "N_pos_train = sum([1 for i in range(L_gold_train.shape[0]) if L_gold_train[i,0] > 0])\n",
    "train_marginals = gen_model.marginals(Xs)\n",
    "\n",
    "predicted = 0\n",
    "correct   = 0\n",
    "total_pos = 0\n",
    "for i,m in enumerate(train_marginals):\n",
    "    cid = mn_inv_maps[i][np.argmax(m)]\n",
    "    if cid > 0:\n",
    "        predicted += 1\n",
    "        if cid == L_gold_train[nz_idxs][i,0]:\n",
    "            correct += 1\n",
    "            \n",
    "prec   = correct / float(predicted)\n",
    "recall = correct / float(N_pos_train)\n",
    "\n",
    "print \"P:\\t\", prec\n",
    "print \"R:\\t\", recall\n",
    "print \"F1:\\t\", (2*prec*recall) / (prec+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Why such a big gap between len(tm) and N???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2896"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:\n",
    "\n",
    "We construct the training marginals as sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.88301307,  0.11698693])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_marginals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61.0, 3163.0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_inv_maps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_gold_train[nz_idxs][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2896x4790 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Np = len(train_marginals)\n",
    "K  = len(set(cd.sid_to_cid.values()))\n",
    "Y  = lil_matrix((Np, K))\n",
    "\n",
    "for i in range(Np):\n",
    "    for j in range(len(train_marginals[i])):\n",
    "        Y[i, int(mn_inv_maps[i][j])] = train_marginals[i][j]\n",
    "Y = Y.tocsr()\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:\n",
    "\n",
    "We train the SSI model using the training marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<63794x19469 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 211070 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cids = [cd.sid_to_cid[list(sid for sid in cd.term_to_sids[t] if sid in cd.sid_to_cid)[0]] for t in cd.pos_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from entity_norm import SSIModel\n",
    "\n",
    "model = SSIModel(D_pos, cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3450x19469 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 7396 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building close negatives dictionary...\n",
      "Iteration: 0"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of bounds: 0 <= 2938 <= 2896, 0 <= 2939 <= 2896, 2938 <= 2939",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-dbd46b23e835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/lfs/raiders7/hdd/ajratner/snorkel/tutorials/disease_norm/entity_norm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y, rate, n_iter, n_iter_sample, n_iter_neg, sample_close_negs, verbose)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;31m# Sample the training example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                     \u001b[0mcids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mt\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/ajratner/.local/lib/python2.7/site-packages/scipy-0.15.1-py2.7-linux-x86_64.egg/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36mgetrow\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mCSR\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/ajratner/.local/lib/python2.7/site-packages/scipy-0.15.1-py2.7-linux-x86_64.egg/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m_get_submatrix\u001b[0;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mj0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/cs.stanford.edu/u/ajratner/.local/lib/python2.7/site-packages/scipy-0.15.1-py2.7-linux-x86_64.egg/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36mcheck_bounds\u001b[0;34m(i0, i1, num)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 raise IndexError(\n\u001b[1;32m    406\u001b[0m                       \u001b[0;34m\"index out of bounds: 0 <= %d <= %d, 0 <= %d <= %d,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                       \" %d <= %d\" % (i0, num, i1, num, i0, i1))\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds: 0 <= 2938 <= 2896, 0 <= 2939 <= 2896, 2938 <= 2939"
     ]
    }
   ],
   "source": [
    "model.train(X_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
