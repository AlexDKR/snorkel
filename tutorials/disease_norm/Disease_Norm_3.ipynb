{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Norm\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* diseases from Pubmed abstracts, using annotations from the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial, which has 5 parts, walks through the process of constructing a model to classify _candidate_ disease mentions as either true (i.e., that it is truly a mention of a disease) or false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a MESH_ID -> CID mapping\n",
    "\n",
    "For now, just store this as a pickle file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import load_mesh_dict\n",
    "diseases = load_mesh_dict('data/desc2017.xml', tree_prefixes=['C', 'F'])\n",
    "print \"Loaded dictionary with %s entries\" % len(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MESH_to_CID = {}\n",
    "mesh_ids    = list(set(diseases.values()))\n",
    "mesh_ids.sort()\n",
    "for mid in mesh_ids:\n",
    "    MESH_to_CID[mid] = len(MESH_to_CID) + 1  # Reserve CID = 0 for null vote\n",
    "print len(MESH_to_CID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cPickle import dump\n",
    "dump(MESH_to_CID, open('MESH_to_CID.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling the candidates based on the gold annotations\n",
    "\n",
    "We look for the candidates which are equal to or contain the gold annotations, and then label them with the corresponding MESH ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_docs_xml, get_CD_mentions_by_MESHID\n",
    "from snorkel.models import Document, TemporarySpan, Label, AnnotationKeySet, AnnotationKey, Span, CandidateSet\n",
    "from snorkel.loaders import create_or_fetch\n",
    "import os\n",
    "ROOT = os.environ['SNORKELHOME'] + '/tutorials/disease_norm/data/'\n",
    "\n",
    "def load_BioC_CDR_entity_labels(name, entity_class):\n",
    "    seen  = set()\n",
    "    \n",
    "    candidates    = session.query(CandidateSet).filter(CandidateSet.name == 'CDR %s Candidates' % name).one()\n",
    "    label_key_set = create_or_fetch(session, AnnotationKeySet, \"CDR %s Label Set\" % name)\n",
    "    label_key     = create_or_fetch(session, AnnotationKey, \"CDR %s Label\" % name)\n",
    "    if label_key not in label_key_set.keys:\n",
    "        label_key_set.append(label_key)\n",
    "    session.commit()\n",
    "    \n",
    "    # Get all the annotated Pubtator documents as XML trees\n",
    "    file_name = 'CDR_%sSet.BioC.xml' % name\n",
    "    doc_xmls  = get_docs_xml(ROOT + file_name)\n",
    "    for doc_id, doc_xml in doc_xmls.iteritems():\n",
    "    \n",
    "        # Get the corresponding Document object\n",
    "        stable_id = \"%s::document:0:0\" % doc_id\n",
    "        doc       = session.query(Document).filter(Document.stable_id == stable_id).one()\n",
    "    \n",
    "        # Use custom script to extract the annotations as (sentence, char_start, char_end, text) tuples\n",
    "        for mesh_id, mentions in get_CD_mentions_by_MESHID(doc_xml, doc.sentences)[entity_class.__name__].iteritems():\n",
    "            \n",
    "            # HACK HERE\n",
    "            if mesh_id == \"-1\":\n",
    "                continue\n",
    "            elif \"|\" in mesh_id:\n",
    "                mesh_id = mesh_id.split(\"|\")[0]\n",
    "            elif mesh_id not in MESH_to_CID:\n",
    "                continue\n",
    "            \n",
    "            for sent, char_start, char_end, txt in mentions:\n",
    "                \n",
    "                # Instantiate the annotation as a temporary span\n",
    "                g = TemporarySpan(parent=sent, char_start=char_start, char_end=char_end)\n",
    "                \n",
    "                # Get the candidates in our NP candidate set which are in the same sentence\n",
    "                ds = session.query(Disease).join(Span)\\\n",
    "                    .filter(Disease.sets.contains(candidates))\\\n",
    "                    .filter(Span.parent == sent).all()\n",
    "                    \n",
    "                # Check for the superset candidate which contains the gold span\n",
    "                for d in ds:\n",
    "        \n",
    "                    # Note that a small number of candidates contain > 1 gold candidate\n",
    "                    # Just deal with heuristically here...\n",
    "                    if char_start >= d.disease.char_start and char_end <= d.disease.char_end and d not in seen:\n",
    "                        label = Label(key=label_key, candidate=d, value=MESH_to_CID[mesh_id])\n",
    "                        session.add(label)\n",
    "                        seen.add(d)\n",
    "                        break\n",
    "    \n",
    "    # Label all other candidates as negative\n",
    "    for d in candidates:\n",
    "        if d not in seen:\n",
    "            label = Label(key=label_key, candidate=d, value=-1)\n",
    "            session.add(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time load_BioC_CDR_entity_labels(\"Training\", Disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time load_BioC_CDR_entity_labels(\"Development\", Disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time load_BioC_CDR_entity_labels(\"Test\", Disease)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
