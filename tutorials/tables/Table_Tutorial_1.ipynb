{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables in Snorkel: Extracting Attributes from Spec Sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will walk through the process of using Snorkel to extract relations from text, including text found in tables. If you have not already, consider walking through the Intro tutorial first to familiarize yourself with Snorkel in general. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source documents for this tutorial are specification sheets from various manufacturers of transistors. Prior to the beginning of this tutorial, these sheets were converted from PDF to HTML format using Adobe Acrobat. These conversions are not always (in fact, are almost never) perfectly accurate, but with Snorkel we aim to learn through this noise. In this tutorial specifically, we will be attempting to extract (part number, minimum storage temperature) pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first notebook, we will preprocess the input data, parsing it into python objects that we will store in a database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a `SnorkelSession`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize a SnorkelSession, which will enable us to save intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the Train `Corpus`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a `DocParser` we use `HTMLParser`, which reads a file (or directory of files) looking for `<html>` tags and extracts the contents of each one as a new document.\n",
    "\n",
    "For a `ContextParser` we use `OmniParser`, which parses the contents of an HTML document, paying special attention to tags that denote table-like structure and recording row/column information as relevant.\n",
    "\n",
    "We limit the number of documents to parse to 10 in this tutorial for the sake of speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser import HTMLParser\n",
    "from snorkel.parser import OmniParser\n",
    "\n",
    "doc_parser = HTMLParser(path='data/hardware/hardware100_html/')\n",
    "context_parser = OmniParser()\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 28.1 s, sys: 1.93 s, total: 30 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%time corpus = cp.parse_corpus(name='Hardware', session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate here how to traverse the object hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2N6427\n",
      "Table(Doc: 2N6427, Position: 0)\n",
      "Cell(Doc: 2N6427, Table: 0, Row: 1, Col: 1)\n",
      "Phrase(Doc: 2N6427, Table: 0, Row: 1, Col: 1, Position: 0, Text: Collector-Emitter Voltage)\n"
     ]
    }
   ],
   "source": [
    "doc = corpus.documents[0]\n",
    "print doc\n",
    "print doc.tables[0]\n",
    "print doc.tables[0].cells[5]\n",
    "print doc.tables[0].cells[5].phrases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the `Corpus`\n",
    "We persist the parsed corpus in Snorkel's database backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the `Corpus`\n",
    "If the corpus has already been parsed, load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus (Hardware) contains 10 Documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware').one()\n",
    "print \"%s contains %d Documents\" % (corpus, len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the `Corpus` into Train/Dev\n",
    "\n",
    "Here we segment the parsed corpus into a `Training` and `Development` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Documents added to corpus Hardware Training\n",
      "2 Documents added to corpus Hardware Development\n"
     ]
    }
   ],
   "source": [
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.queries import split_corpus\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "split_corpus(session, corpus, train=0.8, development=0.2, test=0, seed=0) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate below how these corpora can be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus (Hardware Training) contains 8 Documents\n",
      "Corpus (Hardware Development) contains 2 Documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.models import Corpus\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "print \"%s contains %d Documents\" % (corpus, len(corpus))\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "print \"%s contains %d Documents\" % (corpus, len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part 2, we will look at how to extract `Candidate` relations from our saved `Corpus` objects."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
