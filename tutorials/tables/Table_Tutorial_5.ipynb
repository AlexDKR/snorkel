{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables in Snorkel: Extracting Attributes from Spec Sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Training a Model with Data Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the `CandidateSet`,  `Feature` matrix, and `Label` matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together now, we reload the `CandidateSet`, `Feature` matrix, and `Label` matrix from the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 457 ms, total: 13 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.load(session, train, 'Training Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 339 ms, sys: 49.5 ms, total: 388 ms\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "%time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our generative model using the `Label` Matrix from the Training `CandidateSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t6571\n",
      "Features:\t\t\t10\n",
      "================================================================================\n",
      "Begin training for rate=0.001, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.354352\n",
      "\tLearning epoch = 250\tGradient mag. = 0.375214\n",
      "\tLearning epoch = 500\tGradient mag. = 0.379046\n",
      "\tLearning epoch = 750\tGradient mag. = 0.384424\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.391265\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.399481\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.408980\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.419665\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.431442\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.444216\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.457898\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.472403\n",
      "\tLearning epoch = 3000\tGradient mag. = 0.487653\n",
      "\tLearning epoch = 3250\tGradient mag. = 0.503577\n",
      "\tLearning epoch = 3500\tGradient mag. = 0.520112\n",
      "\tLearning epoch = 3750\tGradient mag. = 0.537200\n",
      "\tLearning epoch = 4000\tGradient mag. = 0.554792\n",
      "\tLearning epoch = 4250\tGradient mag. = 0.572844\n",
      "\tLearning epoch = 4500\tGradient mag. = 0.591319\n",
      "\tLearning epoch = 4750\tGradient mag. = 0.610182\n",
      "Final gradient magnitude for rate=0.001, mu=1e-06: 0.629\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=5000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.save(session, 'Generative Params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Discriminative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a discriminative model using the `Feature` matrix generated earlier and marginal probabilities produced by the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t6571\n",
      "Features:\t\t\t3820\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 0.001\n",
      "\tLoss = 4554.670123\tGradient magnitude = 12692.862502\n",
      "\tLearning epoch = 100\tStep size = 0.000904792147114\n",
      "\tLoss = 1899.505850\tGradient magnitude = 988.946242\n",
      "\tLearning epoch = 200\tStep size = 0.000818648829479\n",
      "\tLoss = 1869.787360\tGradient magnitude = 5214.426285\n",
      "\tLearning epoch = 300\tStep size = 0.000740707032156\n",
      "\tLoss = 1645.137887\tGradient magnitude = 905.699390\n",
      "\tLearning epoch = 400\tStep size = 0.000670185906007\n",
      "\tLoss = 1518.267465\tGradient magnitude = 835.951013\n",
      "\tLearning epoch = 500\tStep size = 0.000606378944861\n",
      "\tLoss = 1087.352665\tGradient magnitude = 1532.727777\n",
      "\tLearning epoch = 600\tStep size = 0.000548646907485\n",
      "\tLoss = 1172.138936\tGradient magnitude = 983.269116\n",
      "\tLearning epoch = 700\tStep size = 0.000496411413431\n",
      "\tLoss = 902.762534\tGradient magnitude = 1262.552477\n",
      "\tLearning epoch = 800\tStep size = 0.00044914914861\n",
      "\tLoss = 912.473345\tGradient magnitude = 768.188099\n",
      "\tLearning epoch = 900\tStep size = 0.000406386622545\n",
      "\tLoss = 810.739903\tGradient magnitude = 460.271603\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3820,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc_model.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 710 ms, sys: 18.5 ms, total: 728 ms\n",
      "Wall time: 736 ms\n"
     ]
    }
   ],
   "source": [
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Performance on Development Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "dev = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.81 s, sys: 250 ms, total: 6.06 s\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_dev = feature_manager.load(session, dev, 'Training Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_dev = label_manager.load(session, dev, \"Hardware Development Labels -- Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_dev_set = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration plot:\n",
      "========================================\n",
      "Recall-corrected Noise-aware Model\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: nan\n",
      "Corpus Precision 1.0\n",
      "Corpus Recall    1.0\n",
      "Corpus F1        1.0\n",
      "----------------------------------------\n",
      "TP: 57 | FP: 0 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Recall-corrected Noise-aware Model\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: nan\n",
      "Corpus Precision 1.0\n",
      "Corpus Recall    1.0\n",
      "Corpus F1        1.0\n",
      "----------------------------------------\n",
      "TP: 57 | FP: 0 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_dev, L_dev, gold_dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can perform error analysis on any `Candidates` which were incorrectly classified. In a text-only environment, we could use the `Viewer` for this task (see, for example, the Intro tutorial). Because we do not yet have a viewer compatible with HTML tables, we use helper functions with print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import part_error_analysis\n",
    "\n",
    "if fp:\n",
    "    part_error_analysis(list(fp)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above are reported at the `Candidate`, or _mention_, level. What we're really interested in for many applications (including this one) is the performance at the _entity_ level. (For example, classifying all five (BC548, -55) `Candidates` from a document correctly should only count as one true positive entity, not five). The function below performs this correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 1.0\n",
      "Corpus Recall    1.0\n",
      "Corpus F1        1.0\n",
      "----------------------------------------\n",
      "TP: 4 | FP: 0 | FN: 0\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Development').one()\n",
    "(TP, FP, FN) = entity_level_f1(tp, fp, tn, fn, gold_file, corpus, 'stg_temp_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if FP:\n",
    "    print FP[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what we've learned, we can then iterate over and refine our LFs or learning parameters before assessing our final system performance on a Test set of `Candidates`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The End."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
