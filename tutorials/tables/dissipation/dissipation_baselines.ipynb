{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dissipation baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Dissipation = candidate_subclass('Part_Dissipation', ['part','dissipation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "eeca_matcher = RegexMatchSpan(rgx='([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)')\n",
    "jedec_matcher = RegexMatchSpan(rgx='([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)')\n",
    "jis_matcher = RegexMatchSpan(rgx='(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})')\n",
    "others_matcher = RegexMatchSpan(rgx='((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)')\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)\n",
    "\n",
    "dissipation_matcher = RegexMatchSpan(rgx=r'\\d\\d[05]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from snorkel.candidates import OmniNgrams\n",
    "from snorkel.lf_helpers import *\n",
    "from hardware_utils import OmniNgramsPart, get_gold_dict\n",
    "\n",
    "# Make parts list\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "parts_by_doc = defaultdict(set)\n",
    "for part in gold_parts:\n",
    "    parts_by_doc[part[0]].add(part[1])\n",
    "\n",
    "# Baseline 1: all candidates, no splitting/linking, majority label\n",
    "# part_ngrams        = OmniNgrams(n_max=1)\n",
    "# dissipation_ngrams = OmniNgrams(n_max=1)\n",
    "# throttler          = None\n",
    "\n",
    "# Baseline 2: candidates w/ throttler, no splitting/linking, majority label\n",
    "# part_ngrams        = OmniNgrams(n_max=1)\n",
    "# dissipation_ngrams = OmniNgrams(n_max=1)\n",
    "# throttler = lambda x: overlap(['power','dissipation','mw'], get_aligned_ngrams(x[1]))\n",
    "\n",
    "# Current 1: candidates (w/ throttler?), splitting, no linking, supervised learning\n",
    "# part_ngrams        = OmniNgramsPart(n_max=2)\n",
    "# dissipation_ngrams = OmniNgrams(n_max=1)\n",
    "# throttler = lambda x: overlap(['power','dissipation','mw'], get_aligned_ngrams(x[1]))\n",
    "\n",
    "# Oracle 1: candidates (w/ throttler?), splitting/linking, supervised learning\n",
    "part_ngrams        = OmniNgramsPart(n_max=2, parts_by_doc=parts_by_doc)\n",
    "dissipation_ngrams = OmniNgrams(n_max=1)\n",
    "throttler = lambda x: overlap(['power','dissipation','mw'], get_aligned_ngrams(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "ce = CandidateExtractor(Part_Dissipation, \n",
    "                        [part_ngrams, dissipation_ngrams], \n",
    "                        [parts_matcher, dissipation_matcher], \n",
    "                        throttler=throttler)\n",
    "\n",
    "for corpus_name in ['Hardware Training', 'Hardware Development']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(\\\n",
    "        corpus.documents, corpus_name + ' Candidates', session)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Dissipation = candidate_subclass('Part_Dissipation', ['part','dissipation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to determine majority label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import CandidateSet\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from hardware_utils import candidates_to_entities, count_labels\n",
    "\n",
    "# # map train candidates to entities\n",
    "# train_candidates = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "# train_entities   = candidates_to_entities(train_candidates)\n",
    "\n",
    "# # get majority label for training set\n",
    "# gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# gold_entities = get_gold_dict(gold_file, attrib='dev_dissipation')\n",
    "# T, F = count_labels()\n",
    "# print \"True: %d, False: %d\" % (T, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Corpus, CandidateSet\n",
    "# from hardware_utils import entity_level_f1\n",
    "\n",
    "# dev_corpus = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "# dev_candidates = get_ORM_instance(CandidateSet, session, 'Hardware Development Candidates')\n",
    "# # dev_entities   = candidates_to_entities(dev_candidates)\n",
    "\n",
    "# # consider all candidates as True\n",
    "# tp = set([c for c in dev_candidates])\n",
    "# fp = set()\n",
    "# tn = set()\n",
    "# fn = set()\n",
    "# TP, FP, FN = entity_level_f1(tp, fp, tn, fn, gold_file, dev_corpus, 'dev_dissipation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Dissipation = candidate_subclass('Part_Dissipation', ['part','dissipation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.models import CandidateSet\n",
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "for set_name in ['Training', 'Development']:\n",
    "    candidate_set_name = 'Hardware %s Candidates' % set_name\n",
    "    candidates = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name).one()\n",
    "    label_set_name = 'Hardware %s Candidates -- Gold' % set_name\n",
    "    annotation_key_name = 'Hardware %s Labels -- Gold' % set_name\n",
    "    %time gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "                           label_set_name, \\\n",
    "                           annotation_key_name, \\\n",
    "                           candidates, \\\n",
    "                           gold_file, \\\n",
    "                           'dev_dissipation')\n",
    "    candidates_gold = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "    print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "        len(candidates_gold), len(candidates), candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ labels snorkel.db');\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Dissipation = candidate_subclass('Part_Dissipation', ['part','dissipation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.fast_annotations import FeatureManager\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "dev   = get_ORM_instance(CandidateSet, session, 'Hardware Development Candidates')\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ featurized');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ featurized snorkel.db');\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Dissipation = candidate_subclass('Part_Dissipation', ['part','dissipation'])\n",
    "\n",
    "# from snorkel.models import CandidateSet\n",
    "# train = session.query(CandidateSet).filter(\n",
    "#     CandidateSet.name == 'Hardware Training Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.fast_annotations import LabelManager\n",
    "from snorkel.lf_helpers import *\n",
    "import re\n",
    "label_manager = LabelManager()\n",
    "\n",
    "LFs = []\n",
    "\n",
    "def LF_complement_phrase_part(c):\n",
    "    return -1 if overlap(['complement','complementary'], \n",
    "                         get_phrase_ngrams(c.part)) else 0\n",
    "LFs.append(LF_complement_phrase_part)\n",
    "\n",
    "def LF_complement_phrase_dissipation(c):\n",
    "    return -1 if overlap(['complement','complementary'], \n",
    "                         get_phrase_ngrams(c.dissipation)) else 0\n",
    "LFs.append(LF_complement_phrase_dissipation)\n",
    "\n",
    "def LF_complement_neighbor_dissipation(c):\n",
    "    return -1 if overlap(['complement','complementary'], \n",
    "                         get_neighbor_phrase_ngrams(c.dissipation)) else 0\n",
    "LFs.append(LF_complement_neighbor_dissipation)\n",
    "\n",
    "def LF_top_mark_col_part(c):\n",
    "    return -1 if overlap(['top','mark'],\n",
    "                         get_col_ngrams(c.part)) else 0\n",
    "LFs.append(LF_top_mark_col_part)\n",
    "\n",
    "def LF_endswith_D_part(c):\n",
    "    return -1 if c.part.get_span().endswith('D') else 0\n",
    "LFs.append(LF_endswith_D_part)\n",
    "\n",
    "def LF_default_positive(c):\n",
    "    return 1 if not overlap(['complement','complementary'],\n",
    "                            chain.from_iterable([\n",
    "                            get_phrase_ngrams(c.part),\n",
    "                            get_phrase_ngrams(c.dissipation),\n",
    "                            get_neighbor_phrase_ngrams(c.dissipation)])) else 0\n",
    "LFs.append(LF_default_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate\n",
    "from hardware_utils import entity_to_candidates\n",
    "\n",
    "candidates = session.query(Candidate).all()\n",
    "print len(candidates)\n",
    "# matches = entity_to_candidates((u'SIEMS01215-1', u'BC856', u'NPN'), candidates)\n",
    "# c = matches[0]\n",
    "c = candidates[0]\n",
    "print candidates[0]\n",
    "\n",
    "print LF_complement_phrase_part(c)\n",
    "print LF_complement_phrase_dissipation(c)\n",
    "print LF_complement_neighbor_dissipation(c)\n",
    "print LF_top_mark_col_part(c)\n",
    "print LF_endswith_D_part(c)\n",
    "print LF_default_positive(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess LF accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "%time L_train.lf_stats(train_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 399 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n",
      "CPU times: user 5.81 s, sys: 239 ms, total: 6.05 s\n",
      "Wall time: 6.07 s\n",
      "CPU times: user 374 ms, sys: 13.8 ms, total: 388 ms\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ features snorkel.db');\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "Part_Dissipation = candidate_subclass('Part_Dissipation', ['part','dissipation'])\n",
    "\n",
    "from snorkel.models import CandidateSet\n",
    "train = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "from snorkel.annotations import FeatureManager, LabelManager\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')\n",
    "\n",
    "label_manager = LabelManager()\n",
    "%time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t6147\n",
      "Features:\t\t\t6\n",
      "================================================================================\n",
      "Begin training for rate=0.01, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.010293\n",
      "\tLearning epoch = 250\tGradient mag. = 0.010638\n",
      "\tLearning epoch = 500\tGradient mag. = 0.010447\n",
      "\tLearning epoch = 750\tGradient mag. = 0.010262\n",
      "\tLearning epoch = 1000\tGradient mag. = 0.010082\n",
      "\tLearning epoch = 1250\tGradient mag. = 0.009907\n",
      "\tLearning epoch = 1500\tGradient mag. = 0.009737\n",
      "\tLearning epoch = 1750\tGradient mag. = 0.009571\n",
      "\tLearning epoch = 2000\tGradient mag. = 0.009410\n",
      "\tLearning epoch = 2250\tGradient mag. = 0.009253\n",
      "\tLearning epoch = 2500\tGradient mag. = 0.009101\n",
      "\tLearning epoch = 2750\tGradient mag. = 0.008953\n",
      "\tLearning epoch = 3000\tGradient mag. = 0.008809\n",
      "\tLearning epoch = 3250\tGradient mag. = 0.008669\n",
      "\tLearning epoch = 3500\tGradient mag. = 0.008532\n",
      "\tLearning epoch = 3750\tGradient mag. = 0.008400\n",
      "\tLearning epoch = 4000\tGradient mag. = 0.008271\n",
      "\tLearning epoch = 4250\tGradient mag. = 0.008145\n",
      "\tLearning epoch = 4500\tGradient mag. = 0.008023\n",
      "\tLearning epoch = 4750\tGradient mag. = 0.007905\n",
      "\tLearning epoch = 5000\tGradient mag. = 0.007789\n",
      "\tLearning epoch = 5250\tGradient mag. = 0.007677\n",
      "\tLearning epoch = 5500\tGradient mag. = 0.007568\n",
      "\tLearning epoch = 5750\tGradient mag. = 0.007463\n",
      "\tLearning epoch = 6000\tGradient mag. = 0.007360\n",
      "\tLearning epoch = 6250\tGradient mag. = 0.007260\n",
      "\tLearning epoch = 6500\tGradient mag. = 0.007163\n",
      "\tLearning epoch = 6750\tGradient mag. = 0.007069\n",
      "\tLearning epoch = 7000\tGradient mag. = 0.006978\n",
      "\tLearning epoch = 7250\tGradient mag. = 0.006890\n",
      "\tLearning epoch = 7500\tGradient mag. = 0.006805\n",
      "\tLearning epoch = 7750\tGradient mag. = 0.006722\n",
      "\tLearning epoch = 8000\tGradient mag. = 0.006642\n",
      "\tLearning epoch = 8250\tGradient mag. = 0.006565\n",
      "\tLearning epoch = 8500\tGradient mag. = 0.006490\n",
      "\tLearning epoch = 8750\tGradient mag. = 0.006418\n",
      "\tLearning epoch = 9000\tGradient mag. = 0.006348\n",
      "\tLearning epoch = 9250\tGradient mag. = 0.006281\n",
      "\tLearning epoch = 9500\tGradient mag. = 0.006217\n",
      "\tLearning epoch = 9750\tGradient mag. = 0.006155\n",
      "\tLearning epoch = 10000\tGradient mag. = 0.006096\n",
      "\tLearning epoch = 10250\tGradient mag. = 0.006039\n",
      "\tLearning epoch = 10500\tGradient mag. = 0.005985\n",
      "\tLearning epoch = 10750\tGradient mag. = 0.005933\n",
      "\tLearning epoch = 11000\tGradient mag. = 0.005883\n",
      "\tLearning epoch = 11250\tGradient mag. = 0.005836\n",
      "\tLearning epoch = 11500\tGradient mag. = 0.005791\n",
      "\tLearning epoch = 11750\tGradient mag. = 0.005749\n",
      "\tLearning epoch = 12000\tGradient mag. = 0.005709\n",
      "\tLearning epoch = 12250\tGradient mag. = 0.005672\n",
      "\tLearning epoch = 12500\tGradient mag. = 0.005636\n",
      "\tLearning epoch = 12750\tGradient mag. = 0.005603\n",
      "\tLearning epoch = 13000\tGradient mag. = 0.005573\n",
      "\tLearning epoch = 13250\tGradient mag. = 0.005544\n",
      "\tLearning epoch = 13500\tGradient mag. = 0.005518\n",
      "\tLearning epoch = 13750\tGradient mag. = 0.005494\n",
      "\tLearning epoch = 14000\tGradient mag. = 0.005473\n",
      "\tLearning epoch = 14250\tGradient mag. = 0.005454\n",
      "\tLearning epoch = 14500\tGradient mag. = 0.005436\n",
      "\tLearning epoch = 14750\tGradient mag. = 0.005422\n",
      "Final gradient magnitude for rate=0.01, mu=1e-06: 0.005\n",
      "CPU times: user 134 ms, sys: 15.6 ms, total: 150 ms\n",
      "Wall time: 153 ms\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=15000, rate=1e-2)\n",
    "%time gen_model.save(session, 'Generative Params')\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t6147\n",
      "Features:\t\t\t16102\n",
      "================================================================================\n",
      "Using gradient descent...\n",
      "\tLearning epoch = 0\tStep size = 1e-05\n",
      "\tLoss = 4260.775719\tGradient magnitude = 298.721469\n",
      "\tLearning epoch = 100\tStep size = 9.04792147114e-06\n",
      "\tLoss = 4254.700548\tGradient magnitude = 52.696830\n",
      "\tLearning epoch = 200\tStep size = 8.18648829479e-06\n",
      "\tLoss = 4253.166191\tGradient magnitude = 37.789619\n",
      "\tLearning epoch = 300\tStep size = 7.40707032156e-06\n",
      "\tLoss = 4252.403175\tGradient magnitude = 30.802047\n",
      "\tLearning epoch = 400\tStep size = 6.70185906007e-06\n",
      "\tLoss = 4251.941239\tGradient magnitude = 26.911635\n",
      "\tLearning epoch = 500\tStep size = 6.06378944861e-06\n",
      "\tLoss = 4251.629708\tGradient magnitude = 24.501080\n",
      "\tLearning epoch = 600\tStep size = 5.48646907485e-06\n",
      "\tLoss = 4251.406324\tGradient magnitude = 22.897253\n",
      "\tLearning epoch = 700\tStep size = 4.96411413431e-06\n",
      "\tLoss = 4251.239887\tGradient magnitude = 21.795142\n",
      "\tLearning epoch = 800\tStep size = 4.4914914861e-06\n",
      "\tLoss = 4251.112795\tGradient magnitude = 21.018045\n",
      "\tLearning epoch = 900\tStep size = 4.06386622545e-06\n",
      "\tLoss = 4251.014492\tGradient magnitude = 20.478276\n",
      "\tLearning epoch = 1000\tStep size = 3.67695424771e-06\n",
      "\tLoss = 4250.938154\tGradient magnitude = 20.105637\n",
      "\tLearning epoch = 1100\tStep size = 3.32687932862e-06\n",
      "\tLoss = 4250.878660\tGradient magnitude = 19.846968\n",
      "\tLearning epoch = 1200\tStep size = 3.01013429093e-06\n",
      "\tLoss = 4250.832473\tGradient magnitude = 19.711460\n",
      "\tLearning epoch = 1300\tStep size = 2.72354586819e-06\n",
      "\tLoss = 4250.797271\tGradient magnitude = 19.667884\n",
      "\tLearning epoch = 1400\tStep size = 2.46424291385e-06\n",
      "\tLoss = 4250.770949\tGradient magnitude = 19.665788\n",
      "\tLearning epoch = 1500\tStep size = 2.22962763703e-06\n",
      "\tLoss = 4250.752339\tGradient magnitude = 19.756092\n",
      "\tLearning epoch = 1600\tStep size = 2.01734957697e-06\n",
      "\tLoss = 4250.740056\tGradient magnitude = 19.913746\n",
      "\tLearning epoch = 1700\tStep size = 1.82528205523e-06\n",
      "\tLoss = 4250.733347\tGradient magnitude = 20.153125\n",
      "\tLearning epoch = 1800\tStep size = 1.65150086984e-06\n",
      "\tLoss = 4250.731461\tGradient magnitude = 20.400290\n",
      "\tLearning epoch = 1900\tStep size = 1.49426501798e-06\n",
      "\tLoss = 4250.733830\tGradient magnitude = 20.678059\n",
      "CPU times: user 3.41 s, sys: 101 ms, total: 3.51 s\n",
      "Wall time: 3.12 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-5)\n",
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "L_dev = label_manager.load(session, dev, 'Hardware Development Labels -- Gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration plot:\n",
      "========================================\n",
      "Recall-corrected Noise-aware Model\n",
      "========================================\n",
      "Pos. class accuracy: 0.147843942505\n",
      "Neg. class accuracy: 0.899094437257\n",
      "Corpus Precision 0.48\n",
      "Corpus Recall    0.148\n",
      "Corpus F1        0.226\n",
      "----------------------------------------\n",
      "TP: 72 | FP: 78 | TN: 695 | FN: 415\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Recall-corrected Noise-aware Model\n",
      "========================================\n",
      "Pos. class accuracy: 0.147843942505\n",
      "Neg. class accuracy: 0.899094437257\n",
      "Corpus Precision 0.48\n",
      "Corpus Recall    0.148\n",
      "Corpus F1        0.226\n",
      "----------------------------------------\n",
      "TP: 72 | FP: 78 | TN: 695 | FN: 415\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_dev, L_dev, dev_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scoring on Entity-Level Gold Data\n",
      "========================================\n",
      "Corpus Precision 0.406\n",
      "Corpus Recall    0.195\n",
      "Corpus F1        0.264\n",
      "----------------------------------------\n",
      "TP: 26 | FP: 38 | FN: 107\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Development').one()\n",
    "(TP, FP, FN) = entity_level_f1(tp, fp, tn, fn, gold_file, corpus, 'dev_dissipation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'BC546_DIOTEC', u'BC546', u'100'),\n",
      " (u'BC546_DIOTEC', u'BC546', u'200'),\n",
      " (u'BC546_DIOTEC', u'BC547', u'100'),\n",
      " (u'BC546_DIOTEC', u'BC547', u'200'),\n",
      " (u'BC550', u'BC546', u'550'),\n",
      " (u'BC550', u'BC549', u'550'),\n",
      " (u'BC550', u'BC550', u'550'),\n",
      " (u'CSEMS05382-1', u'BC546', u'250'),\n",
      " (u'CSEMS05382-1', u'BC546A', u'250'),\n",
      " (u'CSEMS05382-1', u'BC546B', u'250'),\n",
      " (u'CSEMS05382-1', u'BC547', u'250'),\n",
      " (u'CSEMS05382-1', u'BC547A', u'250'),\n",
      " (u'CSEMS05382-1', u'BC547B', u'250'),\n",
      " (u'CSEMS05382-1', u'BC547C', u'250'),\n",
      " (u'CSEMS05382-1', u'BC548', u'250'),\n",
      " (u'CSEMS05382-1', u'BC548A', u'250'),\n",
      " (u'CSEMS05382-1', u'BC548B', u'250'),\n",
      " (u'CSEMS05382-1', u'BC548C', u'250'),\n",
      " (u'DISES00189-1', u'BC546', u'100'),\n",
      " (u'DISES00189-1', u'BC546', u'200'),\n",
      " (u'DISES00189-1', u'BC546XBK', u'100'),\n",
      " (u'DISES00189-1', u'BC546XBK', u'200'),\n",
      " (u'DISES00189-1', u'BC546XBK', u'500'),\n",
      " (u'DISES00189-1', u'BC547', u'100'),\n",
      " (u'DISES00189-1', u'BC547', u'200'),\n",
      " (u'DISES00192-1', u'BC807', u'200'),\n",
      " (u'DISES00192-1', u'BC807', u'800'),\n",
      " (u'DISES00192-1', u'BC807 /', u'200'),\n",
      " (u'DISES00192-1', u'BC807 /', u'310'),\n",
      " (u'DISES00192-1', u'BC807 /', u'800'),\n",
      " (u'DISES00192-1', u'BC808', u'200'),\n",
      " (u'DISES00192-1', u'BC808', u'800'),\n",
      " (u'LITES00690-1', u'BC556', u'500'),\n",
      " (u'LITES00690-1', u'BC557', u'500'),\n",
      " (u'LITES00690-1', u'BC558', u'500'),\n",
      " (u'MMBT3904', u'2N3904', u'625'),\n",
      " (u'MMBT3904', u'MMBT3904', u'625'),\n",
      " (u'MMBT3904', u'PZT3904', u'625')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "FP_list = sorted(list(FP))\n",
    "pprint(FP_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'BC546_DIOTEC', u'BC546', u'100')\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0c46131128dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_to_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# print \"# Matches: %d\" % len(matches)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# print candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from hardware_utils import entity_to_candidates\n",
    "\n",
    "for i in range(1):\n",
    "    entity = FP_list[i]\n",
    "    print entity\n",
    "    print\n",
    "\n",
    "    matches = entity_to_candidates(entity, fp)\n",
    "    # print \"# Matches: %d\" % len(matches)\n",
    "    candidate = matches[0]\n",
    "    # print candidate\n",
    "    print\n",
    "\n",
    "    print disc_model.get_candidate_score(candidate, F_dev)\n",
    "    print\n",
    "    pprint(disc_model.get_candidate_feature_weights(candidate, F_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ngram in candidate.part.get_attrib_tokens():\n",
    "    print \"CONTAINS_%s_[%s]\" % ('words'.upper(), ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import part_error_analysis\n",
    "part_error_analysis(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ final');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The End."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
