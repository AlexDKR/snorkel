{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB_V_MAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.parser import CorpusParser, HTMLParser, OmniParser\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.queries import split_corpus\n",
    "\n",
    "html_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_html/'\n",
    "pdf_path  = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware100_pdf/'\n",
    "doc_parser = HTMLParser(path=html_path)\n",
    "context_parser = OmniParser(pdf_path=pdf_path, session=session)\n",
    "cp = CorpusParser(doc_parser, context_parser, max_docs=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time corpus = cp.parse_corpus(name='Hardware', session=session)\n",
    "\n",
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Corpus\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "split_corpus(session, corpus, train=0.8, development=0.2, test=0, seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ corpus');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ corpus snorkel.db');\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "eeca_rgx = ur'([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z]{0,2}[\\/]?[A-Z]{0,2}[0-9]?[A-Z]?([(\\-|\\u2010|\\u2011|\\u2012|\\u2013|\\u2014|\\u2212)][A-Z0-9]{1,7})?([(\\-|\\u2010|\\u2011|\\u2012|\\u2013|\\u2014|\\u2212)][A-Z0-9]{1,2})?)'\n",
    "eeca_matcher = RegexMatchSpan(rgx=eeca_rgx, longest_match_only=True)\n",
    "jedec_rgx = '([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)'\n",
    "jedec_matcher = RegexMatchSpan(rgx=jedec_rgx, longest_match_only=True)\n",
    "jis_rgx = '(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})'\n",
    "jis_matcher = RegexMatchSpan(rgx=jis_rgx, longest_match_only=True)\n",
    "others_rgx = '((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)'\n",
    "others_matcher = RegexMatchSpan(rgx=others_rgx, longest_match_only=True)\n",
    "# parts_rgx = '|'.join([eeca_rgx, jedec_rgx, jis_rgx, others_rgx])\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)\n",
    "\n",
    "#NOTE: This is super specific.\n",
    "temp_matcher = RegexMatchSpan(rgx=r'-[5-7][05]', longest_match_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# part_finder = re.compile(parts_rgx, re.I)\n",
    "# print any([part_finder.match(x) for x in ['blue', 'red', 'black', 'green']])\n",
    "# print any([part_finder.match(x) for x in ['blue', 'red', 'BC546A', 'green']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ContextSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "[========================================] 100%\n"
     ]
    }
   ],
   "source": [
    "from hardware_utils import get_gold_dict, get_first_pass_dict, OmniNgramsPart, OmniNgramsTemp, merge_two_dicts\n",
    "from collections import defaultdict\n",
    "from snorkel.candidates import OmniNgrams\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.models import Corpus\n",
    "\n",
    "eeca_suffix = '^(A|B|C|-16|-25|-40|16|25|40)$'\n",
    "suffix_matcher = RegexMatchSpan(rgx=eeca_suffix, ignore_case=False)\n",
    "suffix_ngrams = OmniNgrams(n_max=1)\n",
    "part_ngrams = OmniNgramsPart(n_max=5)\n",
    "\n",
    "\n",
    "dev_corpus = get_ORM_instance(Corpus, session, \"Hardware Development\")\n",
    "\n",
    "train_corpus = get_ORM_instance(Corpus, session, \"Hardware Training\")\n",
    "\n",
    "\n",
    "parts_dev, s_dev, p_dev = get_first_pass_dict(dev_corpus.documents, parts_matcher=parts_matcher, part_ngrams=part_ngrams, suffix_matcher=suffix_matcher, suffix_ngrams=suffix_ngrams)      \n",
    "\n",
    "parts_train, s_train, p_train = get_first_pass_dict(train_corpus.documents, parts_matcher=parts_matcher, part_ngrams=part_ngrams, suffix_matcher=suffix_matcher, suffix_ngrams=suffix_ngrams)  \n",
    "\n",
    "parts_by_doc = merge_two_dicts(parts_dev, parts_train)\n",
    "    \n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=parts_by_doc, n_max=5)\n",
    "\n",
    "# TODO: This is missing the current represented as an Amp rather than a milliamp\n",
    "temp_ngrams = OmniNgramsTemp(n_max=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Throttler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import *\n",
    "\n",
    "def part_throttler((part_span, attr_span)):\n",
    "    \"\"\"\n",
    "    Keep only those candidates where both spans are on the same page and\n",
    "    either aligned in the same table (visually or structurally) or the part is global.\n",
    "    \"\"\"\n",
    "    # TODO: Write this in an easier to tweak way. No reason to try and\n",
    "    # cram it all into a single return statement.\n",
    "    return(\n",
    "        same_page((part_span, attr_span)) and\n",
    "        (part_span.parent.table is None or\n",
    "        (same_row((part_span, attr_span)) or is_horz_aligned((part_span, attr_span)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CandidateExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Candidates from Corpus (Hardware Training)\n",
      "[=============================           ] 70%"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0bc9fafaca58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ORM_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Extracting Candidates from %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"time candidates = ce.extract(        corpus.documents, corpus_name + ' Candidates', session)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%s contains %d Candidates\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lwhsiao/repos/snorkel/.virtualenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lwhsiao/repos/snorkel/.virtualenv/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/lwhsiao/repos/snorkel/.virtualenv/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lwhsiao/repos/snorkel/.virtualenv/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/lwhsiao/repos/snorkel/snorkel/candidates.pyc\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, contexts, name, session, parallelism)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_from_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parallelism is not yet implemented.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lwhsiao/repos/snorkel/snorkel/candidates.pyc\u001b[0m in \u001b[0;36m_extract_from_context\u001b[0;34m(self, context, candidate_set, session)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# (throttler returns whether or not proposed candidate passes throttling condition)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrottler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrottler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-232fa1f14d49>\u001b[0m in \u001b[0;36mpart_throttler\u001b[0;34m((part_span, attr_span))\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# cram it all into a single return statement.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     return(\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msame_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_span\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_span\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         (part_span.parent.table is None or\n\u001b[1;32m     13\u001b[0m         (same_row((part_span, attr_span)) or is_horz_aligned((part_span, attr_span)))))\n",
      "\u001b[0;32m/home/lwhsiao/repos/snorkel/snorkel/lf_helpers.pyc\u001b[0m in \u001b[0;36msame_page\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    561\u001b[0m     return (all([_bbox_from_span(c[i]).page is not None and \n\u001b[1;32m    562\u001b[0m                  \u001b[0m_bbox_from_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_bbox_from_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                  for i in range(len(c))]))\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_horz_aligned_ngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'page'"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "\n",
    "ce = CandidateExtractor(Part_Temp, \n",
    "                        [part_ngrams, temp_ngrams], \n",
    "                        [parts_matcher, temp_matcher],\n",
    "                        throttler=part_throttler)\n",
    "\n",
    "for corpus_name in ['Hardware Training', 'Hardware Development']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(\\\n",
    "        corpus.documents, corpus_name + ' Candidates', session)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import entity_level_total_recall, most_common_document, get_gold_dict\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.models import Candidate, Corpus\n",
    "\n",
    "all_candidates = session.query(Candidate).all()\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "(tp, fp, fn) = entity_level_total_recall(\n",
    "    all_candidates, gold_file, 'cb_v_max', corpus=corpus, relation=True, integerize=True)\n",
    "print len(tp)\n",
    "print len(fp)\n",
    "print len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "fns = list(fn)\n",
    "pprint(sorted(fns)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "# for document in corpus.documents:\n",
    "# #     print document.name\n",
    "#     if document.name == 'MOTOS03160-1':\n",
    "#         doc = document\n",
    "# print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for c in all_candidates:\n",
    "#     if c.part.get_span()=='BC183' and c.part.parent.document.name=='MOTOS03160-1':\n",
    "#         print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for phrase in doc.phrases:\n",
    "#     if 'BC183' in phrase.words:\n",
    "#         print phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "# import os\n",
    "# os.remove('snorkel.db');\n",
    "# os.system('cp snorkel.db\\ candidates snorkel.db');\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()\n",
    "\n",
    "# from snorkel.models import candidate_subclass\n",
    "# Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.models import CandidateSet\n",
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "for set_name in ['Training', 'Development']:\n",
    "    candidate_set_name = 'Hardware %s Candidates' % set_name\n",
    "    candidates = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name).one()\n",
    "    label_set_name = 'Hardware %s Candidates -- Gold' % set_name\n",
    "    annotation_key_name = 'Hardware %s Labels -- Gold' % set_name\n",
    "    %time gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "                           label_set_name, \\\n",
    "                           annotation_key_name, \\\n",
    "                           candidates, \\\n",
    "                           gold_file, \\\n",
    "                           attrib='cb_v_max')\n",
    "    candidates_gold = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "    print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "        len(candidates_gold), len(candidates), candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ labels snorkel.db');\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.fast_annotations import FeatureManager\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "dev   = get_ORM_instance(CandidateSet, session, 'Hardware Development Candidates')\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.create(session, train, 'Train Features')\n",
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', expand_key_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ featurized');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ featurized snorkel.db');\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])\n",
    "from snorkel.models import CandidateSet\n",
    "train = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.fast_annotations import LabelManager\n",
    "from snorkel.lf_helpers import *\n",
    "label_manager = LabelManager()\n",
    "\n",
    "LFs = []\n",
    "\n",
    "###################################################################\n",
    "# BOTH\n",
    "###################################################################\n",
    "\n",
    "# cb_words_individual = set(['collector', 'base', 'voltage'])\n",
    "# cb_words_together = set(['collector-base', 'voltage'])\n",
    "cb_words = set(['collector base', 'collector-base', 'collector - base'])\n",
    "def LF_cb_keywords_all(c):\n",
    "    return 1 if overlap(cb_words, get_row_ngrams(c.voltage, spread=[0,3], n_max=3)) else -1\n",
    "LFs.append(LF_cb_keywords_all)\n",
    "\n",
    "###################################################################\n",
    "# POSITIVE\n",
    "###################################################################\n",
    "    \n",
    "pos_keys = set(['cbo', 'vcbo']) # 'value', 'rating'\n",
    "def LF_pos_keywords_in_row(c):\n",
    "    return 1 if overlap(pos_keys, get_row_ngrams(c.voltage, spread=[0,3])) else 0\n",
    "LFs.append(LF_pos_keywords_in_row)\n",
    "\n",
    "def LF_pos_keywords_horz(c):\n",
    "    return 1 if overlap(pos_keys, get_horz_aligned_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_pos_keywords_horz)\n",
    "\n",
    "###################################################################\n",
    "# NEGATIVE\n",
    "###################################################################\n",
    "\n",
    "eeca_rgx = '([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)'\n",
    "jedec_rgx = '([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)'\n",
    "jis_rgx = '(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})'\n",
    "others_rgx = '((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)'\n",
    "parts_rgx = '|'.join([eeca_rgx, jedec_rgx, jis_rgx, others_rgx])\n",
    "part_sniffer = re.compile(parts_rgx)\n",
    "def LF_cheating_with_another_part(c):\n",
    "    return -1 if (any(part_sniffer.match(x) for x in get_horz_aligned_ngrams(c)) and \n",
    "                     not is_horz_aligned(c)) else 0\n",
    "LFs.append(LF_cheating_with_another_part)\n",
    "\n",
    "def LF_same_table_must_align(c):\n",
    "    part_row_ngrams    = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=2))\n",
    "    volt_row_ngrams = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=2))\n",
    "    return -1 if (overlap(part_row_ngrams, cb_words) and \n",
    "                  overlap(volt_row_ngrams, cb_words) and\n",
    "                  not is_horz_aligned(c)) else 0\n",
    "LFs.append(LF_same_table_must_align)\n",
    "\n",
    "# A good LF, but made obsolete by the throttling condition\n",
    "def LF_not_horz_aligned(c):\n",
    "    return -1 if (same_table(c) and not is_horz_aligned(c)) else 0\n",
    "LFs.append(LF_not_horz_aligned)\n",
    "\n",
    "def LF_voltage_not_in_table(c):\n",
    "    return -1 if c.voltage.parent.table is None else 0\n",
    "LFs.append(LF_voltage_not_in_table)\n",
    "\n",
    "def LF_low_table_num(c):\n",
    "    return -1 if (c.voltage.parent.table and\n",
    "        c.voltage.parent.table.position > 2) else 0\n",
    "LFs.append(LF_low_table_num)\n",
    "\n",
    "neg_keys = set(['continuous', 'emitter', 'cut-off', 'gain'])\n",
    "def LF_specific_neg_row_keywords(c):\n",
    "    return -1 if overlap(neg_keys, get_row_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_specific_neg_row_keywords)\n",
    "\n",
    "def LF_equals_in_row(c):\n",
    "    return -1 if overlap('=', get_row_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_equals_in_row)\n",
    "\n",
    "def LF_i_in_row(c):\n",
    "    return -1 if overlap('i', get_row_ngrams(c.voltage)) else 0\n",
    "LFs.append(LF_i_in_row)\n",
    "\n",
    "def LF_too_many_numbers_row(c):\n",
    "    num_numbers = list(get_row_ngrams(c.voltage, attrib=\"ner_tags\")).count('number')\n",
    "    return -1 if num_numbers >= 4 else 0\n",
    "LFs.append(LF_too_many_numbers_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.utils import ProgressBar\n",
    "\n",
    "# train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "dev   = get_ORM_instance(CandidateSet, session, 'Hardware Development Candidates')\n",
    "\n",
    "tp = set()\n",
    "fp = set()\n",
    "fn = set()\n",
    "tn = set()\n",
    "pb = ProgressBar(len(dev))\n",
    "\n",
    "def heuristic(c): \n",
    "    return LF_cb_keywords_all(c) == 1 and not (\n",
    "        LF_cheating_with_another_part(c) or\n",
    "        LF_not_horz_aligned(c) or\n",
    "        LF_voltage_not_in_table(c) or\n",
    "        LF_same_table_must_align(c) or\n",
    "        LF_specific_neg_row_keywords(c) or\n",
    "        LF_equals_in_row(c) or\n",
    "        LF_i_in_row(c) or\n",
    "        LF_too_many_numbers_row(c)\n",
    "        )\n",
    "\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from snorkel.models import Candidate\n",
    "# all_candidates = session.query(Candidate).all()\n",
    "\n",
    "for i, c in enumerate(dev):\n",
    "    pb.bar(i)\n",
    "    if heuristic(c):\n",
    "        tp.add(c)\n",
    "    else:\n",
    "        tn.add(c)\n",
    "pb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(dev)\n",
    "print len(tp) + len(tn)\n",
    "print len(tp)\n",
    "print len(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess LF accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "%time L_train.lf_stats(train_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ features snorkel.db');\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "Part_Voltage = candidate_subclass('Part_Voltage', ['part','voltage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.fast_annotations import FeatureManager, LabelManager\n",
    "from snorkel.models import CandidateSet\n",
    "train = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "%time F_train = feature_manager.load(session, train, 'Train Features')\n",
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')\n",
    "\n",
    "label_manager = LabelManager()\n",
    "%time L_train = label_manager.load(session, train, 'LF Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=100000, rate=1e-6)\n",
    "%time gen_model.save(session, 'Generative Params')\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=2000, rate=1e-4)\n",
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates -- Gold').one()\n",
    "\n",
    "dev_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates -- Gold').one()\n",
    "\n",
    "from snorkel.models import CandidateSet\n",
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "L_dev = label_manager.load(session, dev, 'Hardware Development Labels -- Gold')\n",
    "\n",
    "tp, fp, tn, fn = disc_model.score(F_dev, L_dev, dev_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from hardware_utils import entity_level_f1\n",
    "import os\n",
    "\n",
    "dev_corpus = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Development').one()\n",
    "(TP, FP, FN) = entity_level_f1(tp, fp, tn, fn, gold_file, dev_corpus, 'cb_v_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "FN_list = sorted(list(FN))\n",
    "FP_list = sorted(list(FP))\n",
    "TP_list = sorted(list(TP))\n",
    "# pprint(FN_list[:])\n",
    "pprint(FN_list[:10])\n",
    "# pprint(TP_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# docs = set()\n",
    "# for doc in corpus.documents:\n",
    "#     docs.add(doc.name.upper())\n",
    "# pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# docs = set()\n",
    "# for f in itertools.chain.from_iterable([tp, tn, fp, fn]):\n",
    "#     docs.add(f.part.parent.document.name.upper())\n",
    "# #     if f.part.parent.document.name.upper() == 'AUKCS04635-1':\n",
    "# #         print f\n",
    "# pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import entity_to_candidates, part_error_analysis\n",
    "\n",
    "# disc_model.get_feature_weights(F_dev)\n",
    "\n",
    "entity = FN_list[0]\n",
    "matches = entity_to_candidates(entity, dev)\n",
    "print \"Entity: (%d matches)\" % len(matches)\n",
    "print entity\n",
    "\n",
    "stop = False\n",
    "for i, c in enumerate(matches):\n",
    "    part_error_analysis(c)\n",
    "    results = []\n",
    "    for lf in LFs:\n",
    "        name = lf.__name__\n",
    "        result = lf(c)\n",
    "        results.append((name, result))\n",
    "#         if name == 'LF_cb_keywords_all' and result == -1:\n",
    "#             print name\n",
    "#             ngrams = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=3))\n",
    "#             print ngrams\n",
    "#             print overlap(ngrams, cb_words)\n",
    "#             stop = False\n",
    "#         if name == 'LF_cheating_with_another_part' and result == -1:\n",
    "#             print name\n",
    "#             horz_ngrams = list(get_horz_aligned_ngrams(c))\n",
    "#             print horz_ngrams\n",
    "#             print [part_sniffer.match(x) for x in horz_ngrams]\n",
    "#             stop = False\n",
    "        if name == 'LF_i_in_row' and result == -1:\n",
    "            print name\n",
    "            ngrams = list(get_row_ngrams(c.voltage, spread=[0,3], n_max=3))\n",
    "            print ngrams\n",
    "            stop = False\n",
    "        if stop: break\n",
    "    print \"MATCH %d:\" % i\n",
    "    print heuristic(c)\n",
    "    pprint(results)\n",
    "    print \"--------------------------------------------------------------------------------\"\n",
    "    if stop: break\n",
    "    \n",
    "#     if heuristic(candidate):\n",
    "#         print \"\\nCandidate:\"\n",
    "# #         print candidate\n",
    "#         print part_error_analysis(candidate)\n",
    "#     print heuristic(candidate)\n",
    "#     print LF_voltage_not_in_table(candidate)\n",
    "#         print candidate.voltage.parent.table\n",
    "#     print \"\\nScore:\"\n",
    "#     print disc_model.get_candidate_score(candidate, F_dev)\n",
    "\n",
    "#     print \"\\nFeatures:\"\n",
    "#     pprint(disc_model.get_candidate_feature_weights(candidate, F_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate[0].parent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate[0].get_span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for lf in LFs:\n",
    "    results.append(lf.__name__, lf(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print F_train.shape\n",
    "print F_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ final');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def LF_first_row(c):\n",
    "#     if c.voltage.parent.row_num == 0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "# LFs.append(LF_first_row)\n",
    "    \n",
    "# def LF_not_ce_relevant(c):\n",
    "#     ce_keywords = set(['collector', 'emitter', 'collector-emitter'])\n",
    "#     ngrams = set(get_aligned_ngrams(c.voltage))\n",
    "#     if not set_any_in_set(ce_keywords, ngrams):\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 1\n",
    "# LFs.append(LF_not_ce_relevant)\n",
    "\n",
    "# def LF_negative_keywords(c):\n",
    "#     row_neg_keys = set(['ambient',\n",
    "#                     'small-signal',\n",
    "#                     'cut-off',\n",
    "#                     'na',\n",
    "#                     'ma',\n",
    "#                     'cex',\n",
    "#                     'resistance',\n",
    "#                     'power',\n",
    "#                     'junction',\n",
    "#                     'dissipation', \n",
    "#                     'breakdown',\n",
    "#                     'current',\n",
    "#                     'ceo',\n",
    "#                     'vceo'\n",
    "#                     'peak',\n",
    "#                     '=',\n",
    "#                     'f',\n",
    "#                     'p',\n",
    "#                     'base',\n",
    "#                     'mw',\n",
    "#                     'ebo',\n",
    "#                     'vebo',\n",
    "#                     'i c',\n",
    "#                     'total',\n",
    "#                     'device',\n",
    "#                     'c',\n",
    "#                     'mhz',\n",
    "#                     'temperature',\n",
    "#                     'saturation',\n",
    "#                     'operating',\n",
    "#                     'storage'\n",
    "#                     'bandwidth',\n",
    "#                     'derate',\n",
    "#                     'above',\n",
    "#                     'product',\n",
    "#                     'figure',\n",
    "#                     'conditions',\n",
    "#                     'current gain',\n",
    "#                     'saturation',\n",
    "#                     'min',\n",
    "#                     'min.',\n",
    "#                     'typ',\n",
    "#                     'typ.',\n",
    "#                     'max',\n",
    "#                     'max.',\n",
    "#                     'gain',\n",
    "#                     'p',\n",
    "#                     'thermal',\n",
    "#                     'test'])\n",
    "#     row_ngrams = set(get_row_ngrams(c.voltage))\n",
    "#     col_ngrams = set(get_col_ngrams(c.voltage))\n",
    "#     col_neg_keys = set(['conditions', \n",
    "#                         'condition', \n",
    "#                         'parameter', \n",
    "#                         'min',\n",
    "#                         'min.',\n",
    "#                         'typ',\n",
    "#                         'typ.',\n",
    "#                         'max',\n",
    "#                         'max.',\n",
    "#                         'test'])\n",
    "#     if set_any_in_set(row_neg_keys, row_ngrams):\n",
    "#         return -1\n",
    "#     if set_any_in_set(col_neg_keys, col_ngrams):\n",
    "#         return -1\n",
    "#     return 0\n",
    "# LFs.append(LF_negative_keywords)\n",
    "    \n",
    "# def LF_negative_keywords_in_col(c):\n",
    "#     neg_keys = set(['conditions',\n",
    "#                     'condition',\n",
    "#                     'parameter',\n",
    "#                     'test'])\n",
    "#     ngrams = set(get_col_ngrams(c.voltage))\n",
    "#     if set_any_in_set(neg_keys, ngrams):\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "# LFs.append(LF_negative_keywords_in_col)\n",
    "\n",
    "# def LF_negative_keywords_in_part_aligned(c):\n",
    "#     ngrams = set(get_aligned_ngrams(c.part))\n",
    "#     return -1 if (\n",
    "#         'gain'          in ngrams or\n",
    "#         'small-signal'  in ngrams or\n",
    "#         'small'         in ngrams or\n",
    "#         'cbo'         in ngrams or\n",
    "#         'collector-emitter' in ngrams or\n",
    "#         'value'         in ngrams or\n",
    "#         'thermal'       in ngrams) else 0\n",
    "# LFs.append(LF_negative_keywords_in_part_aligned)\n",
    "\n",
    "# def LF_negative_keywords(c):\n",
    "#     ngrams = set(get_aligned_ngrams(c.voltage))\n",
    "#     return -1 if (\n",
    "#         'collector-base'    in ngrams or\n",
    "#         'cut-off'           in ngrams or\n",
    "#         '='                 in ngrams or\n",
    "#         'gain'              in ngrams or\n",
    "#         'h fe'              in ngrams or\n",
    "#         'typ.'              in ngrams or\n",
    "#         'typ'               in ngrams or\n",
    "#         'min'               in ngrams or\n",
    "#         'min.'              in ngrams or\n",
    "#         'saturation'        in ngrams or\n",
    "#         'mhz'               in ngrams or\n",
    "#         'gain'              in ngrams or\n",
    "#         'obo'               in ngrams or\n",
    "#         'c obo'             in ngrams) else 0\n",
    "# LFs.append(LF_negative_keywords)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
