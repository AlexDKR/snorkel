{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables Total Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to get to the point where we can extract 100% of part names from transistor hardware sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 588 ms, total: 13.3 s\n",
      "Wall time: 13.5 s\n",
      "Corpus has been loaded.\n"
     ]
    }
   ],
   "source": [
    "load_pickle = True # This takes 12sec\n",
    "save_pickle = False # Saved all the documents last time. Took 30min.\n",
    "\n",
    "corpus_loaded = False\n",
    "if load_pickle:\n",
    "    try:\n",
    "        import cPickle\n",
    "        with open(\"data/hardware/hardware_corpus.pkl\",\"r\") as pkl:\n",
    "            %time corpus = cPickle.load(pkl)\n",
    "        corpus_loaded = True\n",
    "        print \"Corpus has been loaded.\"\n",
    "    except:\n",
    "        print \"Corpus could not be loaded.\"\n",
    "        print \"Corpus will be parsed instead...\"\n",
    "if not corpus_loaded:\n",
    "    from snorkel.parser import CorpusParser\n",
    "    from snorkel.parser import HTMLParser\n",
    "    from snorkel.parser import TableParser, OmniParser\n",
    "\n",
    "    doc_parser = HTMLParser(path='data/hardware/hardware_html/')\n",
    "    context_parser = TableParser()\n",
    "\n",
    "    cp = CorpusParser(doc_parser, context_parser, max_docs=101)\n",
    "    %time corpus = cp.parse_corpus(name='Hardware Corpus')\n",
    "    print \"Corpus has been parsed.\"\n",
    "    \n",
    "    if save_pickle:\n",
    "        with open(\"data/hardware/hardware_corpus.pkl\",\"w\") as pkl:\n",
    "            %time cPickle.dump(corpus, pkl)\n",
    "            print \"Corpus has been pickled.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 542 gold (doc, part) pairs.\n"
     ]
    }
   ],
   "source": [
    "from utils import collect_hardware_doc_part_pairs\n",
    "filename='data/hardware/gold_all.csv'\n",
    "gold_pairs = collect_hardware_doc_part_pairs(filename)\n",
    "(gold_docs, gold_parts) = zip(*gold_pairs)\n",
    "print \"Loaded %s gold (doc, part) pairs.\" % len(gold_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 s, sys: 13.6 ms, total: 1.69 s\n",
      "Wall time: 1.7 s\n",
      "Span(\"BC547\", context=None, chars=[0,4], words=[0,0])\n",
      "Span(\"BC548\", context=None, chars=[0,4], words=[0,0])\n",
      "Span(\"BC547\", context=None, chars=[0,4], words=[0,0])\n",
      "Extracted 1125 candidate part numbers.\n"
     ]
    }
   ],
   "source": [
    "from snorkel.candidates import Ngrams, EntityExtractor\n",
    "from snorkel.matchers import RegexMatchEach, DictionaryMatch, RangeMatcher\n",
    "\n",
    "ngrams = Ngrams(n_max=2)\n",
    "part_matcher = DictionaryMatch(d=gold_parts)\n",
    "part_extractor = EntityExtractor(ngrams, part_matcher)\n",
    "\n",
    "%time parts = part_extractor.extract(corpus.get_phrases(), name='all')\n",
    "for p in parts[:3]: \n",
    "    print p\n",
    "print \"Extracted %s candidate part numbers.\" % len(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(g, x):\n",
    "    tp = len(g.intersection(x))\n",
    "    fp = len(x.difference(g))\n",
    "    fn = len(g.difference(x))\n",
    "    precision = float(tp)/(tp + fp)\n",
    "    recall = float(tp)/(tp + fn)\n",
    "    print \"Precision: %0.3f (%s/%s)\" % (precision, tp, tp + fp)\n",
    "    print \"Recall: %0.3f (%s/%s)\" % (recall, tp, tp + fn)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part Stats:\n",
      "Precision: 1.000 (144/144)\n",
      "Recall: 0.804 (144/179)\n"
     ]
    }
   ],
   "source": [
    "g = set(gold_parts)\n",
    "x = set([p.get_span() for p in parts])\n",
    "print \"Part Stats:\"\n",
    "print_stats(g, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair Stats:\n",
      "Precision: 0.691 (251/363)\n",
      "Recall: 0.463 (251/542)\n"
     ]
    }
   ],
   "source": [
    "g = set(gold_pairs)\n",
    "x = set([(p.context.document.name, p.get_span()) for p in parts])\n",
    "print \"Pair Stats:\"\n",
    "print_stats(g, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
