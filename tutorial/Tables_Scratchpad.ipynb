{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables Scratchpad\n",
    "\n",
    "This notebook is meant for in-house demonstration of candidate extraction and featurization of tables. It assumes an input file in XHTML format, a strict form of HTML that coincides with XML structure, allowing for easy display (HTML) and safe tree traversal (XML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of snorkel.candidates failed: Traceback (most recent call last):\n",
      "  File \"/Users/bradenhancock/anaconda/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/bradenhancock/snorkel/snorkel/candidates.py\", line 208\n",
      "    yield Ngram(char_start=char_start, char_end=char_start + m.start(1) - 1, context=context)\n",
      "        ^\n",
      "IndentationError: expected an indented block\n",
      "]\n",
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/sqlalchemy/ext/declarative/clsregistry.py:120: SAWarning: This declarative base already contains a class with the same class name and module name as snorkel.models.candidate.CandidateSet, and will be replaced in the string-lookup table.\n",
      "  item.__name__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of snorkel.models.candidate failed: Traceback (most recent call last):\n",
      "  File \"/Users/bradenhancock/anaconda/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "InvalidRequestError: Table 'candidate_set' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Extraction\n",
    "\n",
    "First, import the 'HTMLParser' class to read HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/diseases/diseases.xhtml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"TableParser\" class divides the html doc into cells, adding a 'cell_id' attribute to each cell for future traversal, and creating \"Cell\" objects that have attributes such as row number, column number, html tag, html attributes, and any tags/attributes on a cells ancestors in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, pass these to a Corpus object for digestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 ms, sys: 11.5 ms, total: 49.5 ms\n",
      "Wall time: 73.1 ms\n"
     ]
    }
   ],
   "source": [
    "# from snorkel.parser import Corpus\n",
    "# %time corpus = Corpus(html_parser, table_parser)\n",
    "\n",
    "from snorkel.parser import CorpusParser\n",
    "cp = CorpusParser(html_parser, table_parser)\n",
    "%time corpus = cp.parse_corpus(name='Diseases Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase('0', 0, 0, 0, u'Disease')\n",
      "Phrase('0', 0, 0, 1, u'Location')\n",
      "Phrase('0', 0, 0, 2, u'Year')\n",
      "Phrase('0', 0, 0, 3, u'Polio')\n",
      "Phrase('0', 0, 0, 4, u'New York')\n",
      "Phrase('0', 0, 0, 5, u'1914')\n",
      "Phrase('0', 0, 0, 6, u\"I don't like Chicken Pox.\")\n",
      "Phrase('0', 0, 0, 7, u'The plague is also bad.')\n",
      "Phrase('0', 0, 0, 8, u'Boston')\n",
      "Phrase('0', 0, 0, 9, u'2001')\n",
      "Phrase('0', 0, 0, 10, u'Scurvy')\n",
      "Phrase('0', 0, 0, 11, u'Annapolis')\n",
      "Phrase('0', 0, 0, 12, u'1901')\n",
      "Phrase('0', 1, 0, 0, u'Problem')\n",
      "Phrase('0', 1, 0, 1, u'Cause')\n",
      "Phrase('0', 1, 0, 2, u'Cost')\n",
      "Phrase('0', 1, 0, 3, u'Arthritis')\n",
      "Phrase('0', 1, 0, 4, u'Pokemon Go')\n",
      "Phrase('0', 1, 0, 5, u'Free')\n",
      "Phrase('0', 1, 0, 6, u'Yellow Fever')\n",
      "Phrase('0', 1, 0, 7, u'Unicorns')\n",
      "Phrase('0', 1, 0, 8, u'$17.75')\n",
      "Phrase('0', 1, 0, 9, u'Hypochondria')\n",
      "Phrase('0', 1, 0, 10, u'Fear')\n",
      "Phrase('0', 1, 0, 11, u'$100')\n"
     ]
    }
   ],
   "source": [
    "doc = corpus.documents[0]\n",
    "for phrase in doc.phrases: print phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the good 'ole disease dictionary for recognizing disease names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 507899 disease phrases!\n"
     ]
    }
   ],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a new CandidateSpace object, CellNgrams. It inherits from Ngrams, and ensures that the Table context object is broken up into cells before being passed into the usual routine for pulling out Ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# Define a candidate space\n",
    "table_ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "disease_matcher = DictionaryMatch(d=diseases, longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the CandidateSpace, Matcher, and Context objects to a Candidates object, extraction is performed, and we see that a number of disease CellNgrams are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 ms, sys: 1.13 ms, total: 4.5 ms\n",
      "Wall time: 3.96 ms\n",
      "Span(\"Disease\", context=None, chars=[0,6], words=[0,0])\n",
      "Span(\"Location\", context=None, chars=[0,7], words=[0,0])\n",
      "Span(\"Polio\", context=None, chars=[0,4], words=[0,0])\n",
      "Span(\"Chicken Pox\", context=None, chars=[13,23], words=[4,5])\n",
      "Span(\"plague\", context=None, chars=[4,9], words=[1,1])\n",
      "Span(\"Scurvy\", context=None, chars=[0,5], words=[0,0])\n",
      "Span(\"Problem\", context=None, chars=[0,6], words=[0,0])\n",
      "Span(\"Arthritis\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"Yellow Fever\", context=None, chars=[0,11], words=[0,1])\n",
      "Span(\"Fever\", context=None, chars=[7,11], words=[1,1])\n",
      "Span(\"Hypochondria\", context=None, chars=[0,11], words=[0,0])\n"
     ]
    }
   ],
   "source": [
    "# With new Candidates object:\n",
    "# from snorkel.candidates import Candidates\n",
    "# %time candidates = Candidates(table_ngrams, disease_matcher, corpus.get_contexts())\n",
    "\n",
    "# With old Candidates object:\n",
    "from snorkel.candidates import EntityExtractor\n",
    "ce = EntityExtractor(table_ngrams, disease_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "for cand in candidates: print cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location\n",
      "year\n",
      "polio\n",
      "new\n",
      "new_york\n",
      "york\n",
      "1914\n",
      "i\n",
      "i_do\n",
      "i_do_n't\n",
      "do\n",
      "do_n't\n",
      "do_n't_like\n",
      "n't\n",
      "n't_like\n",
      "n't_like_chicken\n",
      "like\n",
      "like_chicken\n",
      "like_chicken_pox\n",
      "chicken\n",
      "chicken_pox\n",
      "chicken_pox_.\n",
      "pox\n",
      "pox_.\n",
      ".\n",
      "the\n",
      "the_plague\n",
      "the_plague_is\n",
      "plague\n",
      "plague_is\n",
      "plague_is_also\n",
      "is\n",
      "is_also\n",
      "is_also_bad\n",
      "also\n",
      "also_bad\n",
      "also_bad_.\n",
      "bad\n",
      "bad_.\n",
      ".\n",
      "boston\n",
      "2001\n",
      "scurvy\n",
      "annapolis\n",
      "1901\n"
     ]
    }
   ],
   "source": [
    "c = candidates[0]\n",
    "for ngram in c.row_ngrams('words'): print ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate features on our set of candidates, including *new and improved* table features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11x237 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 888 stored elements in LInked List format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DDLIB_WORD_SEQ_[Location]',\n",
       " u'DDLIB_LEMMA_SEQ_[Location]',\n",
       " u'DDLIB_POS_SEQ_[NNP]',\n",
       " u'DDLIB_DEP_SEQ_[ROOT]',\n",
       " u'DDLIB_W_LEFT_1_[Location]',\n",
       " u'DDLIB_W_LEFT_POS_1_[NNP]',\n",
       " u'DDLIB_STARTS_WITH_CAPITAL',\n",
       " u'DDLIB_NUM_WORDS_1',\n",
       " u'TABLE_ROW_NUM_[0]',\n",
       " u'TABLE_COL_NUM_[0]',\n",
       " u'TABLE_HTML_TAG_th',\n",
       " u'TABLE_HTML_ATTR_style=height:12pt',\n",
       " u'TABLE_HTML_ATTR_type=phenotype',\n",
       " u'TABLE_HTML_ANC_TAG_tr',\n",
       " u'TABLE_HTML_ANC_TAG_tbody',\n",
       " u'TABLE_HTML_ANC_TAG_table',\n",
       " u'TABLE_HTML_ANC_TAG_body',\n",
       " u'TABLE_HTML_ANC_ATTR_style=height:13pt',\n",
       " u'TABLE_HTML_ANC_ATTR_center=left',\n",
       " u'TABLE_HTML_ANC_ATTR_size=2',\n",
       " u'TABLE_HTML_ANC_ATTR_font=blue',\n",
       " u'TABLE_ROW_WORDS_disease',\n",
       " u'TABLE_ROW_WORDS_year',\n",
       " u'TABLE_ROW_WORDS_polio',\n",
       " u'TABLE_ROW_WORDS_new',\n",
       " u'TABLE_ROW_WORDS_new_york',\n",
       " u'TABLE_ROW_WORDS_york',\n",
       " u'TABLE_ROW_WORDS_1914',\n",
       " u'TABLE_ROW_WORDS_i',\n",
       " u'TABLE_ROW_WORDS_i_do',\n",
       " u\"TABLE_ROW_WORDS_i_do_n't\",\n",
       " u'TABLE_ROW_WORDS_do',\n",
       " u\"TABLE_ROW_WORDS_do_n't\",\n",
       " u\"TABLE_ROW_WORDS_do_n't_like\",\n",
       " u\"TABLE_ROW_WORDS_n't\",\n",
       " u\"TABLE_ROW_WORDS_n't_like\",\n",
       " u\"TABLE_ROW_WORDS_n't_like_chicken\",\n",
       " u'TABLE_ROW_WORDS_like',\n",
       " u'TABLE_ROW_WORDS_like_chicken',\n",
       " u'TABLE_ROW_WORDS_like_chicken_pox',\n",
       " u'TABLE_ROW_WORDS_chicken',\n",
       " u'TABLE_ROW_WORDS_chicken_pox',\n",
       " u'TABLE_ROW_WORDS_chicken_pox_.',\n",
       " u'TABLE_ROW_WORDS_pox',\n",
       " u'TABLE_ROW_WORDS_pox_.',\n",
       " u'TABLE_ROW_WORDS_.',\n",
       " u'TABLE_ROW_WORDS_the',\n",
       " u'TABLE_ROW_WORDS_the_plague',\n",
       " u'TABLE_ROW_WORDS_the_plague_is',\n",
       " u'TABLE_ROW_WORDS_plague',\n",
       " u'TABLE_ROW_WORDS_plague_is',\n",
       " u'TABLE_ROW_WORDS_plague_is_also',\n",
       " u'TABLE_ROW_WORDS_is',\n",
       " u'TABLE_ROW_WORDS_is_also',\n",
       " u'TABLE_ROW_WORDS_is_also_bad',\n",
       " u'TABLE_ROW_WORDS_also',\n",
       " u'TABLE_ROW_WORDS_also_bad',\n",
       " u'TABLE_ROW_WORDS_also_bad_.',\n",
       " u'TABLE_ROW_WORDS_bad',\n",
       " u'TABLE_ROW_WORDS_bad_.',\n",
       " u'TABLE_ROW_WORDS_.',\n",
       " u'TABLE_ROW_WORDS_boston',\n",
       " u'TABLE_ROW_WORDS_2001',\n",
       " u'TABLE_ROW_WORDS_scurvy',\n",
       " u'TABLE_ROW_WORDS_annapolis',\n",
       " u'TABLE_ROW_WORDS_1901',\n",
       " u'TABLE_COL_WORDS_disease',\n",
       " u'TABLE_COL_WORDS_year',\n",
       " u'TABLE_COL_WORDS_polio',\n",
       " u'TABLE_COL_WORDS_new',\n",
       " u'TABLE_COL_WORDS_new_york',\n",
       " u'TABLE_COL_WORDS_york',\n",
       " u'TABLE_COL_WORDS_1914',\n",
       " u'TABLE_COL_WORDS_i',\n",
       " u'TABLE_COL_WORDS_i_do',\n",
       " u\"TABLE_COL_WORDS_i_do_n't\",\n",
       " u'TABLE_COL_WORDS_do',\n",
       " u\"TABLE_COL_WORDS_do_n't\",\n",
       " u\"TABLE_COL_WORDS_do_n't_like\",\n",
       " u\"TABLE_COL_WORDS_n't\",\n",
       " u\"TABLE_COL_WORDS_n't_like\",\n",
       " u\"TABLE_COL_WORDS_n't_like_chicken\",\n",
       " u'TABLE_COL_WORDS_like',\n",
       " u'TABLE_COL_WORDS_like_chicken',\n",
       " u'TABLE_COL_WORDS_like_chicken_pox',\n",
       " u'TABLE_COL_WORDS_chicken',\n",
       " u'TABLE_COL_WORDS_chicken_pox',\n",
       " u'TABLE_COL_WORDS_chicken_pox_.',\n",
       " u'TABLE_COL_WORDS_pox',\n",
       " u'TABLE_COL_WORDS_pox_.',\n",
       " u'TABLE_COL_WORDS_.',\n",
       " u'TABLE_COL_WORDS_the',\n",
       " u'TABLE_COL_WORDS_the_plague',\n",
       " u'TABLE_COL_WORDS_the_plague_is',\n",
       " u'TABLE_COL_WORDS_plague',\n",
       " u'TABLE_COL_WORDS_plague_is',\n",
       " u'TABLE_COL_WORDS_plague_is_also',\n",
       " u'TABLE_COL_WORDS_is',\n",
       " u'TABLE_COL_WORDS_is_also',\n",
       " u'TABLE_COL_WORDS_is_also_bad',\n",
       " u'TABLE_COL_WORDS_also',\n",
       " u'TABLE_COL_WORDS_also_bad',\n",
       " u'TABLE_COL_WORDS_also_bad_.',\n",
       " u'TABLE_COL_WORDS_bad',\n",
       " u'TABLE_COL_WORDS_bad_.',\n",
       " u'TABLE_COL_WORDS_.',\n",
       " u'TABLE_COL_WORDS_boston',\n",
       " u'TABLE_COL_WORDS_2001',\n",
       " u'TABLE_COL_WORDS_scurvy',\n",
       " u'TABLE_COL_WORDS_annapolis',\n",
       " u'TABLE_COL_WORDS_1901']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.get_features_by_candidate(candidates[1])[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ta-da! Next up: feeding these features into the learning machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
