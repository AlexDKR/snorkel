{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episode 1: The Phantom [Table] Menace\n",
    "\n",
    "This notebook is meant for in-house demonstration of the the new classes created to perform (still relatively basic) entity extraction on tables. It assumes an input file in XHTML format, a strict form of HTML that coincides with XML structure, allowing for easy display (HTML) and safe tree traversal (XML)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Extraction\n",
    "\n",
    "First, import the 'HTMLParser' class to read HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/diseases.xhtml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"TableParser\" class divides the html doc into cells, adding a 'cell_id' attribute to each cell for future traversal, and creating \"Cell\" objects that have attributes such as row number, column number, html tag, html attributes, and any tags/attributes on a cells ancestors in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, pass these to a Corpus object for digestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing documents...\n",
      "Parsing contexts...\n",
      "CPU times: user 85.7 ms, sys: 24.3 ms, total: 110 ms\n",
      "Wall time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import Corpus\n",
    "%time corpus = Corpus(html_parser, table_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the good 'ole disease dictionary for recognizing disease names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 507899 disease phrases!\n"
     ]
    }
   ],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a new CandidateSpace object, CellNgrams. It inherits from Ngrams, and ensures that the Table context object is broken up into cells before being passed into the usual routine for pulling out Ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import CellNgrams\n",
    "from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# Define a candidate space\n",
    "cell_ngrams = CellNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "disease_matcher = DictionaryMatch(d=diseases, longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the CandidateSpace, Matcher, and Context objects to a Candidates object, extraction is performed, and we see that a number of disease CellNgrams are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting candidates...\n",
      "CPU times: user 2.45 ms, sys: 580 Âµs, total: 3.03 ms\n",
      "Wall time: 2.65 ms\n",
      "<CellNgram(\"Disease\", id=0-0-0:0-6, chars=[0,6], (row,col)=(0,1), tag=th)\n",
      "<CellNgram(\"Polio\", id=0-0-3:0-4, chars=[0,4], (row,col)=(1,1), tag=th)\n",
      "<CellNgram(\"Chicken Pox\", id=0-0-6:0-10, chars=[0,10], (row,col)=(2,1), tag=th)\n",
      "<CellNgram(\"Yellow Fever\", id=0-1-6:0-11, chars=[0,11], (row,col)=(2,1), tag=th)\n",
      "<CellNgram(\"Location\", id=0-0-1:0-7, chars=[0,7], (row,col)=(0,3), tag=th)\n",
      "<CellNgram(\"Arthritis\", id=0-1-3:0-8, chars=[0,8], (row,col)=(1,1), tag=th)\n",
      "<CellNgram(\"Problem\", id=0-1-0:0-6, chars=[0,6], (row,col)=(0,1), tag=th)\n",
      "<CellNgram(\"Scurvy\", id=0-0-9:0-5, chars=[0,5], (row,col)=(3,1), tag=th)\n",
      "<CellNgram(\"Hypochondria\", id=0-1-9:0-11, chars=[0,11], (row,col)=(3,1), tag=th)\n",
      "<CellNgram(\"Fever\", id=0-1-6:7-11, chars=[7,11], (row,col)=(2,1), tag=th)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.candidates import Candidates\n",
    "%time c = Candidates(cell_ngrams, disease_matcher, corpus.get_sentences())\n",
    "for candy in c.get_candidates(): print candy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then examine the basic tabular features on a given CellNGram, which can be added to the feature index Snorkel is accustomed to using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 16)\n"
     ]
    }
   ],
   "source": [
    "features = c.extract_features()\n",
    "print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREEDLIB_features_to come\n",
      "DDLIB_features_to come\n",
      "TABLE_ROW_NUM_0\n",
      "TABLE_COL_NUM_1\n",
      "TABLE_HTML_TAG_th\n",
      "TABLE_HTML_ANC_TAG_tr\n",
      "TABLE_HTML_ANC_TAG_tbody\n",
      "TABLE_HTML_ANC_TAG_table\n",
      "TABLE_HTML_ANC_TAG_body\n",
      "TABLE_HTML_ANC_ATTR_align=left\n",
      "TABLE_HTML_ANC_ATTR_size=5\n",
      "TABLE_HTML_ANC_ATTR_font=blue\n"
     ]
    }
   ],
   "source": [
    "for feat in c.get_candidates()[0]._get_features():\n",
    "    print feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TA-DA! It's magic. Next up (Friday?): scooping up ngrams/features from spans of cells (like \"all ngrams above me in the table\" or \"all ngrams within 2 cells of me\") using simple Xpath queries on the decorated xhtml tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
