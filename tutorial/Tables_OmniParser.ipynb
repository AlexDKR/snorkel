{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables OmniParser\n",
    "This notebook is meant for testing and development of an \"OmniParser\" that can parse all components of an HTML document, including the title, captions, sentences, tables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser import HTMLParser\n",
    "from snorkel.parser import OmniParser\n",
    "doc_parser = HTMLParser(path='data/diseases/diseases.xhtml')\n",
    "context_parser = OmniParser()\n",
    "cp = CorpusParser(doc_parser, context_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def parse_tag(tag):\n",
    "#     if tag.name is not None:\n",
    "#         print tag.name\n",
    "#         print \"---\"\n",
    "#         for child in tag.children:\n",
    "#             parse_tag(child)\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "# with open('data/diseases/diseases.xhtml','r') as f:\n",
    "#     soup = BeautifulSoup(f, 'lxml')\n",
    "# for tag in soup.children:\n",
    "#     parse_tag(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 12.4 ms, total: 115 ms\n",
      "Wall time: 174 ms\n"
     ]
    }
   ],
   "source": [
    "%time corpus = cp.parse_corpus(name='Diseases Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "29\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print len(corpus.documents)\n",
    "print len(corpus.documents[0].tables)\n",
    "print len(corpus.documents[0].phrases)\n",
    "print len(corpus.documents[0].sentences)\n",
    "for sent in corpus.documents[0].sentences: print sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 507899 disease phrases!\n"
     ]
    }
   ],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# Define a candidate space\n",
    "table_ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "disease_matcher = DictionaryMatch(d=diseases, longest_match_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.5 ms, sys: 1.06 ms, total: 46.6 ms\n",
      "Wall time: 48.9 ms\n",
      "Span(\"coughs\", context=None, chars=[18,23], words=[4,4])\n",
      "Span(\"colds\", context=None, chars=[30,34], words=[7,7])\n",
      "Span(\"Brain Cancer\", context=None, chars=[0,11], words=[0,1])\n",
      "Span(\"Brain\", context=None, chars=[0,4], words=[0,0])\n",
      "Span(\"Cancer\", context=None, chars=[6,11], words=[1,1])\n",
      "Span(\"Common\", context=None, chars=[0,5], words=[0,0])\n",
      "Span(\"Ailments\", context=None, chars=[7,14], words=[1,1])\n",
      "Span(\"Disease\", context=None, chars=[0,6], words=[0,0])\n",
      "Span(\"Location\", context=None, chars=[0,7], words=[0,0])\n",
      "Span(\"Polio\", context=None, chars=[0,4], words=[0,0])\n",
      "Span(\"Chicken Pox\", context=None, chars=[13,23], words=[4,5])\n",
      "Span(\"plague\", context=None, chars=[4,9], words=[1,1])\n",
      "Span(\"Scurvy\", context=None, chars=[0,5], words=[0,0])\n",
      "Span(\"Problem\", context=None, chars=[0,6], words=[0,0])\n",
      "Span(\"Arthritis\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"Yellow Fever\", context=None, chars=[0,11], words=[0,1])\n",
      "Span(\"Fever\", context=None, chars=[7,11], words=[1,1])\n",
      "Span(\"Hypochondria\", context=None, chars=[0,11], words=[0,0])\n"
     ]
    }
   ],
   "source": [
    "# With old Candidates object:\n",
    "from snorkel.candidates import EntityExtractor\n",
    "ce = EntityExtractor(table_ngrams, disease_matcher)\n",
    "%time candidates = ce.extract(corpus.get_phrases(), name='all')\n",
    "\n",
    "for cand in candidates: print cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature index...\n",
      "Extracting features...\n",
      "0/371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<18x371 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 645 stored elements in LInked List format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DDLIB_WORD_SEQ_[colds]',\n",
       " u'DDLIB_LEMMA_SEQ_[cold]',\n",
       " u'DDLIB_POS_SEQ_[NNS]',\n",
       " u'DDLIB_DEP_SEQ_[conj]',\n",
       " u'DDLIB_W_LEFT_1_[and]',\n",
       " u'DDLIB_W_LEFT_POS_1_[CC]',\n",
       " u'DDLIB_W_LEFT_2_[, and]',\n",
       " u'DDLIB_W_LEFT_POS_2_[, CC]',\n",
       " u'DDLIB_W_LEFT_3_[cough , and]',\n",
       " u'DDLIB_W_LEFT_POS_3_[NNS , CC]',\n",
       " u'DDLIB_NUM_WORDS_1',\n",
       " u'TABLE_HTML_TAG_h1',\n",
       " u'TABLE_HTML_ANC_TAG_[document]',\n",
       " u'TABLE_HTML_ANC_TAG_html',\n",
       " u'TABLE_HTML_ANC_TAG_html',\n",
       " u'TABLE_HTML_ANC_TAG_body',\n",
       " u'TABLE_HTML_ANC_TAG_body',\n",
       " u'TABLE_HTML_ANC_TAG_p',\n",
       " u'TABLE_HTML_ANC_TAG_body',\n",
       " u'TABLE_HTML_ANC_TAG_p',\n",
       " u'TABLE_HTML_ANC_TAG_body',\n",
       " u'TABLE_HTML_ANC_TAG_body',\n",
       " u'TABLE_HTML_ANC_ATTR_lang',\n",
       " u'TABLE_HTML_ANC_ATTR_xml:lang',\n",
       " u'TABLE_HTML_ANC_ATTR_xmlns',\n",
       " u'TABLE_HTML_ANC_ATTR_lang',\n",
       " u'TABLE_HTML_ANC_ATTR_xml:lang',\n",
       " u'TABLE_HTML_ANC_ATTR_xmlns']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.get_features_by_candidate(candidates[1])[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
