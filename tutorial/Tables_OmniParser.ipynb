{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables OmniParser\n",
    "This notebook is meant for testing and development of an \"OmniParser\" that can parse all components of an HTML document, including the title, captions, sentences, tables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.parser import HTMLParser\n",
    "from snorkel.parser import OmniParser\n",
    "doc_parser = HTMLParser(path='data/diseases/diseases.xhtml')\n",
    "context_parser = OmniParser()\n",
    "cp = CorpusParser(doc_parser, context_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def parse_tag(tag):\n",
    "#     if tag.name is not None:\n",
    "#         print tag.name\n",
    "#         print \"---\"\n",
    "#         for child in tag.children:\n",
    "#             parse_tag(child)\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "# with open('data/diseases/diseases.xhtml','r') as f:\n",
    "#     soup = BeautifulSoup(f, 'lxml')\n",
    "# for tag in soup.children:\n",
    "#     parse_tag(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON-TABLE:Types of viruses, coughs, and colds\n",
      "NON-TABLE:Brain Cancer\n",
      "NON-TABLE:See Table Below.\n",
      "NON-TABLE:Common Ailments\n",
      "TABLE!\n",
      "TABLE!\n",
      "CPU times: user 95.8 ms, sys: 7.79 ms, total: 104 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%time corpus = cp.parse_corpus(name='Diseases Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "25\n",
      "29\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Types of viruses, coughs, and colds')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Brain Cancer')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'See Table Below.')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Common Ailments')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Disease')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Location')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Year')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Polio')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'New York')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'1914')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u\"I don't like Chicken Pox.\")\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 1, u'The plague is also bad.')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Boston')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'2001')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Scurvy')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Annapolis')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'1901')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Problem')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Cause')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Cost')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Arthritis')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Pokemon Go')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Free')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Yellow Fever')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Unicorns')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'$17.75')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Hypochondria')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'Fear')\n",
      "Sentence(Document('diseases', Corpus (Diseases Corpus)), 0, u'$100')\n"
     ]
    }
   ],
   "source": [
    "print len(corpus.documents)\n",
    "print len(corpus.documents[0].tables)\n",
    "print len(corpus.documents[0].phrases)\n",
    "print len(corpus.documents[0].sentences)\n",
    "for sent in corpus.documents[0].sentences: print sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 507899 disease phrases!\n"
     ]
    }
   ],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# Define a candidate space\n",
    "table_ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "disease_matcher = DictionaryMatch(d=diseases, longest_match_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With old Candidates object:\n",
    "from snorkel.candidates import EntityExtractor\n",
    "ce = EntityExtractor(table_ngrams, disease_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "for cand in candidates: print cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = candidates[0]\n",
    "for ngram in c.row_ngrams('words'): print ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurizer.get_features_by_candidate(candidates[1])[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
