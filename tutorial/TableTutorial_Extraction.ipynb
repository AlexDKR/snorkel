{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Extraction : Diseases\n",
    "\n",
    "This notebook is meant for in-house demonstration of candidate extraction and featurization of tables. It assumes an input file in XHTML format, a strict form of HTML that coincides with XML structure, allowing for easy display (HTML) and safe tree traversal (XML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Extraction\n",
    "\n",
    "First, import the 'HTMLParser' class to read HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/diseases/diseases.xhtml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"TableParser\" class divides the html doc into cells, adding a 'cell_id' attribute to each cell for future traversal, and creating \"Cell\" objects that have attributes such as row number, column number, html tag, html attributes, and any tags/attributes on a cells ancestors in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, pass these to a Corpus object for digestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 ms, sys: 3.53 ms, total: 44.1 ms\n",
      "Wall time: 64.4 ms\n"
     ]
    }
   ],
   "source": [
    "# from snorkel.parser import Corpus\n",
    "# %time corpus = Corpus(html_parser, table_parser)\n",
    "\n",
    "from snorkel.parser import CorpusParser\n",
    "cp = CorpusParser(html_parser, table_parser)\n",
    "%time corpus = cp.parse_corpus(name='Diseases Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase('0', 0, 0, 0, u'Disease')\n",
      "Phrase('0', 0, 1, 0, u'Location')\n",
      "Phrase('0', 0, 2, 0, u'Year')\n",
      "Phrase('0', 0, 3, 0, u'Polio')\n",
      "Phrase('0', 0, 4, 0, u'New York')\n",
      "Phrase('0', 0, 5, 0, u'1914')\n",
      "Phrase('0', 0, 6, 0, u'Chicken Pox are bad.')\n",
      "Phrase('0', 0, 6, 1, u'So is the plague.')\n",
      "Phrase('0', 0, 7, 0, u'Boston')\n",
      "Phrase('0', 0, 8, 0, u'2001')\n",
      "Phrase('0', 0, 9, 0, u'Scurvy')\n",
      "Phrase('0', 0, 10, 0, u'Annapolis')\n",
      "Phrase('0', 0, 11, 0, u'1901')\n",
      "Phrase('0', 0, 0, 0, u'Problem')\n",
      "Phrase('0', 0, 1, 0, u'Cause')\n",
      "Phrase('0', 0, 2, 0, u'Cost')\n",
      "Phrase('0', 0, 3, 0, u'Arthritis')\n",
      "Phrase('0', 0, 4, 0, u'Pokemon Go')\n",
      "Phrase('0', 0, 5, 0, u'Free')\n",
      "Phrase('0', 0, 6, 0, u'Yellow Fever')\n",
      "Phrase('0', 0, 7, 0, u'Unicorns')\n",
      "Phrase('0', 0, 8, 0, u'$17.75')\n",
      "Phrase('0', 0, 9, 0, u'Hypochondria')\n",
      "Phrase('0', 0, 10, 0, u'Fear')\n",
      "Phrase('0', 0, 11, 0, u'$100')\n"
     ]
    }
   ],
   "source": [
    "doc = corpus.documents[0]\n",
    "for phrase in doc.phrases: print phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the good 'ole disease dictionary for recognizing disease names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 507899 disease phrases!\n"
     ]
    }
   ],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a new CandidateSpace object, CellNgrams. It inherits from Ngrams, and ensures that the Table context object is broken up into cells before being passed into the usual routine for pulling out Ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "disease_matcher = DictionaryMatch(d=diseases, longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the CandidateSpace, Matcher, and Context objects to a Candidates object, extraction is performed, and we see that a number of disease CellNgrams are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 ms, sys: 1.3 ms, total: 47.3 ms\n",
      "Wall time: 57.2 ms\n",
      "Ngram(\"Disease\", context=None, chars=[0,6], words=[0,0])\n",
      "Ngram(\"Location\", context=None, chars=[11,18], words=[0,0])\n",
      "Ngram(\"Polio\", context=None, chars=[31,35], words=[0,0])\n",
      "Ngram(\"Chicken Pox\", context=None, chars=[60,70], words=[0,1])\n",
      "Ngram(\"plague\", context=None, chars=[91,96], words=[3,3])\n",
      "Ngram(\"Scurvy\", context=None, chars=[120,125], words=[0,0])\n",
      "Ngram(\"Problem\", context=None, chars=[0,6], words=[0,0])\n",
      "Ngram(\"Arthritis\", context=None, chars=[28,36], words=[0,0])\n",
      "Ngram(\"Yellow Fever\", context=None, chars=[63,74], words=[0,1])\n",
      "Ngram(\"Fever\", context=None, chars=[70,74], words=[1,1])\n",
      "Ngram(\"Hypochondria\", context=None, chars=[101,112], words=[0,0])\n"
     ]
    }
   ],
   "source": [
    "# With new Candidates object:\n",
    "# from snorkel.candidates import Candidates\n",
    "# %time candidates = Candidates(table_ngrams, disease_matcher, corpus.get_contexts())\n",
    "\n",
    "# With old Candidates object:\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce = CandidateExtractor(ngrams, disease_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "for cand in candidates: print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate features on our set of candidates, including *new and improved* table features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11x115 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 242 stored elements in LInked List format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DDLIB_WORD_SEQ_[Disease]',\n",
       " u'DDLIB_LEMMA_SEQ_[disease]',\n",
       " u'DDLIB_POS_SEQ_[NN]',\n",
       " u'DDLIB_DEP_SEQ_[ROOT]',\n",
       " u'DDLIB_W_LEFT_1_[disease]',\n",
       " u'DDLIB_W_LEFT_POS_1_[NN]',\n",
       " 'DDLIB_STARTS_WITH_CAPITAL',\n",
       " 'DDLIB_LENGTH_1',\n",
       " 'TABLE_ROW_NUM_0',\n",
       " 'TABLE_COL_NUM_1',\n",
       " 'TABLE_HTML_TAG_th',\n",
       " 'TABLE_HTML_ATTR_style=height:66pt',\n",
       " 'TABLE_HTML_ATTR_style=outline:solid',\n",
       " 'TABLE_HTML_ATTR_type=phenotype',\n",
       " 'TABLE_HTML_ANC_TAG_tr',\n",
       " 'TABLE_HTML_ANC_TAG_tbody',\n",
       " 'TABLE_HTML_ANC_TAG_table',\n",
       " 'TABLE_HTML_ANC_TAG_body',\n",
       " 'TABLE_HTML_ANC_ATTR_align=left',\n",
       " 'TABLE_HTML_ANC_ATTR_style=width:158pt',\n",
       " 'TABLE_HTML_ANC_ATTR_style=border-top-style:solid',\n",
       " 'TABLE_HTML_ANC_ATTR_style=border-top-width:1pt',\n",
       " 'TABLE_HTML_ANC_ATTR_size=5',\n",
       " 'TABLE_HTML_ANC_ATTR_font=blue']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurizer.get_features_by_candidate(candidates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ta-da! Next up: feeding these features into the learning machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
