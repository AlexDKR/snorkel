{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Extraction : Diseases\n",
    "\n",
    "This notebook is meant for in-house demonstration of candidate extraction and featurization of tables. It assumes an input file in XHTML format, a strict form of HTML that coincides with XML structure, allowing for easy display (HTML) and safe tree traversal (XML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Extraction\n",
    "\n",
    "First, import the 'HTMLParser' class to read HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenhancock/anaconda/lib/python2.7/site-packages/sqlalchemy/ext/declarative/clsregistry.py:120: SAWarning: This declarative base already contains a class with the same class name and module name as snorkel.models.context.Context, and will be replaced in the string-lookup table.\n",
      "  item.__name__\n",
      "[autoreload of snorkel.models.context failed: Traceback (most recent call last):\n",
      "  File \"/Users/bradenhancock/anaconda/lib/python2.7/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "InvalidRequestError: Table 'context' is already defined for this MetaData instance.  Specify 'extend_existing=True' to redefine options and columns on an existing Table object.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/diseases/diseases.xhtml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"TableParser\" class divides the html doc into cells, adding a 'cell_id' attribute to each cell for future traversal, and creating \"Cell\" objects that have attributes such as row number, column number, html tag, html attributes, and any tags/attributes on a cells ancestors in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, pass these to a Corpus object for digestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 171 ms, sys: 89.5 ms, total: 260 ms\n",
      "Wall time: 379 ms\n"
     ]
    }
   ],
   "source": [
    "# from snorkel.parser import Corpus\n",
    "# %time corpus = Corpus(html_parser, table_parser)\n",
    "\n",
    "from snorkel.parser import CorpusParser\n",
    "cp = CorpusParser(html_parser, table_parser)\n",
    "%time corpus = cp.parse_corpus(name='Diseases Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('0', Corpus (Diseases Corpus))\n",
      "Table('0', 0)\n",
      "Cell('0', 0, 0, 'Disease')\n",
      "Phrase('0', 0, 0, 0, u'Disease')\n"
     ]
    }
   ],
   "source": [
    "doc = corpus.documents[0]\n",
    "print doc\n",
    "print doc.tables[0]\n",
    "print doc.tables[0].cells[0]\n",
    "print doc.tables[0].cells[0].phrases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the good 'ole disease dictionary for recognizing disease names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 507899 disease phrases!\n"
     ]
    }
   ],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a new CandidateSpace object, CellNgrams. It inherits from Ngrams, and ensures that the Table context object is broken up into cells before being passed into the usual routine for pulling out Ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "disease_matcher = DictionaryMatch(d=diseases, longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the CandidateSpace, Matcher, and Context objects to a Candidates object, extraction is performed, and we see that a number of disease CellNgrams are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 ms, sys: 3.79 ms, total: 60.1 ms\n",
      "Wall time: 58.2 ms\n",
      "Ngram(\"Disease\", context=None, chars=[0,6], words=[0,0])\n",
      "Ngram(\"Location\", context=None, chars=[0,7], words=[0,0])\n",
      "Ngram(\"Polio\", context=None, chars=[0,4], words=[0,0])\n",
      "Ngram(\"Chicken Pox\", context=None, chars=[0,10], words=[0,1])\n",
      "Ngram(\"plague\", context=None, chars=[31,36], words=[3,3])\n",
      "Ngram(\"Scurvy\", context=None, chars=[0,5], words=[0,0])\n",
      "Ngram(\"Problem\", context=None, chars=[0,6], words=[0,0])\n",
      "Ngram(\"Arthritis\", context=None, chars=[0,8], words=[0,0])\n",
      "Ngram(\"Yellow Fever\", context=None, chars=[0,11], words=[0,1])\n",
      "Ngram(\"Fever\", context=None, chars=[7,11], words=[1,1])\n",
      "Ngram(\"Hypochondria\", context=None, chars=[0,11], words=[0,0])\n",
      "Ngram(\"Disease\", context=None, chars=[0,6], words=[0,0])\n",
      "Ngram(\"Location\", context=None, chars=[0,7], words=[0,0])\n",
      "Ngram(\"Polio\", context=None, chars=[0,4], words=[0,0])\n",
      "Ngram(\"Chicken Pox\", context=None, chars=[0,10], words=[0,1])\n",
      "Ngram(\"plague\", context=None, chars=[31,36], words=[3,3])\n",
      "Ngram(\"Scurvy\", context=None, chars=[0,5], words=[0,0])\n",
      "Ngram(\"Problem\", context=None, chars=[0,6], words=[0,0])\n",
      "Ngram(\"Arthritis\", context=None, chars=[0,8], words=[0,0])\n",
      "Ngram(\"Yellow Fever\", context=None, chars=[0,11], words=[0,1])\n",
      "Ngram(\"Fever\", context=None, chars=[7,11], words=[1,1])\n",
      "Ngram(\"Hypochondria\", context=None, chars=[0,11], words=[0,0])\n"
     ]
    }
   ],
   "source": [
    "# With new Candidates object:\n",
    "# from snorkel.candidates import Candidates\n",
    "# %time candidates = Candidates(table_ngrams, disease_matcher, corpus.get_contexts())\n",
    "\n",
    "# With old Candidates object:\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce = CandidateExtractor(ngrams, disease_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "for cand in candidates: print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate features on our set of candidates, including *new and improved* table features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22x113 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 440 stored elements in LInked List format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDLIB_WORD_SEQ_[Disease]\n",
      "DDLIB_LEMMA_SEQ_[disease]\n",
      "DDLIB_POS_SEQ_[NN]\n",
      "DDLIB_DEP_SEQ_[ROOT]\n",
      "DDLIB_W_LEFT_1_[disease]\n",
      "DDLIB_W_LEFT_POS_1_[NN]\n",
      "DDLIB_STARTS_WITH_CAPTIAL\n",
      "DDLIB_LENGTH_1\n",
      "TABLE_ROW_NUM_0\n",
      "TABLE_COL_NUM_1\n",
      "TABLE_HTML_TAG_th\n",
      "TABLE_HTML_ANC_TAG_tr\n",
      "TABLE_HTML_ANC_TAG_tbody\n",
      "TABLE_HTML_ANC_TAG_table\n",
      "TABLE_HTML_ANC_TAG_body\n",
      "TABLE_HTML_ANC_ATTR_align=left\n",
      "TABLE_HTML_ANC_ATTR_size=5\n",
      "TABLE_HTML_ANC_ATTR_font=blue\n"
     ]
    }
   ],
   "source": [
    "featurizer.print_features(candidates[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ta-da! Next up: feeding these features into the learning machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
