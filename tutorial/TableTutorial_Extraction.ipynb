{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Extraction : Diseases\n",
    "\n",
    "This notebook is meant for in-house demonstration of candidate extraction and featurization of tables. It assumes an input file in XHTML format, a strict form of HTML that coincides with XML structure, allowing for easy display (HTML) and safe tree traversal (XML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Extraction\n",
    "\n",
    "First, import the 'HTMLParser' class to read HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/diseases/diseases.xhtml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"TableParser\" class divides the html doc into cells, adding a 'cell_id' attribute to each cell for future traversal, and creating \"Cell\" objects that have attributes such as row number, column number, html tag, html attributes, and any tags/attributes on a cells ancestors in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, pass these to a Corpus object for digestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 parsed\n",
      "CPU times: user 37.6 ms, sys: 3.61 ms, total: 41.2 ms\n",
      "Wall time: 54.7 ms\n"
     ]
    }
   ],
   "source": [
    "# from snorkel.parser import Corpus\n",
    "# %time corpus = Corpus(html_parser, table_parser)\n",
    "\n",
    "from snorkel.parser import CorpusParser\n",
    "cp = CorpusParser(html_parser, table_parser)\n",
    "%time corpus = cp.parse_corpus(name='Diseases Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase('0', 0, 0, 1, u'Disease.')\n",
      "Phrase('0', 0, 1, 0, u'Location.')\n",
      "Phrase('0', 0, 2, 0, u'Year.')\n",
      "Phrase('0', 0, 3, 0, u'Polio.')\n",
      "Phrase('0', 0, 4, 0, u'New York.')\n",
      "Phrase('0', 0, 5, 0, u'1914.')\n",
      "Phrase('0', 0, 6, 0, u'Chicken Pox are bad.')\n",
      "Phrase('0', 0, 6, 1, u'So is the plague.')\n",
      "Phrase('0', 0, 6, 2, u'.')\n",
      "Phrase('0', 0, 7, 0, u'Boston.')\n",
      "Phrase('0', 0, 8, 0, u'2001.')\n",
      "Phrase('0', 0, 9, 0, u'Scurvy.')\n",
      "Phrase('0', 0, 10, 0, u'Annapolis.')\n",
      "Phrase('0', 0, 11, 0, u'1901')\n",
      "Phrase('0', 0, 0, 1, u'Problem.')\n",
      "Phrase('0', 0, 1, 0, u'Cause.')\n",
      "Phrase('0', 0, 2, 0, u'Cost.')\n",
      "Phrase('0', 0, 3, 0, u'Arthritis.')\n",
      "Phrase('0', 0, 4, 0, u'Pokemon Go.')\n",
      "Phrase('0', 0, 5, 0, u'Free.')\n",
      "Phrase('0', 0, 6, 0, u'Yellow Fever.')\n",
      "Phrase('0', 0, 7, 0, u'Unicorns.')\n",
      "Phrase('0', 0, 8, 0, u'$17.75.')\n",
      "Phrase('0', 0, 9, 0, u'Hypochondria.')\n",
      "Phrase('0', 0, 10, 0, u'Fear.')\n",
      "Phrase('0', 0, 11, 0, u'$100')\n"
     ]
    }
   ],
   "source": [
    "doc = corpus.documents[0]\n",
    "for phrase in doc.phrases: print phrase\n",
    "# doc.phrases[0].words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the good 'ole disease dictionary for recognizing disease names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from load_dictionaries import load_disease_dictionary\n",
    "\n",
    "# Load the disease phrase dictionary\n",
    "diseases = load_disease_dictionary()\n",
    "print \"Loaded %s disease phrases!\" % len(diseases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a new CandidateSpace object, CellNgrams. It inherits from Ngrams, and ensures that the Table context object is broken up into cells before being passed into the usual routine for pulling out Ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "disease_matcher = DictionaryMatch(d=diseases, longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the CandidateSpace, Matcher, and Context objects to a Candidates object, extraction is performed, and we see that a number of disease CellNgrams are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With new Candidates object:\n",
    "# from snorkel.candidates import Candidates\n",
    "# %time candidates = Candidates(table_ngrams, disease_matcher, corpus.get_contexts())\n",
    "\n",
    "# With old Candidates object:\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce = CandidateExtractor(ngrams, disease_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "for cand in candidates: print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate features on our set of candidates, including *new and improved* table features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featurizer.print_features(candidates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ta-da! Next up: feeding these features into the learning machine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
