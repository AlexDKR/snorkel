{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction + Learning : Hardware Spec Sheets\n",
    "\n",
    "This notebook demonstrates the full entity extraction process on transistor data sheets, extracting min storage temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/hardware/hardware_docs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 s, sys: 2.35 s, total: 55.5 s\n",
      "Wall time: 55.8 s\n",
      "Corpus has been loaded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import cPickle\n",
    "    with open(\"hardware_corpus.pkl\",\"r\") as pkl:\n",
    "        %time corpus = cPickle.load(pkl)\n",
    "    print \"Corpus has been loaded.\"\n",
    "except:\n",
    "    from snorkel.parser import CorpusParser\n",
    "    cp = CorpusParser(html_parser, table_parser, max_docs=200)\n",
    "    %time corpus = cp.parse_corpus(name='Hardware Corpus')\n",
    "    print \"Corpus has been parsed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import cPickle\n",
    "# with open(\"hardware_corpus.pkl\",'wb') as pkl:\n",
    "#     cPickle.dump(corpus, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# session.add(corpus)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Corpus\n",
    "# corpus = session.query(Corpus).filter(Corpus.name == 'Hardware Corpus').one()\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import NumberMatcher, RangeMatcher\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "number_matcher = RangeMatcher(low=-70,high=-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.candidates import Candidates\n",
    "# %time candidates = Candidates(ngrams, number_matcher, corpus.get_contexts())\n",
    "# for c in candidates.get_candidates()[:5]: print c\n",
    "    \n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce = CandidateExtractor(ngrams, number_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "for cand in candidates[:10]: \n",
    "    print cand\n",
    "print \"%s candidates extracted\" % len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# session.add(candidates)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import CandidateSet\n",
    "# candidates = session.query(CandidateSet).filter(CandidateSet.name == 'all').one()\n",
    "# print len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate gold data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import collect_hardware_temperature_annotations\n",
    "gt_dict = collect_hardware_temperature_annotations('data/hardware/gold_all.csv', 'stg_temp_min', candidates)\n",
    "print \"%s out of %s candidates have gold labels\" % (len(gt_dict),len(candidates))\n",
    "print \"%s out of %s labeled candidates have positive label\" \\\n",
    "        % (gt_dict.values().count(1), len(gt_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then confirm that features work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)\n",
    "for f in featurizer.get_features_by_candidate(candidates[0])[:10]: print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a legacy DDLiteModel with which we will do learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.snorkel import DDLiteModel\n",
    "DDL = DDLiteModel(candidates, featurizer.fit_transform(candidates), gt_dict)\n",
    "\n",
    "DDL.set_holdout(idxs=range(int(len(gt_dict)*.7)), validation_frac=0.5)\n",
    "print \"%s training data\" % len(DDL.gt.get_labeled_ground_truth('training')[0])\n",
    "print \"%s test data\" % len(DDL.gt.get_labeled_ground_truth('test')[0])\n",
    "print \"%s validation data\" % len(DDL.gt.get_labeled_ground_truth('validation')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LF_to(m):\n",
    "    return 1 if 'to' in m.post_window('words') else 0\n",
    "def LF_storage(m):\n",
    "    return 1 if 'storage' in m.aligned_ngrams('words') else -1\n",
    "def LF_tstg(m):\n",
    "    return 1 if 'tstg' in m.aligned_ngrams('words') else -1\n",
    "def LF_temperature(m):\n",
    "    return 1 if 'temperature' in m.aligned_ngrams('words') else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs = [LF_to, LF_storage, LF_tstg, LF_temperature]\n",
    "DDL.apply_lfs(LFs, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print DDL.lf_names\n",
    "DDL.print_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.top_conflict_lfs(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.lowest_coverage_lfs(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn, baby, learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "mu_seq = np.ravel([1e-9, 1e-5, 1e-3, 1e-1])\n",
    "lf_opts = {'sample': False, 'verbose': True}\n",
    "model_opts = {'sample': False, 'n_iter': 3000, 'alpha': 0.5, 'mu': mu_seq, 'bias': False, 'verbose': True}\n",
    "%time DDL.train_model(method='lr', lf_opts=lf_opts, model_opts=model_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.show_log()\n",
    "idxs, gt = DDL.get_labeled_ground_truth(subset=DDL.holdout())\n",
    "acc_feats = np.mean(DDL.get_predicted(subset=DDL.holdout()) == gt)\n",
    "print \"Full model accuracy: {:.3f}\".format(acc_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune in next time for relation extraction!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
