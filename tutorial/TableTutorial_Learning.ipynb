{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction + Learning : Hardware Spec Sheets\n",
    "\n",
    "This notebook demonstrates the full entity extraction process on transistor data sheets, extracting min storage temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/hardware/hardware_docs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 documents parsed\n",
      "1 documents parsed\n",
      "2 documents parsed\n",
      "3 documents parsed\n",
      "4 documents parsed\n",
      "CPU times: user 53.3 s, sys: 2.4 s, total: 55.7 s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "cp = CorpusParser(html_parser, table_parser, max_docs=5)\n",
    "%time corpus = cp.parse_corpus(name='Hardware Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import NumberMatcher, RangeMatcher\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "number_matcher = RangeMatcher(low=-80,high=-40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.75 s, sys: 354 ms, total: 10.1 s\n",
      "Wall time: 10 s\n",
      "Ngram(\"-40\", context=None, chars=[0,2], words=[0,0])\n",
      "Ngram(\"-40\", context=None, chars=[0,2], words=[0,0])\n",
      "Ngram(\"-55\", context=None, chars=[0,2], words=[0,0])\n",
      "Ngram(\"-40\", context=None, chars=[0,2], words=[0,0])\n",
      "Ngram(\"-40\", context=None, chars=[0,2], words=[0,0])\n",
      "Ngram(\"-50\", context=None, chars=[0,2], words=[0,0])\n",
      "Ngram(\"-50\", context=None, chars=[0,2], words=[0,0])\n",
      "Ngram(\"-50\", context=None, chars=[4,6], words=[2,2])\n",
      "Ngram(\"-50\", context=None, chars=[4,6], words=[2,2])\n",
      "Ngram(\"-50\", context=None, chars=[4,6], words=[2,2])\n"
     ]
    }
   ],
   "source": [
    "# from snorkel.candidates import Candidates\n",
    "# %time candidates = Candidates(ngrams, number_matcher, corpus.get_contexts())\n",
    "# for c in candidates.get_candidates()[:5]: print c\n",
    "    \n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce = CandidateExtractor(ngrams, number_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "for cand in candidates[:10]: print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate gold data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 gold annotations\n",
      "1 out of 1 candidates are positive\n"
     ]
    }
   ],
   "source": [
    "# read from csv\n",
    "import csv\n",
    "with open('data/hardware/gold_all.csv', 'rb') as csvfile:\n",
    "    gold_reader = csv.reader(csvfile)\n",
    "    gold = []\n",
    "    for row in gold_reader:\n",
    "        (doc, part, temp, label) = row\n",
    "        if label=='stg_temp_min':\n",
    "            gold.append((doc,temp))\n",
    "gold = set(gold)\n",
    "print \"%s gold annotations\" % len(gold)\n",
    "\n",
    "# match with candidates\n",
    "gt_dict = {}\n",
    "for c in candidates:\n",
    "    filename = (c.context.document.file).split('.')[0]\n",
    "    temp = c.get_attrib_span('words')\n",
    "    label = 1 if (filename, temp) in gold else -1\n",
    "    gt_dict[c.id] = label\n",
    "print \"%s out of %s candidates are positive\" % (gt_dict.values().count(1), len(gt_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then confirm that features work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Extracted 904 features for each of 101 candidates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'BASIC_NGRAM_-40',\n",
       " 'TABLE_ROW_NUM_9',\n",
       " 'TABLE_COL_NUM_2',\n",
       " 'TABLE_HTML_TAG_td',\n",
       " 'TABLE_HTML_ATTR_style=width:108pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt',\n",
       " 'TABLE_HTML_ANC_TAG_tr',\n",
       " 'TABLE_HTML_ANC_TAG_table',\n",
       " 'TABLE_HTML_ANC_TAG_body',\n",
       " 'TABLE_HTML_ANC_ATTR_style=height:16pt',\n",
       " 'TABLE_HTML_ANC_ATTR_style=border-collapse:collapse;margin-left:23.7102pt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer(candidates, corpus)\n",
    "featurizer.get_features_by_id(candidates[0].id)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a legacy DDLiteModel with which we will do learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ngram' object has no attribute 'uid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-65cc81a4cad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnorkel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDLiteModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDDL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDLiteModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDDL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_holdout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%s training data\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDDL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labeled_ground_truth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenhancock/snorkel/snorkel/snorkel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, candidates, feats, gt_dict)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlf_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# GT data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCandidateGT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0;31m# MT data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_mindtagger_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bradenhancock/snorkel/snorkel/snorkel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, candidates, gt_dict)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gt_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt_dict\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gt_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Ngram' object has no attribute 'uid'"
     ]
    }
   ],
   "source": [
    "from snorkel.snorkel import DDLiteModel\n",
    "DDL = DDLiteModel(candidates, featurizer.get_features(), gt_dict)\n",
    "\n",
    "DDL.set_holdout(idxs=range(50), validation_frac=0.5)\n",
    "print \"%s training data\" % len(DDL.gt.get_labeled_ground_truth('training')[0])\n",
    "print \"%s test data\" % len(DDL.gt.get_labeled_ground_truth('test')[0])\n",
    "print \"%s validation data\" % len(DDL.gt.get_labeled_ground_truth('validation')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_to(m):\n",
    "    return 1 if 'to' in m.post_window('words') else 0\n",
    "def LF_storage(m):\n",
    "    return 1 if 'storage' in m.aligned('words') else -1\n",
    "def LF_tstg(m):\n",
    "    return 1 if 'tstg' in m.aligned('words') else -1\n",
    "def LF_temperature(m):\n",
    "    return 1 if 'temperature' in m.aligned('words') else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs = [LF_to, LF_storage, LF_tstg, LF_temperature]\n",
    "DDL.apply_lfs(LFs, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print DDL.lf_names\n",
    "DDL.print_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.top_conflict_lfs(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.lowest_coverage_lfs(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn, baby, learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "mu_seq = np.ravel([1e-9, 1e-5, 1e-3, 1e-1])\n",
    "lf_opts = {'sample': False, 'verbose': True}\n",
    "model_opts = {'sample': False, 'n_iter': 3000, 'alpha': 0.5, 'mu': mu_seq, 'bias': False, 'verbose': True}\n",
    "%time DDL.train_model(method='lr', lf_opts=lf_opts, model_opts=model_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.show_log()\n",
    "idxs, gt = DDL.get_labeled_ground_truth(subset=DDL.holdout())\n",
    "acc_feats = np.mean(DDL.get_predicted(subset=DDL.holdout()) == gt)\n",
    "print \"Full model accuracy: {:.3f}\".format(acc_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune in next time for relation extraction!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
