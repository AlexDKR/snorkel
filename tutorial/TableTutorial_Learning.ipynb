{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction + Learning : Hardware Spec Sheets\n",
    "\n",
    "This notebook demonstrates the full entity extraction process on transistor data sheets, extracting min storage temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel import SnorkelSession\n",
    "# session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "html_parser = HTMLParser(path='data/hardware/hardware_docs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import TableParser\n",
    "table_parser = TableParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.54 s, sys: 96 ms, total: 4.64 s\n",
      "Wall time: 7.27 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "cp = CorpusParser(html_parser, table_parser, max_docs=10)\n",
    "%time corpus = cp.parse_corpus(name='Hardware Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# session.add(corpus)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Corpus\n",
    "# corpus = session.query(Corpus).filter(Corpus.name == 'CDR Corpus').one()\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import TableNgrams\n",
    "from snorkel.matchers import NumberMatcher, RangeMatcher\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=3)\n",
    "\n",
    "# Define a matcher\n",
    "number_matcher = RangeMatcher(low=-100,high=-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 s, sys: 121 ms, total: 1.74 s\n",
      "Wall time: 1.68 s\n",
      "Ngram(\"-40\", context=None, chars=[77,79], words=[0,0])\n",
      "Ngram(\"-40\", context=None, chars=[123,125], words=[0,0])\n",
      "Ngram(\"-55\", context=None, chars=[297,299], words=[0,0])\n",
      "Ngram(\"-40\", context=None, chars=[160,162], words=[0,0])\n",
      "Ngram(\"-10\", context=None, chars=[228,230], words=[2,2])\n",
      "Ngram(\"-40\", context=None, chars=[249,251], words=[0,0])\n",
      "Ngram(\"-10\", context=None, chars=[315,317], words=[2,2])\n",
      "Ngram(\"-30\", context=None, chars=[389,391], words=[2,2])\n",
      "Ngram(\"-50\", context=None, chars=[414,416], words=[0,0])\n",
      "Ngram(\"-30\", context=None, chars=[469,471], words=[2,2])\n",
      "40 candidates extracted\n"
     ]
    }
   ],
   "source": [
    "# from snorkel.candidates import Candidates\n",
    "# %time candidates = Candidates(ngrams, number_matcher, corpus.get_contexts())\n",
    "# for c in candidates.get_candidates()[:5]: print c\n",
    "    \n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce = CandidateExtractor(ngrams, number_matcher)\n",
    "%time candidates = ce.extract(corpus.get_tables(), name='all')\n",
    "for cand in candidates[:10]: \n",
    "    print cand\n",
    "print \"%s candidates extracted\" % len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate gold data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import collect_hardware_annotations\n",
    "gt_dict = collect_hardware_annotations('data/hardware/gold_all.csv', 'stg_temp_min', candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 gold annotations\n",
      "1 out of 40 candidates have gold labels\n",
      "0 out of 1 labeled candidates have positive label\n"
     ]
    }
   ],
   "source": [
    "# read from csv\n",
    "\n",
    "print \"%s out of %s candidates have gold labels\" % (len(gt_dict),len(candidates))\n",
    "print \"%s out of %s labeled candidates have positive label\" \\\n",
    "        % (gt_dict.values().count(1), len(gt_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then confirm that features work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDLIB_WORD_SEQ_[-40]\n",
      "DDLIB_LEMMA_SEQ_[-40]\n",
      "DDLIB_POS_SEQ_[CD]\n",
      "DDLIB_DEP_SEQ_[ROOT]\n",
      "DDLIB_W_LEFT_1_[_NUMBER]\n",
      "DDLIB_W_LEFT_POS_1_[CD]\n",
      "DDLIB_LENGTH_1\n",
      "TABLE_ROW_NUM_1\n",
      "TABLE_COL_NUM_2\n",
      "TABLE_HTML_TAG_td\n"
     ]
    }
   ],
   "source": [
    "from snorkel.features import TableNgramFeaturizer\n",
    "featurizer = TableNgramFeaturizer()\n",
    "featurizer.fit_transform(candidates)\n",
    "for f in featurizer.get_features_by_candidate(candidates[0])[:10]: print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a legacy DDLiteModel with which we will do learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.snorkel import DDLiteModel\n",
    "DDL = DDLiteModel(candidates, featurizer.fit_transform(candidates), gt_dict)\n",
    "\n",
    "DDL.set_holdout(idxs=range(50), validation_frac=0.5)\n",
    "print \"%s training data\" % len(DDL.gt.get_labeled_ground_truth('training')[0])\n",
    "print \"%s test data\" % len(DDL.gt.get_labeled_ground_truth('test')[0])\n",
    "print \"%s validation data\" % len(DDL.gt.get_labeled_ground_truth('validation')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LF_to(m):\n",
    "    return 1 if 'to' in m.post_window('words') else 0\n",
    "def LF_storage(m):\n",
    "    return 1 if 'storage' in m.aligned_ngrams('words') else -1\n",
    "def LF_tstg(m):\n",
    "    return 1 if 'tstg' in m.aligned_ngrams('words') else -1\n",
    "def LF_temperature(m):\n",
    "    return 1 if 'temperature' in m.aligned_ngrams('words') else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs = [LF_to, LF_storage, LF_tstg, LF_temperature]\n",
    "DDL.apply_lfs(LFs, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print DDL.lf_names\n",
    "DDL.print_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.top_conflict_lfs(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.lowest_coverage_lfs(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn, baby, learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "mu_seq = np.ravel([1e-9, 1e-5, 1e-3, 1e-1])\n",
    "lf_opts = {'sample': False, 'verbose': True}\n",
    "model_opts = {'sample': False, 'n_iter': 3000, 'alpha': 0.5, 'mu': mu_seq, 'bias': False, 'verbose': True}\n",
    "%time DDL.train_model(method='lr', lf_opts=lf_opts, model_opts=model_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DDL.show_log()\n",
    "idxs, gt = DDL.get_labeled_ground_truth(subset=DDL.holdout())\n",
    "acc_feats = np.mean(DDL.get_predicted(subset=DDL.holdout()) == gt)\n",
    "print \"Full model accuracy: {:.3f}\".format(acc_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune in next time for relation extraction!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
